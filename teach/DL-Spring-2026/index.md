---
layout: page
permalink: /teach/DL-Spring-2026/
title: Deep Learning---Models, Computation, and Applications 
---

Over the last few years, deep neural networks (DNNs) have fundamentally transformed the way people think of machine learning and approach practical problems. Successes around DNNs have ranged from traditional AI fields such as computer vision, natural language processing, interactive games, to healthcare, physical sciences---touching each and every corner of theoretical and applied domains. On the other hand, DNNs still largely operate as black-boxes and we only have very limited understanding as for when and why they work. This course introduces basic ingredients of DNNs, samples important applications, and throws around open problems. Emphasis is put on thinking from first principles and basic building blocks, as the field is still evolving rapidly and there is nothing there that cannot be changed. 

Full syllabus: [Syllabus.pdf](CSCI5527_2026_Spring.pdf)

**Instructor**: [Professor Ju Sun](https://sunju.org/)  Email: jusun AT umn.edu   (Office Hours: 4--6pm, Thur)

**When/Where**: Tue/Thur 2:30--3:45pm @ Bruininks Hall 230

**TA's**:   
[Jiandong Chen](https://www.linkedin.com/in/jiandong-chen/) (email: chen8111 AT umn.edu, office Hours: 11am--1pm Mon @ xx)    
[Wenjie Zhang](https://wenjie-zhang08.github.io/) (email: zhan7867 AT umn.edu, office Hours: 4--5pm Wed @ xx) 

**Lecture Schedule**

Disclaimer: The schedule is tentative and subject to change 

| Date   | Topics |    
| ------ |----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|    
| Jan 20/22 | Deep learning: overview \[[slides](Jan-20.pdf)\] <br> Neural networks: old and new \[[slides](Jan-22.pdf)\] <br> [Supplementary notes on high-dimensional calculus](calculus-review.pdf) |    
| Jan 27/29 | Fundamental belief: universal approximation theorems \[[slides](Jan-27.pdf)\]  <br> Basics of numerical optimization: optimality conditions \[[slides]\]  |
| Feb 03/05 | Basics of numerical optimization: iterative methods \[[slides]\]   |
| Feb 10/12 | Basics of numerical optimization: computing derivatives \[[slides]\]  | 
| Feb 17/19 | Basics of numerical optimization: computing derivative (Continued) <br> Training DNNs: Basic methods and tricks \[[slides]\]  |    
| Feb 24/26 | Training DNNs: basic methods and tricks (Continued) | 
| Mar 03/05 | Introduction to Google Colab and PyTorch \[[slides]\] <br> Introduction to Minnesota Supercomputing Institute (MSI) \[[slides]\] <br>    Course project \[[slides]\] | 
| Mar 10/12 | SPRING BREAK; NO LECTURES | 
| Mar 17/19 | From fully connected to convolutional neural networks \[[slides]\] | 
| Mar 24/26 | Applications of CNNs in computer vision: detection & segmentation \[[slides]\]| 
| Mar 31/Apr 02 | Sequence modeling: recurrent neural networks \[[slides]\] | 
| Apr 07/09 | Transformers, large language models, and foundation models \[[slides]\]| 
| Apr 14/16 | Relationship modeling: graph neural networks \[[slides]\]| 
| Apr 21/23 | Unsupervised and self-supervised representation \[[slides]\]| 
| Apr 28/30 | Deep generative models \[[slides]\]| 
|  |  |

**Homework**   
+ [HW 0](HW0-2026.pdf) (Due: Feb 07)
+ [HW 1] (Due: xx)
+ [HW 2] (Due: xx)
+ [HW 3] (Due: xx)
+ [HW 4] (Due: xx)
+ [HW 5] (Due: xx)