{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iXhGOlyRltux"
   },
   "source": [
    "# Introduction to CoLab, NumPy, and SciPy\n",
    "### Benjamin Lynch, Ph.D.\n",
    "### Minnesota Supercomputing Institute (MSI)\n",
    "\n",
    "*z.umn.edu/colab-5980*\n",
    "\n",
    "Below is a brief introduction to Google CoLab, NumPy, and SciPy. Some examples below borrow material from http://z.umn.edu/msipython and https://github.com/gmonce/scikit-learn-book \n",
    "\n",
    "## Outline\n",
    "* First, we're going to look at a few features in Google CoLab.\n",
    "* Next, we'll look at some features of NumPy\n",
    "* Finally, we'll look at a couple features of SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWztxB1yOd7r"
   },
   "source": [
    "# Google Colaboratory\n",
    "\n",
    "\n",
    "\n",
    "![alt text](https://s3.msi.umn.edu/blynch/public/csci_5980_colab_diagram.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uV22oucuXk9H"
   },
   "source": [
    "We're going to focus on 2 evironments (CoLab and MSI). There are many others. You can run a Jupyter notebook on your own laptop or you can use other online environment like Microsoft Azure Notebooks https://notebooks.azure.com \n",
    "\n",
    "# Moving Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nafMzBDLVQiP"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3NQfR5IVUBR"
   },
   "outputs": [],
   "source": [
    "!ls /content/gdrive/\n",
    "!ls \"/content/gdrive/Shared drives\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j53fdk0EB15p"
   },
   "source": [
    "Now, lets create a file and put it in our GDrive to make sure it's working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLgxoscbCV9e"
   },
   "outputs": [],
   "source": [
    "!echo woo hoo > /tmp/test.txt\n",
    "!mkdir -p \"/content/gdrive/My Drive/csci-5980\"\n",
    "!cp /tmp/test.txt \"/content/gdrive/My Drive/csci-5980\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tGrP3KraDH_r"
   },
   "source": [
    "Using this connection to GDrive, we can pull data into our colab instance. Another "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TWcaV9vDdyZ"
   },
   "outputs": [],
   "source": [
    "!wget https://opendata.arcgis.com/datasets/38cfcfe07c2543ad869c8ee8c8378b5e_0.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UaRSdzPfIZqV"
   },
   "source": [
    "now lets open it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w3W5EpiCIfzc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('38cfcfe07c2543ad869c8ee8c8378b5e_0.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uPNG_ACcQoDz"
   },
   "source": [
    "Lets try another method for getting data to our colab instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GSaJtIiQmbB"
   },
   "outputs": [],
   "source": [
    "from google.colab import files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nf-zff2mRMMk"
   },
   "outputs": [],
   "source": [
    "uploaded = files.upload() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yWZnUGQZVT4B"
   },
   "source": [
    "![alt text](https://blynch.s3.msi.umn.edu/public/csci_5980_1_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fXbkZGycu7x"
   },
   "source": [
    "![alt text](https://blynch.s3.msi.umn.edu/public/csci_5980_1_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_dwMThgcvIq"
   },
   "source": [
    "![alt text](https://blynch.s3.msi.umn.edu/public/csci_5980_1_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_uGvZbz-8oD"
   },
   "source": [
    "If our instance is running on a GPU, we can take a peek at what hardware we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAuXmWiMbJ8Q"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N2jpES7WdHVm"
   },
   "source": [
    "You can download your notebook from File -> Download .ipynb\n",
    "\n",
    "![alt text](https://blynch.s3.msi.umn.edu/public/csci_5980_1_4.png)\n",
    "\n",
    "This might be the easiest way to copy your notebook and move it to another platform. In addition to downloading the notebook, you can download data that you generate. E.g.;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Df0F-PXt9LXx"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_pziJCEgNfP"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('Original-Joan-Miro-Signed-Limited-Edition.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RA1krrZVlhVO"
   },
   "outputs": [],
   "source": [
    "!ls -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHmJ9S4OVuto"
   },
   "source": [
    "\n",
    "Introduction to NumPy\n",
    "NumPy Arrays\n",
    "NumPy (module numpy) provides an array datatype with vectorized operations (similar to Matlab or IDL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8wX3tJu9bzr"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Ls6P1mu4mf5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IV_71prP4pdB"
   },
   "source": [
    "Create two NumPy arrays containing 5 elements each. The numpy module contains a number of functions for generating common arrays:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R01dSWEx4ri1"
   },
   "outputs": [],
   "source": [
    "x = np.arange(5)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAmf4uyu42D3"
   },
   "outputs": [],
   "source": [
    "y = np.ones(5)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6MllfPBX45A4"
   },
   "source": [
    "Operations are vectorized, so we can do arithmetic with arrays (as long as the dimensions match!) as we would with scalar variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TjqHoF925D6_"
   },
   "outputs": [],
   "source": [
    "x - (y+0.005) * 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OxMNjtHP5Fvk"
   },
   "source": [
    "You can try to put different types of objects into an array, and NumPy will pick a data type that can hold them all.\n",
    "\n",
    "The results might not be quite what you expect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HGliLBS45IMX"
   },
   "outputs": [],
   "source": [
    "mixed = np.array([3,3.3e-10,\"string\",5,5])\n",
    "mixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yv-J5XpC5MhT"
   },
   "outputs": [],
   "source": [
    "mixed*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nv4eAhUA5PbH"
   },
   "source": [
    "More sensibly, it will choose types to avoid losing precision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3TLK_J_8oc4"
   },
   "outputs": [],
   "source": [
    "z = np.array([5,6.66666666666,7,8,9],dtype=np.float32)\n",
    "np.set_printoptions(precision=12)\n",
    "print(z)\n",
    "z.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lkUdye5V8sde"
   },
   "source": [
    "Supports the same type of list operations as ordinary Python lists:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMAm2QxI8yHR"
   },
   "outputs": [],
   "source": [
    "sorted(x - y * 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7fxw90sa9O71"
   },
   "source": [
    "...except the data type must match! A NumPy array only holds values of a single data type.\n",
    "\n",
    "This allows them to be packed efficiently in memory like C arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pK5QbB9-9Sbf"
   },
   "outputs": [],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3RUaCBXy9VSC"
   },
   "source": [
    "Speed comparison\n",
    "Math with NumPy arrays is much faster and more intuitive than the equivalent native Python operations\n",
    "\n",
    "Consider the function $y = 1.324\\cdot a - 12.99\\cdot b + 1$\n",
    "In pure Python we would define:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ga6QAmhx-Tm4"
   },
   "outputs": [],
   "source": [
    "def py_add(a, b):\n",
    "    assert(len(a) == len(b))\n",
    "    c = [0]*len(a)\n",
    "    for i in range(0,len(a)):\n",
    "        c[i] = 1.324 * a[i] - 12.99*b[i] + 1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qj2YAvrm-X5M"
   },
   "source": [
    "Using NumPy we could instead define:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2zX0nZu9wwu"
   },
   "outputs": [],
   "source": [
    "def np_add(a, b):\n",
    "    return 1.324 * a - 12.99 * b + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmDJHNoX90Jh"
   },
   "source": [
    "Now let's create a couple of very large arrays to work with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4yAwTcWL93GQ"
   },
   "outputs": [],
   "source": [
    "a = np.arange(1000000)\n",
    "b = np.random.randn(1000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4dnVA_rt9-03"
   },
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3UwKwFId9--v"
   },
   "outputs": [],
   "source": [
    "b[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gs-1HX33gSzC"
   },
   "source": [
    "Use the magic function %timeit to test the performance of both approaches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRuupSz9-Fyd"
   },
   "outputs": [],
   "source": [
    "%timeit py_add(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPepDX52-LTx"
   },
   "outputs": [],
   "source": [
    "%timeit np_add(a,b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h9hVYAJcHlzX"
   },
   "source": [
    "Now, we want to try out a memory profiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "84klIFdRgre0"
   },
   "outputs": [],
   "source": [
    "!pip install memory_profiler\n",
    "import memory_profiler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1lYjhy0ZgvJ5"
   },
   "source": [
    "Oops, we don't have one installed. We can install it on-the-fly like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwnkmG16-lD_"
   },
   "outputs": [],
   "source": [
    "import memory_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q99lHQCJICt1"
   },
   "outputs": [],
   "source": [
    "%memit py_add(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EfWe5d3dIFt0"
   },
   "outputs": [],
   "source": [
    "%memit np_add(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KJNVPeUJ3XZ"
   },
   "source": [
    "\n",
    "\n",
    "## Spiral Data Classification\n",
    "\n",
    "First, we import some modules and generate data in 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9dUWIfhBJ3h_"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from IPython.display import HTML, display, Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12.0, 10.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "N = 100 # number of points per class\n",
    "D = 2 # dimensionality\n",
    "K = 3 # number of classes\n",
    "X = np.zeros((N*K,D)) # data matrix (each row = single example)\n",
    "y = np.zeros(N*K, dtype='uint8') # class labels\n",
    "for j in range(K):\n",
    "  ix = range(N*j,N*(j+1))\n",
    "  r = np.linspace(0.0,1,N) # radius\n",
    "  t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta\n",
    "  X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "  y[ix] = j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j0CFgjWRvr6N"
   },
   "source": [
    "### Let's visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqYECBbmvxoD"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bd2Zsfn-K4lY"
   },
   "source": [
    "# Train a Linear Classifier\n",
    "\n",
    "## Initialize the weights with random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QBElZDfUKlGC"
   },
   "outputs": [],
   "source": [
    "W = 0.01 * np.random.randn(D,K)\n",
    "b = np.zeros((1,K))\n",
    "step_size = 1e-0\n",
    "reg = 1e-3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8kBUjzcALEZh"
   },
   "source": [
    "## Optimize the classifier using a basic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eytY13d0KQw0"
   },
   "outputs": [],
   "source": [
    "num_examples = X.shape[0]\n",
    "for i in range(200):\n",
    "  \n",
    "  # evaluate class scores, [N x K]\n",
    "  scores = np.dot(X, W) + b \n",
    "  \n",
    "  # compute the class probabilities\n",
    "  exp_scores = np.exp(scores)\n",
    "  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "  \n",
    "  # compute the loss: average cross-entropy loss and regularization\n",
    "  correct_logprobs = -np.log(probs[range(num_examples),y])\n",
    "  data_loss = np.sum(correct_logprobs)/num_examples\n",
    "  reg_loss = 0.5*reg*np.sum(W*W)\n",
    "  loss = data_loss + reg_loss\n",
    "  if i % 10 == 0:\n",
    "    print(\"iteration %d: loss %f\" % (i, loss))\n",
    "  # Compute the gradient\n",
    "  dscores = probs\n",
    "  dscores[range(num_examples),y] -= 1\n",
    "  dscores /= num_examples\n",
    "  \n",
    "  # backpropogate the gradient to the parameters (W,b)\n",
    "  dW = np.dot(X.T, dscores)\n",
    "  db = np.sum(dscores, axis=0, keepdims=True)\n",
    "  \n",
    "  dW += reg*W # regularization gradient\n",
    "  \n",
    "  # perform a parameter update\n",
    "  W += -step_size * dW\n",
    "  b += -step_size * db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhUtSKSOLE_T"
   },
   "source": [
    "## Evaluate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ppTBjc_jLPo4"
   },
   "outputs": [],
   "source": [
    "scores = np.dot(X, W) + b\n",
    "predicted_class = np.argmax(scores, axis=1)\n",
    "print('training accuracy: %.2f' % (np.mean(predicted_class == y)))\n",
    "print(W.size)\n",
    "print(b.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Luu4pqSMLrFU"
   },
   "source": [
    "## Plot the resulting classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4w_QR8VMaWQ"
   },
   "outputs": [],
   "source": [
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = np.dot(np.c_[xx.ravel(), yy.ravel()], W) + b\n",
    "Z = np.argmax(Z, axis=1)\n",
    "Z = Z.reshape(xx.shape)\n",
    "fig = plt.figure()\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KKTEaWExrruH"
   },
   "source": [
    "## Let's try again, and add a hidden layer\n",
    "### We start by initializing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1g2ZbVxLNqZ8"
   },
   "outputs": [],
   "source": [
    "h = 100 # size of hidden layer\n",
    "W = 0.01 * np.random.randn(D,h)\n",
    "b = np.zeros((1,h))\n",
    "W2 = 0.01 * np.random.randn(h,K)\n",
    "b2 = np.zeros((1,K))\n",
    "\n",
    "step_size = 1e-0\n",
    "reg = 1e-3 # regularization strength\n",
    "\n",
    "# gradient descent loop\n",
    "num_examples = X.shape[0]\n",
    "for i in range(10000):\n",
    "  \n",
    "  # evaluate class scores, [N x K]\n",
    "  hidden_layer = np.maximum(0, np.dot(X, W) + b) # note, ReLU activation\n",
    "  scores = np.dot(hidden_layer, W2) + b2\n",
    "  \n",
    "  # compute the class probabilities\n",
    "  exp_scores = np.exp(scores)\n",
    "  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "  \n",
    "  # compute the loss: average cross-entropy loss and regularization\n",
    "  correct_logprobs = -np.log(probs[range(num_examples),y])\n",
    "  data_loss = np.sum(correct_logprobs)/num_examples\n",
    "  reg_loss = 0.5*reg*np.sum(W*W) + 0.5*reg*np.sum(W2*W2)\n",
    "  loss = data_loss + reg_loss\n",
    "  if i % 1000 == 0:\n",
    "    print(\"iteration %d: loss %f\" % (i, loss))\n",
    "  \n",
    "  # compute the gradient on scores\n",
    "  dscores = probs\n",
    "  dscores[range(num_examples),y] -= 1\n",
    "  dscores /= num_examples\n",
    "  \n",
    "  # backpropate the gradient to the parameters\n",
    "  # first backprop into parameters W2 and b2\n",
    "  dW2 = np.dot(hidden_layer.T, dscores)\n",
    "  db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "  # next backprop into hidden layer\n",
    "  dhidden = np.dot(dscores, W2.T)\n",
    "  # backprop the ReLU non-linearity\n",
    "  dhidden[hidden_layer <= 0] = 0\n",
    "  # finally into W,b\n",
    "  dW = np.dot(X.T, dhidden)\n",
    "  db = np.sum(dhidden, axis=0, keepdims=True)\n",
    "  \n",
    "  # add regularization gradient contribution\n",
    "  dW2 += reg * W2\n",
    "  dW += reg * W\n",
    "  \n",
    "  # perform a parameter update\n",
    "  W += -step_size * dW\n",
    "  b += -step_size * db\n",
    "  W2 += -step_size * dW2\n",
    "  b2 += -step_size * db2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bBTn5pJ1heHB"
   },
   "source": [
    "## Evaluate training set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iSbIAHTLM0XY"
   },
   "outputs": [],
   "source": [
    "hidden_layer = np.maximum(0, np.dot(X, W) + b)\n",
    "scores = np.dot(hidden_layer, W2) + b2\n",
    "predicted_class = np.argmax(scores, axis=1)\n",
    "print('training accuracy: %.2f' % (np.mean(predicted_class == y)))\n",
    "print(b.size)\n",
    "print(W.size)\n",
    "print(b2.size)\n",
    "print(W2.size)\n",
    "print(dscores.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SHNHHqLEspPI"
   },
   "source": [
    "### Plot the resulting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UFlY3jP4PvQA"
   },
   "outputs": [],
   "source": [
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = np.dot(np.maximum(0, np.dot(np.c_[xx.ravel(), yy.ravel()], W) + b), W2) + b2\n",
    "Z = np.argmax(Z, axis=1)\n",
    "Z = Z.reshape(xx.shape)\n",
    "fig = plt.figure()\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJDhZOEgl4CD"
   },
   "source": [
    "Hooray, with 603 parameters, we were able to fit the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40H0qMJAlzzV"
   },
   "source": [
    "# Introduction to SciPy\n",
    "\n",
    "### SciPy has loads of useful \n",
    "\n",
    " * scipy.io.matlab\tâ€“\tsupport\tfor\tMatlab\t(.mat)\t\n",
    " * scipy.io.loadmat()\tand\tscipy.io.savemat()\t\n",
    " * Clustering\talgorithms\t(scipy.cluster)\n",
    " * Integration\tand\tODEs\t(scipy.integrate)\n",
    " * Interpolation\t(scipy.interpolate)\n",
    " * Input\tand\toutput\t(scipy.io)\n",
    " * Linear\talgebra\t(scipy.linalg)\n",
    " * Muli-dimensional\timage\tprocessing\t(scipy.ndimage)\n",
    " * Optimizaton\tand\troot\tfinding\t(scipy.optimize)\n",
    " * Signal\tprocessing\t(scipy.signal)\n",
    " * Sparse\tmatrices\t(scipy.sparse)\n",
    " * Spatial\talgorithms\tand\tdata\tstructures\t(scipy.spatial)\n",
    " * Special\tfunctions\t(scipy.special)\n",
    " * Statstical\tfunctions\t(scipy.stats)\n",
    "\n",
    "\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html\n",
    "\n",
    "\n",
    "1-D interpolation (interp1d)\n",
    "The interp1d class in scipy.interpolate is a convenient method to create a function based on fixed data points, which can be evaluated anywhere within the domain defined by the given data using linear interpolation. An instance of this class is created by passing the 1-D vectors comprising the data. The instance of this class defines a __call__ method and can therefore by treated like a function which interpolates between known data values to obtain unknown values (it also has a docstring for help). Behavior at the boundary can be specified at instantiation time. The following example demonstrates its use, for linear and cubic spline interpolation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "buOFu9gwSjuo"
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "x = np.linspace(0, 10, num=11, endpoint=True)\n",
    "y = np.cos(-x**2/9.0)\n",
    "f = interp1d(x, y)\n",
    "f2 = interp1d(x, y, kind='cubic')\n",
    "\n",
    "xnew = np.linspace(0, 10, num=41, endpoint=True)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, y, 'o', xnew, f(xnew), '-', xnew, f2(xnew), '--')\n",
    "plt.legend(['data', 'linear', 'cubic'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rzcBP-wkS0U5"
   },
   "source": [
    "Multivariate data interpolation (griddata)\n",
    "Suppose you have multidimensional data, for instance, for an underlying function f(x, y) you only know the values at points (x[i], y[i]) that do not form a regular grid.\n",
    "\n",
    "Suppose we want to interpolate the 2-D function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qn5R1C_jS1q1"
   },
   "outputs": [],
   "source": [
    "def func(x, y):\n",
    "  return x*(1-x)*np.cos(4*np.pi*x) * np.sin(4*np.pi*y**2)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zmNd9zjGTJVx"
   },
   "source": [
    "## on a grid in [0, 1]x[0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9KVOL2xTgGG"
   },
   "outputs": [],
   "source": [
    "grid_x, grid_y = np.mgrid[0:1:100j, 0:1:200j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M1BRIaMSTg2a"
   },
   "source": [
    "### but we only know its values at 1000 data points:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f9sytmTOThAN"
   },
   "outputs": [],
   "source": [
    "points = np.random.rand(1000, 2)\n",
    "values = func(points[:,0], points[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zshAkYzXThI4"
   },
   "source": [
    "### This can be done with the griddata function. Below, we try out all of the interpolation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2Jd5uG-ThTZ"
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata \n",
    "grid_z0 = griddata(points, values, (grid_x, grid_y), method='nearest') \n",
    "grid_z1 = griddata(points, values, (grid_x, grid_y), method='linear') \n",
    "grid_z2 = griddata(points, values, (grid_x, grid_y), method='cubic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2URAi94cThe4"
   },
   "source": [
    "### One can see that the exact result is reproduced by all of the methods to some degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TX9mTRRxThon"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(221)\n",
    "plt.imshow(func(grid_x, grid_y).T, extent=(0,1,0,1), origin='lower')\n",
    "plt.plot(points[:,0], points[:,1], 'k.', ms=1)\n",
    "plt.title('Original')\n",
    "plt.subplot(222)\n",
    "plt.imshow(grid_z0.T, extent=(0,1,0,1), origin='lower')\n",
    "plt.title('Nearest')\n",
    "plt.subplot(223)\n",
    "plt.imshow(grid_z1.T, extent=(0,1,0,1), origin='lower')\n",
    "plt.title('Linear')\n",
    "plt.subplot(224)\n",
    "plt.imshow(grid_z2.T, extent=(0,1,0,1), origin='lower')\n",
    "plt.title('Cubic')\n",
    "plt.gcf().set_size_inches(10, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FFK3h2DqJsw5"
   },
   "source": [
    "# Notebooks at MSI\n",
    "\n",
    "Jupyter is more than an interface for teaching. Jupyter is heavily used by researchers. It's a great interface for research. MSI has a large cluster for running large-scale simulations and data anlysis. MSI also runs  JupyterHub to allow researchers to access thier data in a Jupyter environment. JupyterHub can be accessed here:\n",
    "\n",
    "https://notebooks.msi.umn.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5HP9UYy3DQnZ"
   },
   "source": [
    "To use the notebooks at MSI, you will first need to select the group you want to work in. Most of you only have access to a single group. If you happen to be doing some research, you might have access to another group. After you select the group created for the class (csci5980) and press continue, you can click a button that reads \"Start My Server\". This will bring you to a dropdown menu to select the resources you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2G5LHfbjIevK"
   },
   "source": [
    "You can select the one labeled \"Mesabi - 2 Cores, 4 GB, 8 hours\". This will submit a job to the cluster and reserve the described resources for your Jupyter session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80ejVmqEJI4l"
   },
   "source": [
    "JupyterHub at MSI is being upgraded over the next few weeks, so there will be some changes and outages to the interface. Expect email with updates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aEar4g1-DN1r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NumPySciPy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
