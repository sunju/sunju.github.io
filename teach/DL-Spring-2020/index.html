<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Ju Sun | Think Deep Learning</title>
  <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/teach/DL-Spring-2020/">
  
  <style>
	ul {list-style-type: circle;}
  </style>
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Ju Sun</strong>
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">Welcome</a>

        <!-- Blog -->
        <a class="page-link" href="/blog/">Blog</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
            <a class="page-link" href="/teach/">Teaching</a>
          
        
          
            <a class="page-link" href="/pub/">Publications</a>
          
        
          
            <a class="page-link" href="/talks/">Talks</a>
          
        
          
            <a class="page-link" href="/software/">Software</a>
          
        
          
            <a class="page-link" href="/grants/">Grants</a>
          
        
          
            <a class="page-link" href="/people/">People</a>
          
        
          
        
          
        
          
        
          
            <a class="page-link" href="/research/">Research</a>
          
        
          
        
          
        
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Think Deep Learning</h1>
    <h5 class="post-description"></h5>
  </header>

  <article class="post-content Think Deep Learning clearfix">
    <p>Over the last few years, deep neural networks (DNN) have fundamentally transformed the way people think of machine learning and approach practical problems. Successes around DNN have ranged from traditional AI fields such as computer vision, natural language processing, interactive games, to health care, physical sciences—touching each and every corner of theoretical and applied domains. On the other hand, DNN still largely operate as black-boxes and we only have very limited understanding as for when and why they work. This course introduces basic ingredients of DNN, samples important applications, and throws around open problems. Emphasis is put on thinking from first principles, as the field is still evolving rapidly and there is nothing there that cannot be changed.</p>

<p><strong>Instructor</strong>: <a href="https://sunju.org/">Professor Ju Sun</a>  Email: jusun AT umn.edu</p>

<p><strong>When/Where</strong>: T/Th 2:30PM–3:45PM, Akerman Hall 225</p>

<p><strong>TA’s</strong>: <a href="https://myaccount.umn.edu/lookup?SET_INSTITUTION=&amp;UID=yaoxx340">Yuan Yao</a>  Email: yaoxx340 AT umn.edu        <a href="https://myaccount.umn.edu/lookup?SET_INSTITUTION=&amp;UID=lixx5027">Taihui Li</a> Email: lixx5027 AT umn.edu</p>

<p>The detailed syllabus, containing the office hours, recommended references, assessment, homework and project requirements, programming and computing, and other resources, can be found here: <a href="/teach/DL-Spring-2020/Syllabus.pdf">Syllabus.pdf</a></p>

<!-- **Target**: Graduate and advanced undergrad students. Registration is based on permission from the instructor. If you're interested, please email Prof. Sun (jusun AT umn.edu) and describe your academic standing, relevant course experience, and research experience if any. -->

<!-- **No Panic**: <span style="color:red"> The enrollment has reached the cap. </span> While we're maintaining a waiting list, and may decide to increase the cap later, there's no guarantee. We're likely to re-run the course in fall 2020 and to make the course regular in the near future, and so please consider next iterations if you're not in. -->

<!-- **Prerequisite**: Introduction to machine learning or equivalent. Maturity in linear algebra, calculus, and basic probability is assumed. Familiarity with Python (esp. numpy, scipy) is necessary to complete the homework assignments and final projects.   -->

<ul>
  <li><a href="#references">References</a></li>
  <li><a href="#lectures">Lectures</a></li>
  <li><a href="#homework-assignments">Homework assignments</a></li>
  <li><a href="#course-project">Course project</a></li>
</ul>

<h4 id="references">References</h4>
<ul>
  <li>(D2L)  <a href="https://d2l.ai/">Dive into Deep Learning</a> by Aston Zhang, Zachary C. Lipton,  Mu Li, and Alexander J. Smola. Livebook.</li>
  <li>(DL)  <a href="https://www.deeplearningbook.org/">Deep Learning</a> by Ian Goodfellow, Yoshua Bengio, Aaron Courville. MIT Press, 2016.</li>
  <li>(MNDL) <a href="https://www.springer.com/gp/book/9783319944623">Neural Networks and Deep Learning</a> by Charu Aggarwal. Springer, 2018.</li>
  <li>(DLR) <a href="https://mitpress.mit.edu/books/deep-learning-revolution">The Deep Learning Revolution</a> by Terrence J. Sejnowski. MIT Press, 2018.</li>
  <li>(DLP) <a href="https://livebook.manning.
com/book/deep-learning-with-python">Deep Learning with Python</a> by François Chollet. Livebook.</li>
  <li>(HDML) <a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</a> (2ed) by Aurélien Géron. O’Reilly Media, 2019.</li>
</ul>

<h4 id="lectures">Lectures</h4>
<p><strong>slides</strong>: slides with transitions
<strong>handout</strong>: slides without transitions</p>

<table>
  <thead>
    <tr>
      <th>Date</th>
      <th>Topics</th>
      <th>Notes</th>
      <th>Reading</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>01/21</td>
      <td>Overview</td>
      <td><a href="/teach/DL-Spring-2020/lecture-01-21-slides.pdf">Slides</a>  <a href="/teach/DL-Spring-2020/lecture-01-21-handout.pdf">Handout</a></td>
      <td> </td>
    </tr>
    <tr>
      <td>01/23</td>
      <td>Neural networks: old and new</td>
      <td><a href="/teach/DL-Spring-2020/lecture-01-23-slides.pdf">Slides</a>  <a href="/teach/DL-Spring-2020/lecture-01-23-handout.pdf">Handout</a></td>
      <td>DLP Ch 1, D2L Ch 3–4, MNDL Ch 2</td>
    </tr>
    <tr>
      <td>01/28</td>
      <td>Fundamental belief: universal approximation theorems</td>
      <td><a href="/teach/DL-Spring-2020/lecture-01-28-slides.pdf">Slides</a>  <a href="/teach/DL-Spring-2020/lecture-01-28-handout.pdf">Handout</a></td>
      <td><a href="http://neuralnetworksanddeeplearning.com/chap4.html">Visual proof of UAT</a></td>
    </tr>
    <tr>
      <td>01/30</td>
      <td>UAT: from shallow to deep</td>
      <td><a href="/teach/DL-Spring-2020/lecture-01-30-slides.pdf">Slides</a>  <a href="/teach/DL-Spring-2020/lecture-01-30-handout.pdf">Handout</a></td>
      <td> </td>
    </tr>
    <tr>
      <td>02/04</td>
      <td>(Tutorial) Numpy, Scipy, Colab [Guest: <strong>Dr. Ben Lynch</strong> of MSI]</td>
      <td><a href="/teach/DL-Spring-2020/ColabNumPySciPy.html">HTML</a>  <a href="/teach/DL-Spring-2020/ColabNumPySciPy.ipynb">Notebook</a></td>
      <td> </td>
    </tr>
    <tr>
      <td>02/06</td>
      <td>(Discussion) Project ideas</td>
      <td><a href="/teach/DL-Spring-2020/lecture-02-06-slides.pdf">Slides</a></td>
      <td> </td>
    </tr>
    <tr>
      <td>02/11</td>
      <td>Basics of numerical optimization: preliminaries</td>
      <td><a href="/teach/DL-Spring-2020/lecture-02-11-slides.pdf">Slides</a>  <a href="/teach/DL-Spring-2020/lecture-02-11-handout.pdf">Handout</a></td>
      <td><a href="https://www.springer.com/gp/book/9783662487907">Zorich MA I</a> (Ch 8)       <a href="https://www.springer.com/gp/book/9780387303031">Nocedal &amp; Wright NA</a>  (Chs 1&amp;2)</td>
    </tr>
    <tr>
      <td>02/13</td>
      <td>Basics of numerical optimization: iterative methods – I</td>
      <td><a href="/teach/DL-Spring-2020/lecture-02-13-slides.pdf">Slides</a>  <a href="/teach/DL-Spring-2020/lecture-02-13-handout.pdf">Handout</a></td>
      <td><a href="https://www.springer.com/gp/book/9780387303031">Nocedal &amp; Wright NA</a>  (Chs 3–7)</td>
    </tr>
    <tr>
      <td>02/18</td>
      <td>(Tutorial) Tensorflow, Pytorch, MSI GPU cluster [Guest: <strong>Dr. Ben Lynch</strong> of MSI]</td>
      <td><a href="/teach/DL-Spring-2020/TensorFlowPyTorch.html">HTML</a>        <a href="/teach/DL-Spring-2020/TensorFlowPyTorch.ipynb">Notebook</a></td>
      <td> </td>
    </tr>
    <tr>
      <td>02/20</td>
      <td>Basics of numerical optimization: iterative methods – II</td>
      <td>Same as 02/13</td>
      <td> </td>
    </tr>
    <tr>
      <td>02/25</td>
      <td>Basics of numerical optimization: computing derivatives – I</td>
      <td><a href="/teach/DL-Spring-2020/lecture-02-25-slides.pdf">Slides</a>  <a href="/teach/DL-Spring-2020/lecture-02-25-handout.pdf">Handout</a></td>
      <td><a href="https://www.springer.com/gp/book/9780387303031">Nocedal &amp; Wright NA</a>  (Ch 8), <a href="http://jmlr.org/papers/v18/17-468.html">AD in  ML</a></td>
    </tr>
    <tr>
      <td>02/27</td>
      <td>Basics of numerical optimization: computing derivatives – II</td>
      <td>same as 02/25</td>
      <td><a href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b">Why bother understanding AD? </a></td>
    </tr>
    <tr>
      <td>03/03</td>
      <td>Optimization for DNNs: basic methods</td>
      <td><a href="/teach/DL-Spring-2020/lecture-03-03-slides.pdf">Slides</a>  <a href="/teach/DL-Spring-2020/lecture-03-03-handout.pdf">Handout</a></td>
      <td><a href="https://wiki.illinois.edu/wiki/spaces/viewspace.action?key=IE598ODLSP19">OPT for DL Course by Ruoyu Sun</a>   ,            <a href="https://arxiv.org/abs/1912.08957">Survey paper</a>, Stanford CS231n Notes: <a href="https://cs231n.github.io/neural-networks-1/">1</a>, <a href="https://cs231n.github.io/neural-networks-2/">2</a>, <a href="https://cs231n.github.io/neural-networks-3/">3</a></td>
    </tr>
    <tr>
      <td>03/05</td>
      <td>Optimization for DNNs: tricks</td>
      <td><a href="/teach/DL-Spring-2020/lecture-03-05-slides.pdf">Slides</a>  <a href="/teach/DL-Spring-2020/lecture-03-05-handout.pdf">Handout</a></td>
      <td><a href="https://wiki.illinois.edu/wiki/spaces/viewspace.action?key=IE598ODLSP19">OPT for DL Course by Ruoyu Sun</a>   ,            <a href="https://arxiv.org/abs/1912.08957">Survey paper</a>, Stanford CS231n Notes: <a href="https://cs231n.github.io/neural-networks-1/">1</a>, <a href="https://cs231n.github.io/neural-networks-2/">2</a>, <a href="https://cs231n.github.io/neural-networks-3/">3</a></td>
    </tr>
    <tr>
      <td>03/10</td>
      <td>SPRING BREAK   – NO CLASS</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>03/12</td>
      <td>SPRING BREAK   – NO CLASS</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>03/17</td>
      <td>Unsupervised representation learning: autoencoders, factorization, and sparse Coding</td>
      <td><a href="/teach/DL-Spring-2020/lecture-03-17-slides.pdf">Slides</a>  <a href="/teach/DL-Spring-2020/lecture-03-17-handout.pdf">Handout</a></td>
      <td><a href="https://arxiv.org/abs/1206.5538">Representation learning review</a>      ,               DL Chs 13–15</td>
    </tr>
    <tr>
      <td>03/19</td>
      <td>From fully connected to convolutional neural networks</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>03/24</td>
      <td>Convolutional neural networks: basic models and computation</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>03/26</td>
      <td>Convolutional neural networks: advanced models and applications</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>03/31</td>
      <td><strong>Project progress presentation</strong></td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>04/02</td>
      <td><strong>Project progress presentation</strong></td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>04/07</td>
      <td><strong>Project progress presentation</strong></td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>04/09</td>
      <td>Sequential 1</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>04/14</td>
      <td>Sequential 2</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>04/16</td>
      <td>Sequential 3</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>04/21</td>
      <td>Generative models 1</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>04/23</td>
      <td>Generative models 2</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>04/28</td>
      <td>Reinforcement learning 1</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>04/30</td>
      <td>Reinforcement learning 2</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>05/05</td>
      <td>Scattering transform</td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h4 id="homework-assignments">Homework assignments</h4>
<ul>
  <li><a href="/teach/DL-Spring-2020/HW0.pdf">Assignment 0</a> (Due: Feb 07)</li>
  <li><a href="/teach/DL-Spring-2020/HW1.pdf">Assignment 1</a> (Due: Mar 15)</li>
  <li><a href="/teach/DL-Spring-2020/HW2.pdf">Assignment 2</a> (Due: Apr 18)</li>
  <li><a href="/teach/DL-Spring-2020/HW3.pdf">Assignment 3</a> (Due: May 02)</li>
  <li><a href="/teach/DL-Spring-2020/HW4.pdf">Assignment 4</a> (Due: May 14)</li>
</ul>

<h4 id="course-project">Course project</h4>
<ul>
  <li><a href="/teach/DL-Spring-2020/lecture-02-06-slides.pdf">Project description</a></li>
</ul>

<!-- #### Tentative topics to cover: -->

  </article>

<!--  -->

<!--  -->

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2026 Ju Sun.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

    
  </div>

</footer>


    <!--load Ubuntu webfont -->

<link href='http://fonts.googleapis.com/css?family=Ubuntu|Ubuntu+Condensed|Ubuntu+Mono' rel='stylesheet' type='text/css'>

<!-- mathjax config-->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'], ['\\(','\\)']],
    displayMath: [ ['$$', '$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true, 
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
    TeX: { equationNumbers: { autoNumber: "AMS", useLabelIds: true } }, 
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>





<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
