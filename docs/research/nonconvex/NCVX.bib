% Encoding: UTF-8

@Article{ChenChi2018Harnessing,
  author  = {Yudong Chen and Yuejie Chi},
  title   = {Harnessing Structures in Big Data via Guaranteed Low-Rank Matrix Estimation},
  journal = {arxiv:1802.08397},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.08397},
}

@Article{JainEtAl2017Non,
  author    = {Jain, Prateek and Kar, Purushottam and others},
  title     = {Non-convex optimization for machine learning},
  journal   = {Foundations and Trends{\textregistered} in Machine Learning},
  year      = {2017},
  volume    = {10},
  number    = {3-4},
  pages     = {142--336},
  publisher = {Now Publishers, Inc.},
}

@Article{AhmedEtAl2012Blind,
  author  = {Ali Ahmed and Benjamin Recht and Justin Romberg},
  title   = {Blind Deconvolution using Convex Programming},
  journal = {arxiv:1211.5608},
  year    = {2012},
  url     = {http://arxiv.org/abs/1211.5608},
}

@Article{GeZou2015Intersecting,
  author  = {Rong Ge and James Zou},
  title   = {Intersecting Faces: Non-negative Matrix Factorization With New Guarantees},
  journal = {arxiv:1507.02189},
  year    = {2015},
  url     = {http://arxiv.org/abs/1507.02189},
}

@Article{Gillis2014Why,
  author  = {Nicolas Gillis},
  title   = {The Why and How of Nonnegative Matrix Factorization},
  journal = {arxiv:1401.5226},
  year    = {2014},
  url     = {http://arxiv.org/abs/1401.5226},
}

@InProceedings{AroraEtAl2012Computing,
  author       = {Arora, Sanjeev and Ge, Rong and Kannan, Ravindran and Moitra, Ankur},
  title        = {Computing a nonnegative matrix factorization--provably},
  booktitle    = {Proceedings of the forty-fourth annual ACM symposium on Theory of computing},
  year         = {2012},
  pages        = {145--162},
  organization = {ACM},
}

@Article{LiEtAl2018Nonconvex,
  author  = {Yuanxin Li and Cong Ma and Yuxin Chen and Yuejie Chi},
  title   = {Nonconvex Matrix Factorization from Rank-One Measurements},
  journal = {arxiv:1802.06286},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.06286},
}

@Article{LiEtAl2017Algorithmic,
  author  = {Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang},
  title   = {Algorithmic Regularization in Over-parameterized Matrix Recovery},
  journal = {arXiv:1712.09203},
  year    = {2017},
}

@Article{CaiEtAl2017Accelerated,
  author  = {HanQin Cai and Jian-Feng Cai and Ke Wei},
  title   = {Accelerated Alternating Projections for Robust Principal Component Analysis},
  journal = {arxiv:1711.05519},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.05519},
}

@Article{KyrillidisEtAl2017Provable,
  author  = {Anastasios Kyrillidis and Amir Kalev and Dohuyng Park and Srinadh Bhojanapalli and Constantine Caramanis and Sujay Sanghavi},
  title   = {Provable quantum state tomography via non-convex methods},
  journal = {arxiv:1711.02524},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.02524},
}

@Article{ChenLi2017Memory,
  author  = {Ji Chen and Xiaodong Li},
  title   = {Memory-efficient Kernel PCA via Partial Matrix Sampling and Nonconvex Optimization: a Model-free Analysis of Local Minima},
  journal = {arxiv:1711.01742},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.01742},
}

@Article{LiEtAl2017Nonconvex,
  author  = {Yuanxin Li and Yuejie Chi and Huishuai Zhang and Yingbin Liang},
  title   = {Nonconvex Low-Rank Matrix Recovery with Arbitrary Outliers via Median-Truncated Gradient Descent},
  journal = {arxiv:1709.08114},
  year    = {2017},
  url     = {http://arxiv.org/abs/1709.08114},
}

@Article{ZhangYang2017Robust,
  author  = {Zhang, Teng and Yang, Yi},
  title   = {Robust Principal Component Analysis by Manifold Optimization},
  journal = {arXiv:1708.00257},
  year    = {2017},
}

@Article{CaiEtAl2017Spectral,
  author  = {Jian-Feng Cai and Tianming Wang and Ke Wei},
  title   = {Spectral Compressed Sensing via Projected Gradient Descent},
  journal = {arxiv:1707.09726},
  year    = {2017},
  url     = {http://arxiv.org/abs/1707.09726},
}

@Article{CilibertoEtAl2017Reexamining,
  author  = {Carlo Ciliberto and Dimitris Stamos and Massimiliano Pontil},
  title   = {Reexamining Low Rank Matrix Factorization for Trace Norm Regularization},
  journal = {arxiv:1706.08934},
  year    = {2017},
  url     = {http://arxiv.org/abs/1706.08934},
}

@Article{MaunuEtAl2017Well,
  author  = {Tyler Maunu and Teng Zhang and Gilad Lerman},
  title   = {A Well-Tempered Landscape for Non-convex Robust Subspace Recovery},
  journal = {arxiv:1706.03896},
  year    = {2017},
  url     = {http://arxiv.org/abs/1706.03896},
}

@Article{BalcanEtAl2017Optimal,
  author  = {Balcan, Maria-Florina and Liang, Yingyu and Woodruff, David P and Zhang, Hongyang},
  title   = {Optimal Sample Complexity for Matrix Completion and Related Problems via $\ell_2$-Regularization},
  journal = {arXiv:1704.08683},
  year    = {2017},
}

@Article{LiEtAl2017Geometry,
  author  = {Qiuwei Li and Zhihui Zhu and Gongguo Tang},
  title   = {Geometry of Factored Nuclear Norm Regularization},
  journal = {arxiv:1704.01265},
  year    = {2017},
  url     = {http://arxiv.org/abs/1704.01265},
}

@Article{GeEtAl2017No,
  author  = {Rong Ge and Chi Jin and Yi Zheng},
  title   = {No Spurious Local Minima in Nonconvex Low Rank Problems: A Unified Geometric Analysis},
  journal = {arxiv:1704.00708},
  year    = {2017},
  url     = {http://arxiv.org/abs/1704.00708},
}

@Article{StrohmerWei2017Painless,
  author    = {Strohmer, Thomas and Wei, Ke},
  title     = {Painless Breakups---Efficient Demixing of Low Rank Matrices},
  journal   = {Journal of Fourier Analysis and Applications},
  year      = {2017},
  pages     = {1--31},
  publisher = {Springer},
}

@Article{XuEtAl2017Speeding,
  author  = {Pan Xu and Jian Ma and Quanquan Gu},
  title   = {Speeding Up Latent Variable Gaussian Graphical Model Estimation via Nonconvex Optimizations},
  journal = {arxiv:1702.08651},
  year    = {2017},
  url     = {http://arxiv.org/abs/1702.08651},
}

@Article{ZhuEtAl2017Global,
  author  = {Zhihui Zhu and Qiuwei Li and Gongguo Tang and Michael B. Wakin},
  title   = {Global Optimality in Low-rank Matrix Optimization},
  journal = {arxiv:1702.07945},
  year    = {2017},
  url     = {http://arxiv.org/abs/1702.07945},
}

@Article{ZhangEtAl2017nonconvex,
  author  = {Zhang, Xiao and Wang, Lingxiao and Gu, Quanquan},
  title   = {A nonconvex free lunch for low-rank plus sparse matrix recovery},
  journal = {arXiv:1702.06525},
  year    = {2017},
}

@Article{LiEtAl2016Symmetry,
  author  = {Xingguo Li and Junwei Lu and Raman Arora and Jarvis Haupt and Han Liu and Zhaoran Wang and Tuo Zhao},
  title   = {Symmetry, Saddle Points, and Global Optimization Landscape of Nonconvex Matrix Factorization},
  journal = {arxiv:1612.09296},
  year    = {2016},
  url     = {http://arxiv.org/abs/1612.09296},
}

@Article{ParkEtAl2016Non,
  author  = {Dohyung Park and Anastasios Kyrillidis and Constantine Caramanis and Sujay Sanghavi},
  title   = {Non-square matrix sensing without spurious local minima via the Burer-Monteiro approach},
  journal = {arxiv:1609.03240},
  year    = {2016},
  url     = {http://arxiv.org/abs/1609.03240},
}

@Article{CherapanamjeriEtAl2016Nearly,
  author  = {Yeshwanth Cherapanamjeri and Kartik Gupta and Prateek Jain},
  title   = {Nearly-optimal Robust Matrix Completion},
  journal = {arxiv:1606.07315},
  year    = {2016},
  url     = {http://arxiv.org/abs/1606.07315},
}

@Article{ParkEtAl2016Provable,
  author  = {Dohyung Park and Anastasios Kyrillidis and Srinadh Bhojanapalli and Constantine Caramanis and Sujay Sanghavi},
  title   = {Provable Burer-Monteiro factorization for a class of norm-constrained matrix problems},
  journal = {arxiv:1606.01316},
  year    = {2016},
  url     = {http://arxiv.org/abs/1606.01316},
}

@Article{ParkEtAl2016Finding,
  author  = {Dohyung Park and Anastasios Kyrillidis and Constantine Caramanis and Sujay Sanghavi},
  title   = {Finding Low-Rank Solutions via Non-Convex Matrix Factorization, Efficiently and Provably},
  journal = {arxiv:1606.03168},
  year    = {2016},
  url     = {http://arxiv.org/abs/1606.03168},
}

@Article{JinEtAl2016Provable,
  author  = {Chi Jin and Sham M. Kakade and Praneeth Netrapalli},
  title   = {Provable Efficient Online Matrix Completion via Non-convex Stochastic Gradient Descent},
  journal = {arxiv:1605.08370},
  year    = {2016},
  url     = {http://arxiv.org/abs/1605.08370},
}

@Article{YiEtAl2016Fast,
  author  = {Xinyang Yi and Dohyung Park and Yudong Chen and Constantine Caramanis},
  title   = {Fast Algorithms for Robust PCA via Gradient Descent},
  journal = {arxiv:1605.07784},
  year    = {2016},
  url     = {http://arxiv.org/abs/1605.07784},
}

@Article{ZhengLafferty2016Convergence,
  author  = {Qinqing Zheng and John Lafferty},
  title   = {Convergence Analysis for Rectangular Matrix Completion Using Burer-Monteiro Factorization and Gradient Descent},
  journal = {arxiv:1605.07051},
  year    = {2016},
  url     = {http://arxiv.org/abs/1605.07051},
}

@Article{GeEtAl2016Matrix,
  author  = {Rong Ge and Jason D. Lee and Tengyu Ma},
  title   = {Matrix Completion has No Spurious Local Minimum},
  journal = {arxiv:1605.07272},
  year    = {2016},
  url     = {http://arxiv.org/abs/1605.07272},
}

@Article{BhojanapalliEtAl2016Global,
  author  = {Srinadh Bhojanapalli and Behnam Neyshabur and Nathan Srebro},
  title   = {Global Optimality of Local Search for Low Rank Matrix Recovery},
  journal = {arxiv:1605.07221},
  year    = {2016},
  url     = {http://arxiv.org/abs/1605.07221},
}

@Article{WeiEtAl2016Guarantees,
  author  = {Ke Wei and Jian-Feng Cai and Tony F. Chan and Shingyu Leung},
  title   = {Guarantees of Riemannian Optimization for Low Rank Matrix Completion},
  journal = {arxiv:1603.06610},
  year    = {2016},
  url     = {http://arxiv.org/abs/1603.06610},
}

@Article{GamarnikMisra2016Note,
  author    = {David Gamarnik and Sidhant Misra},
  title     = {A Note on Alternating Minimization Algorithm for the Matrix Completion Problem},
  journal   = {{IEEE} Signal Processing Letters},
  year      = {2016},
  volume    = {23},
  number    = {10},
  pages     = {1340--1343},
  month     = {oct},
  doi       = {10.1109/lsp.2016.2576979},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {https://doi.org/10.1109%2Flsp.2016.2576979},
}

@Article{LiEtAl2016Recovery,
  author  = {Yuanzhi Li and Yingyu Liang and Andrej Risteski},
  title   = {Recovery guarantee of weighted low-rank approximation via alternating minimization},
  journal = {arxiv:1602.02262},
  year    = {2016},
  url     = {http://arxiv.org/abs/1602.02262},
}

@InProceedings{ZhongEtAl2015Efficient,
  author       = {Zhong, Kai and Jain, Prateek and Dhillon, Inderjit S},
  title        = {Efficient matrix sensing using rank-1 gaussian measurements},
  booktitle    = {International Conference on Algorithmic Learning Theory},
  year         = {2015},
  pages        = {3--18},
  organization = {Springer},
}

@Article{WeiEtAl2015Guarantees,
  author  = {Ke Wei and Jian-Feng Cai and Tony F. Chan and Shingyu Leung},
  title   = {Guarantees of Riemannian Optimization for Low Rank Matrix Recovery},
  journal = {arxiv:1511.01562v8},
  year    = {2015},
  url     = {http://arxiv.org/abs/1511.01562v8},
}

@Article{ChenWainwright2015Fast,
  author  = {Yudong Chen and Martin J. Wainwright},
  title   = {Fast low-rank estimation by projected gradient descent: General statistical and algorithmic guarantees},
  journal = {arxiv:1509.03025},
  year    = {2015},
  url     = {http://arxiv.org/abs/1509.03025},
}

@Article{TuEtAl2015Low,
  author  = {Stephen Tu and Ross Boczar and Max Simchowitz and Mahdi Soltanolkotabi and Benjamin Recht},
  title   = {Low-rank Solutions of Linear Matrix Equations via Procrustes Flow},
  journal = {arxiv:1507.03566},
  year    = {2015},
  url     = {http://arxiv.org/abs/1507.03566},
}

@Article{ZhengLafferty2015Convergent,
  author  = {Qinqing Zheng and John Lafferty},
  title   = {A Convergent Gradient Descent Algorithm for Rank Minimization and Semidefinite Programming from Random Linear Measurements},
  journal = {arxiv:1506.06081},
  year    = {2015},
  url     = {http://arxiv.org/abs/1506.06081},
}

@Article{SunLuo2016Guaranteed,
  author    = {Ruoyu Sun and Zhi-Quan Luo},
  title     = {Guaranteed Matrix Completion via Non-Convex Factorization},
  journal   = {{IEEE} Transactions on Information Theory},
  year      = {2016},
  volume    = {62},
  number    = {11},
  pages     = {6535--6579},
  month     = {nov},
  doi       = {10.1109/tit.2016.2598574},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {https://doi.org/10.1109%2Ftit.2016.2598574},
}

@Article{JainNetrapalli2014Fast,
  author  = {Prateek Jain and Praneeth Netrapalli},
  title   = {Fast Exact Matrix Completion with Finite Samples},
  journal = {arxiv:1411.1087},
  year    = {2014},
  url     = {http://arxiv.org/abs/1411.1087},
}

@InProceedings{NetrapalliEtAl2014Non,
  author    = {Netrapalli, Praneeth and Niranjan, UN and Sanghavi, Sujay and Anandkumar, Animashree and Jain, Prateek},
  title     = {Non-convex robust PCA},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2014},
  pages     = {1107--1115},
}

@Article{HardtWootters2014Fast,
  author  = {Moritz Hardt and Mary Wootters},
  title   = {Fast matrix completion without the condition number},
  journal = {arxiv:1407.4070},
  year    = {2014},
  url     = {http://arxiv.org/abs/1407.4070},
}

@Article{Hardt2013Understanding,
  author  = {Moritz Hardt},
  title   = {Understanding Alternating Minimization for Matrix Completion},
  journal = {arxiv:1312.0925},
  year    = {2013},
  url     = {http://arxiv.org/abs/1312.0925},
}

@Article{JainEtAl2012Low,
  author  = {Prateek Jain and Praneeth Netrapalli and Sujay Sanghavi},
  title   = {Low-rank Matrix Completion using Alternating Minimization},
  journal = {arxiv:1212.0467},
  year    = {2012},
  url     = {http://arxiv.org/abs/1212.0467},
}

@Article{KeshavanEtAl2009Matrix,
  author  = {Raghunandan H. Keshavan and Andrea Montanari and Sewoong Oh},
  title   = {Matrix Completion from a Few Entries},
  journal = {arxiv:0901.3150},
  year    = {2009},
  url     = {http://arxiv.org/abs/0901.3150},
}

@Article{MekaEtAl2009Guaranteed,
  author  = {Raghu Meka and Prateek Jain and Inderjit S. Dhillon},
  title   = {Guaranteed Rank Minimization via Singular Value Projection},
  journal = {arxiv:0909.5457},
  year    = {2009},
  url     = {http://arxiv.org/abs/0909.5457},
}

@Article{ArousEtAl2017landscape,
  author  = {Gerard Ben Arous and Song Mei and Andrea Montanari and Mihai Nica},
  title   = {The landscape of the spiked tensor model},
  journal = {arxiv:1711.05424},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.05424},
}

@Article{XiaEtAl2017Statistically,
  author  = {Dong Xia and Ming Yuan and Cun-Hui Zhang},
  title   = {Statistically Optimal and Computationally Efficient Low Rank Tensor Completion from Noisy Entries},
  journal = {arxiv:1711.04934},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.04934},
}

@Article{GeMa2017Optimization,
  author  = {Rong Ge and Tengyu Ma},
  title   = {On the Optimization Landscape of Tensor Decompositions},
  journal = {arxiv:1706.05598},
  year    = {2017},
  url     = {http://arxiv.org/abs/1706.05598},
}

@Article{SharanValiant2017Orthogonalized,
  author  = {Vatsal Sharan and Gregory Valiant},
  title   = {Orthogonalized ALS: A Theoretically Principled Tensor Decomposition Algorithm for Practical Use},
  journal = {arxiv:1703.01804},
  year    = {2017},
  url     = {http://arxiv.org/abs/1703.01804},
}

@Article{XiaYuan2017Polynomial,
  author  = {Dong Xia and Ming Yuan},
  title   = {On Polynomial Time Methods for Exact Low Rank Tensor Completion},
  journal = {arxiv:1702.06980},
  year    = {2017},
  url     = {http://arxiv.org/abs/1702.06980},
}

@Article{AnandkumarEtAl2016Homotopy,
  author  = {Anima Anandkumar and Yuan Deng and Rong Ge and Hossein Mobahi},
  title   = {Homotopy Analysis for Tensor PCA},
  journal = {arxiv:1610.09322},
  year    = {2016},
  url     = {http://arxiv.org/abs/1610.09322},
}

@InProceedings{LiuEtAl2016Low,
  author    = {Xiao-Yang Liu and Shuchin Aeron and Vaneet Aggarwal and Xiaodong Wang},
  title     = {Low-tubal-rank tensor completion using alternating minimization},
  booktitle = {Modeling and Simulation for Defense Systems and Applications {XI}},
  year      = {2016},
  editor    = {Susan Harkrider and Aaron L. Paolini},
  month     = {may},
  publisher = {{SPIE}},
  doi       = {10.1117/12.2224039},
  url       = {https://doi.org/10.1117%2F12.2224039},
}

@Article{HopkinsEtAl2015Speeding,
  author  = {Hopkins, Samuel B and Schramm, Tselil and Shi, Jonathan and Steurer, David},
  title   = {Speeding up sum-of-squares for tensor decomposition and planted sparse vectors},
  journal = {arXiv:1512.02337},
  year    = {2015},
}

@Article{AnandkumarEtAl2015Tensor,
  author  = {Animashree Anandkumar and Prateek Jain and Yang Shi and U. N. Niranjan},
  title   = {Tensor vs Matrix Methods: Robust Tensor Decomposition under Block Sparse Perturbations},
  journal = {arxiv:1510.04747},
  year    = {2015},
  url     = {http://arxiv.org/abs/1510.04747},
}

@Article{AnandkumarEtAl2014Analyzing,
  author  = {Anima Anandkumar and Rong Ge and Majid Janzamin},
  title   = {Analyzing Tensor Power Method Dynamics in Overcomplete Regime},
  journal = {arxiv:1411.1488},
  year    = {2014},
  url     = {http://arxiv.org/abs/1411.1488},
}

@Article{AnandkumarEtAl2012Tensor,
  author  = {Anima Anandkumar and Rong Ge and Daniel Hsu and Sham M. Kakade and Matus Telgarsky},
  title   = {Tensor decompositions for learning latent variable models},
  journal = {arxiv:1210.7559},
  year    = {2012},
  url     = {http://arxiv.org/abs/1210.7559},
}

@Article{AnandkumarEtAl2014Provable,
  author    = {Anandkumar, Animashree and Ge, Rong and Janzamin, Majid},
  title     = {Provable learning of overcomplete latent variable models: Semi-supervised and unsupervised settings},
  journal   = {arXiv:1408.0553},
  year      = {2014},
  publisher = {Citeseer},
}

@Article{JainOh2014Provable,
  author  = {Prateek Jain and Sewoong Oh},
  title   = {Provable Tensor Factorization with Missing Data},
  journal = {arxiv:1406.2784},
  year    = {2014},
  url     = {http://arxiv.org/abs/1406.2784},
}

@Article{AnandkumarEtAl2014Guaranteed,
  author  = {Animashree Anandkumar and Rong Ge and Majid Janzamin},
  title   = {Guaranteed Non-Orthogonal Tensor Decomposition via Alternating Rank-$1$ Updates},
  journal = {arxiv:1402.5180},
  year    = {2014},
  url     = {http://arxiv.org/abs/1402.5180},
}

@Article{MaEtAl2018Optimization,
  author  = {Junjie Ma and Ji Xu and Arian Maleki},
  title   = {Optimization-based AMP for Phase Retrieval: The Impact of Initialization and $\ell_2$-regularization},
  journal = {arxiv:1801.01170},
  year    = {2018},
  url     = {http://arxiv.org/abs/1801.01170},
}

@Article{BakhshizadehEtAl2017Compressive,
  author  = {Milad Bakhshizadeh and Arian Maleki and Shirin Jalali},
  title   = {Compressive Phase Retrieval of Structured Signal},
  journal = {arxiv:1712.03278},
  year    = {2017},
  url     = {http://arxiv.org/abs/1712.03278},
}

@Article{YangEtAl2017Misspecified,
  author  = {Zhuoran Yang and Lin F. Yang and Ethan X. Fang and Tuo Zhao and Zhaoran Wang and Matey Neykov},
  title   = {Misspecified Nonconvex Statistical Optimization for Phase Retrieval},
  journal = {arxiv:1712.06245},
  year    = {2017},
  url     = {http://arxiv.org/abs/1712.06245},
}

@Article{ZhangEtAl2017Compressive,
  author  = {Liang Zhang and Gang Wang and Georgios B. Giannakis and Jie Chen},
  title   = {Compressive Phase Retrieval via Reweighted Amplitude Flow},
  journal = {arxiv:1712.02426},
  year    = {2017},
  url     = {http://arxiv.org/abs/1712.02426},
}

@Article{BarmherzigSun2017Local,
  author  = {David Barmherzig and Ju Sun},
  title   = {A Local Analysis of Block Coordinate Descent for Gaussian Phase Retrieval},
  journal = {arxiv:1712.02083},
  year    = {2017},
  url     = {http://arxiv.org/abs/1712.02083},
}

@Article{QuEtAl2017Convolutional,
  author  = {Qing Qu and Yuqian Zhang and Yonina C. Eldar and John Wright},
  title   = {Convolutional Phase Retrieval via Gradient Descent},
  journal = {arxiv:1712.00716},
  year    = {2017},
  url     = {http://arxiv.org/abs/1712.00716},
}

@Article{LiEtAl2017Linear,
  author  = {Gen Li and Yuchen Jiao and Yuantao Gu},
  title   = {Linear Convergence of An Iterative Phase Retrieval Algorithm with Data Reuse},
  journal = {arxiv:1712.01712},
  year    = {2017},
  url     = {http://arxiv.org/abs/1712.01712},
}

@Article{DavisEtAl2017nonsmooth,
  author  = {Damek Davis and Dmitriy Drusvyatskiy and Courtney Paquette},
  title   = {The nonsmooth landscape of phase retrieval},
  journal = {arxiv:1711.03247},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.03247},
}

@Article{DhifallahEtAl2017Phase,
  author  = {Oussama Dhifallah and Christos Thrampoulidis and Yue M. Lu},
  title   = {Phase Retrieval via Linear Programming: Fundamental Limits and Algorithmic Improvements},
  journal = {arxiv:1710.05234},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.05234},
}

@Article{JeongGuentuerk2017Convergence,
  author  = {Halyun Jeong and C. Sinan Güntürk},
  title   = {Convergence of the randomized Kaczmarz method for phase retrieval},
  journal = {arxiv:1706.10291},
  year    = {2017},
  url     = {http://arxiv.org/abs/1706.10291},
}

@Article{TanVershynin2017Phase,
  author  = {Yan Shuo Tan and Roman Vershynin},
  title   = {Phase Retrieval via Randomized Kaczmarz: Theoretical Guarantees},
  journal = {arxiv:1706.09993},
  year    = {2017},
  url     = {http://arxiv.org/abs/1706.09993},
}

@Article{Zhang2017Phase,
  author  = {Teng Zhang},
  title   = {Phase retrieval using alternating minimization in a batch setting},
  journal = {arxiv:1706.08167},
  year    = {2017},
  url     = {http://arxiv.org/abs/1706.08167},
}

@Article{WangEtAl2017Solving,
  author  = {Gang Wang and Georgios B. Giannakis and Yousef Saad and Jie Chen},
  title   = {Solving Almost all Systems of Random Quadratic Equations},
  journal = {arxiv:1705.10407},
  year    = {2017},
  url     = {http://arxiv.org/abs/1705.10407},
}

@Article{JagatapHegde2017Phase,
  author  = {Jagatap, Gauri and Hegde, Chinmay},
  title   = {Phase retrieval using structured sparsity: A sample efficient algorithmic framework},
  journal = { arXiv:1705.06412},
  year    = {2017},
}

@Article{DuchiRuan2017Solving,
  author  = {John C. Duchi and Feng Ruan},
  title   = {Solving (most) of a set of quadratic equalities: Composite optimization for robust phase retrieval},
  journal = {arxiv:1705.02356},
  year    = {2017},
  url     = {http://arxiv.org/abs/1705.02356},
}

@Article{ChenEtAl2017Robust,
  author  = {Jinghui Chen and Lingxiao Wang and Xiao Zhang and Quanquan Gu},
  title   = {Robust Wirtinger Flow for Phase Retrieval with Arbitrary Corruption},
  journal = {arxiv:1704.06256},
  year    = {2017},
  url     = {http://arxiv.org/abs/1704.06256},
}

@Article{YuanEtAl2017Phase,
  author  = {Ziyang Yuan and Qi Wang and Hongxia Wang},
  title   = {Phase Retrieval via Sparse Wirtinger Flow},
  journal = {arxiv:1704.03286},
  year    = {2017},
  url     = {http://arxiv.org/abs/1704.03286},
}

@Article{Soltanolkotabi2017Structured,
  author  = {Mahdi Soltanolkotabi},
  title   = {Structured signal recovery from quadratic measurements: Breaking sample complexity barriers via nonconvex optimization},
  journal = {arxiv:1702.06175},
  year    = {2017},
  url     = {http://arxiv.org/abs/1702.06175},
}

@Article{WangEtAl2016Sparse,
  author  = {Gang Wang and Liang Zhang and Georgios B. Giannakis and Mehmet Akcakaya and Jie Chen},
  title   = {Sparse Phase Retrieval via Truncated Amplitude Flow},
  journal = {arxiv:1611.07641},
  year    = {2016},
  url     = {http://arxiv.org/abs/1611.07641},
}

@Article{WangEtAl2017Scalable,
  author    = {Gang Wang and Georgios B. Giannakis and Jie Chen},
  title     = {Scalable Solvers of Random Quadratic Equations via Stochastic Truncated Amplitude Flow},
  journal   = {{IEEE} Transactions on Signal Processing},
  year      = {2017},
  volume    = {65},
  number    = {8},
  pages     = {1961--1974},
  month     = {apr},
  doi       = {10.1109/tsp.2017.2652392},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {https://doi.org/10.1109%2Ftsp.2017.2652392},
}

@Article{VaswaniEtAl2017Low,
  author    = {Namrata Vaswani and Seyedehsara Nayer and Yonina C. Eldar},
  title     = {Low-Rank Phase Retrieval},
  journal   = {{IEEE} Transactions on Signal Processing},
  year      = {2017},
  volume    = {65},
  number    = {15},
  pages     = {4059--4074},
  month     = {aug},
  doi       = {10.1109/tsp.2017.2684758},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {https://doi.org/10.1109%2Ftsp.2017.2684758},
}

@Article{Waldspurger2016Phase,
  author  = {Irène Waldspurger},
  title   = {Phase retrieval with random Gaussian sensing vectors by alternating projections},
  journal = {arxiv:1612.04330},
  year    = {2016},
  url     = {http://arxiv.org/abs/1612.04330},
}

@Article{BendoryEtAl2016Non,
  author  = {Tamir Bendory and Yonina C. Eldar and Nicolas Boumal},
  title   = {Non-Convex Phase Retrieval from STFT Measurements},
  journal = {arxiv:1607.08218},
  year    = {2016},
  url     = {http://arxiv.org/abs/1607.08218},
}

@Article{GaoXu2016Gauss,
  author  = {Gao, Bing and Xu, Zhiqiang},
  title   = {Gauss-newton method for phase retrieval},
  journal = {arXiv:1606.08135},
  year    = {2016},
}

@Article{KolteOezguer2016Phase,
  author  = {Ritesh Kolte and Ayfer Özgür},
  title   = {Phase Retrieval via Incremental Truncated Wirtinger Flow},
  journal = {arxiv:1606.03196},
  year    = {2016},
  url     = {http://arxiv.org/abs/1606.03196},
}

@Article{WangEtAl2016Solving,
  author  = {Gang Wang and Georgios B. Giannakis and Yonina C. Eldar},
  title   = {Solving Systems of Random Quadratic Equations via Truncated Amplitude Flow},
  journal = {arxiv:1605.08285},
  year    = {2016},
  url     = {http://arxiv.org/abs/1605.08285},
}

@Article{ZhangEtAl2016Reshaped,
  author  = {Huishuai Zhang and Yi Zhou and Yingbin Liang and Yuejie Chi},
  title   = {Reshaped Wirtinger Flow and Incremental Algorithm for Solving Quadratic System of Equations},
  journal = {arxiv:1605.07719},
  year    = {2016},
  url     = {http://arxiv.org/abs/1605.07719},
}

@InProceedings{ZhangEtAl2016Provable,
  author    = {Zhang, Huishuai and Chi, Yuejie and Liang, Yingbin},
  title     = {Provable non-convex phase retrieval with outliers: Median truncatedwirtinger flow},
  booktitle = {International conference on machine learning},
  year      = {2016},
  pages     = {1022--1031},
}

@Article{SunEtAl2017Geometric,
  author    = {Ju Sun and Qing Qu and John Wright},
  title     = {A Geometric Analysis of Phase Retrieval},
  journal   = {Foundations of Computational Mathematics},
  year      = {2017},
  month     = {aug},
  doi       = {10.1007/s10208-017-9365-9},
  publisher = {Springer Nature},
  url       = {https://doi.org/10.1007%2Fs10208-017-9365-9},
}

@Article{Waldspurger2015Phase,
  author  = {Irène Waldspurger},
  title   = {Phase retrieval for wavelet transforms},
  journal = {arxiv:1512.07024},
  year    = {2015},
  url     = {http://arxiv.org/abs/1512.07024},
}

@Article{WhiteEtAl2015local,
  author  = {Chris D. White and Sujay Sanghavi and Rachel Ward},
  title   = {The local convexity of solving systems of quadratic equations},
  journal = {arxiv:1506.07868},
  year    = {2015},
  url     = {http://arxiv.org/abs/1506.07868},
}

@Article{Wei2015Solving,
  author  = {Ke Wei},
  title   = {Solving systems of phaseless equations via Kaczmarz methods: A proof of concept study},
  journal = {arxiv:1502.01822},
  year    = {2015},
  url     = {http://arxiv.org/abs/1502.01822},
}

@Article{ChenCandes2015Solving,
  author  = {Yuxin Chen and Emmanuel J. Candes},
  title   = {Solving Random Quadratic Systems of Equations Is Nearly as Easy as Solving Linear Systems},
  journal = {arxiv:1505.05114},
  year    = {2015},
  url     = {http://arxiv.org/abs/1505.05114},
}

@Article{CandesEtAl2015Phase,
  author    = {Emmanuel J. Candes and Xiaodong Li and Mahdi Soltanolkotabi},
  title     = {Phase Retrieval via Wirtinger Flow: Theory and Algorithms},
  journal   = {{IEEE} Transactions on Information Theory},
  year      = {2015},
  volume    = {61},
  number    = {4},
  pages     = {1985--2007},
  month     = {apr},
  doi       = {10.1109/tit.2015.2399924},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {https://doi.org/10.1109%2Ftit.2015.2399924},
}

@Article{NetrapalliEtAl2013Phase,
  author  = {Praneeth Netrapalli and Prateek Jain and Sujay Sanghavi},
  title   = {Phase Retrieval using Alternating Minimization},
  journal = {arxiv:1306.0160},
  year    = {2013},
  url     = {http://arxiv.org/abs/1306.0160},
}

@Article{NguyenEtAl2017provable,
  author  = {Nguyen, Thanh and Wong, Raymond KW and Hegde, Chinmay},
  title   = {A provable approach for double-sparse coding},
  journal = { arXiv:1711.03638},
  year    = {2017},
}

@Article{ChatterjiBartlett2017Alternating,
  author  = {Niladri S. Chatterji and Peter L. Bartlett},
  title   = {Alternating minimization for dictionary learning with random initialization},
  journal = {arxiv:1711.03634},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.03634},
}

@Article{SunEtAl2015Complete,
  author  = {Ju Sun and Qing Qu and John Wright},
  title   = {Complete Dictionary Recovery over the Sphere},
  journal = {arxiv:1504.06785},
  year    = {2015},
  url     = {http://arxiv.org/abs/1504.06785},
}

@Article{AroraEtAl2015Simple,
  author  = {Sanjeev Arora and Rong Ge and Tengyu Ma and Ankur Moitra},
  title   = {Simple, Efficient, and Neural Algorithms for Sparse Coding},
  journal = {arxiv:1503.00778},
  year    = {2015},
  url     = {http://arxiv.org/abs/1503.00778},
}

@Article{AroraEtAl2014More,
  author  = {Sanjeev Arora and Aditya Bhaskara and Rong Ge and Tengyu Ma},
  title   = {More Algorithms for Provable Dictionary Learning},
  journal = {arxiv:1401.0579},
  year    = {2014},
  url     = {http://arxiv.org/abs/1401.0579},
}

@Article{AgarwalEtAl2013Exact,
  author  = {Agarwal, Alekh and Anandkumar, Animashree and Netrapalli, Praneeth},
  title   = {Exact recovery of sparsely used overcomplete dictionaries},
  journal = {arXiv:1310.7991},
  year    = {2013},
  volume  = {1050},
  pages   = {8--39},
}

@Article{AroraEtAl2013New,
  author  = {Sanjeev Arora and Rong Ge and Ankur Moitra},
  title   = {New Algorithms for Learning Incoherent and Overcomplete Dictionaries},
  journal = {arxiv:1308.6273},
  year    = {2013},
  url     = {http://arxiv.org/abs/1308.6273},
}

@Article{AgarwalEtAl2013Learning,
  author  = {Alekh Agarwal and Animashree Anandkumar and Prateek Jain and Praneeth Netrapalli},
  title   = {Learning Sparsely Used Overcomplete Dictionaries via Alternating Minimization},
  journal = {arxiv:1310.7991},
  year    = {2013},
  url     = {http://arxiv.org/abs/1310.7991},
}

@Article{LiangEtAl2018Understanding,
  author  = {Shiyu Liang and Ruoyu Sun and Yixuan Li and R. Srikant},
  title   = {Understanding the Loss Surface of Neural Networks for Binary Classification},
  journal = {arxiv:1803.00909},
  year    = {2018},
  url     = {http://arxiv.org/abs/1803.00909},
}

@Article{BartlettEtAl2018Gradient,
  author  = {Peter L. Bartlett and David P. Helmbold and Philip M. Long},
  title   = {Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks},
  journal = {arxiv:1802.06093},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.06093},
}

@Article{LaurentBrecht2017Deep,
  author  = {Thomas Laurent and James von Brecht},
  title   = {Deep linear neural networks with arbitrary loss: All local minima are global},
  journal = {arxiv:1712.01473},
  year    = {2017},
  url     = {http://arxiv.org/abs/1712.01473},
}

@Article{YunEtAl2017Global,
  author  = {Chulhee Yun and Suvrit Sra and Ali Jadbabaie},
  title   = {Global optimality conditions for deep neural networks},
  journal = {arxiv:1707.02444},
  year    = {2017},
  url     = {http://arxiv.org/abs/1707.02444},
}

@Article{LuKawaguchi2017Depth,
  author  = {Haihao Lu and Kenji Kawaguchi},
  title   = {Depth Creates No Bad Local Minima},
  journal = {arxiv:1702.08580},
  year    = {2017},
  url     = {http://arxiv.org/abs/1702.08580},
}

@Article{ZhangEtAl2017Electron,
  author  = {Zhang, Qiuyi and Panigrahy, Rina and Sachdeva, Sushant and Rahimi, Ali},
  title   = {Electron-proton dynamics in deep learning},
  journal = { arXiv:1702.00458},
  year    = {2017},
}

@Article{Kawaguchi2016Deep,
  author  = {Kenji Kawaguchi},
  title   = {Deep Learning without Poor Local Minima},
  journal = {arxiv:1605.07110},
  year    = {2016},
  url     = {http://arxiv.org/abs/1605.07110},
}

@Article{SoudryCarmon2016No,
  author  = {Daniel Soudry and Yair Carmon},
  title   = {No bad local minima: Data independent training error guarantees for multilayer neural networks},
  journal = {arxiv:1605.08361},
  year    = {2016},
  url     = {http://arxiv.org/abs/1605.08361},
}

@Article{LiEtAl2016Recoverya,
  author  = {Yuanzhi Li and Yingyu Liang and Andrej Risteski},
  title   = {Recovery Guarantee of Non-negative Matrix Factorization via Alternating Updates},
  journal = {arxiv:1611.03819},
  year    = {2016},
  url     = {http://arxiv.org/abs/1611.03819},
}

@Article{MontanariRichard2014Non,
  author  = {Andrea Montanari and Emile Richard},
  title   = {Non-negative Principal Component Analysis: Message Passing Algorithms and Sharp Asymptotics},
  journal = {arxiv:1406.4775},
  year    = {2014},
  url     = {http://arxiv.org/abs/1406.4775},
}

@Article{YiEtAl2016Solving,
  author  = {Xinyang Yi and Constantine Caramanis and Sujay Sanghavi},
  title   = {Solving a Mixture of Many Random Linear Equations by Tensor Decomposition and Alternating Minimization},
  journal = {arxiv:1608.05749},
  year    = {2016},
  url     = {http://arxiv.org/abs/1608.05749},
}

@Article{SedghiEtAl2014Provable,
  author  = {Hanie Sedghi and Majid Janzamin and Anima Anandkumar},
  title   = {Provable Tensor Methods for Learning Mixtures of Generalized Linear Models},
  journal = {arxiv:1412.3046},
  year    = {2014},
  url     = {http://arxiv.org/abs/1412.3046},
}

@Article{YiEtAl2013Alternating,
  author  = {Xinyang Yi and Constantine Caramanis and Sujay Sanghavi},
  title   = {Alternating Minimization for Mixed Linear Regression},
  journal = {arxiv:1310.3745},
  year    = {2013},
  url     = {http://arxiv.org/abs/1310.3745},
}

@Article{LiEtAl2017Blind,
  author  = {Yanjun Li and Kiryung Lee and Yoram Bresler},
  title   = {Blind Gain and Phase Calibration via Sparse Spectral Methods},
  journal = {arxiv:1712.00111},
  year    = {2017},
  url     = {http://arxiv.org/abs/1712.00111},
}

@Article{HuangHand2017Blind,
  author  = {Wen Huang and Paul Hand},
  title   = {Blind Deconvolution by a Steepest Descent Algorithm on a Quotient Manifold},
  journal = {arxiv:1710.03309},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.03309},
}

@Article{LingStrohmer2017Regularized,
  author  = {Shuyang Ling and Thomas Strohmer},
  title   = {Regularized Gradient Descent: A Nonconvex Recipe for Fast Joint Blind Deconvolution and Demixing},
  journal = {arxiv:1703.08642},
  year    = {2017},
  url     = {http://arxiv.org/abs/1703.08642},
}

@Article{LingStrohmer2016Self,
  author  = {Ling, Shuyang and Strohmer, Thomas},
  title   = {Self-calibration via linear least squares},
  journal = {arXiv:1611.04196},
  year    = {2016},
}

@Article{CambareriJacques2016Haze:,
  author  = {Valerio Cambareri and Laurent Jacques},
  title   = {Through the Haze: a Non-Convex Approach to Blind Gain Calibration for Linear Random Sensing Models},
  journal = {arxiv:1610.09028},
  year    = {2016},
  url     = {http://arxiv.org/abs/1610.09028},
}

@Article{LeeEtAl2016Fast,
  author  = {Kiryung Lee and Ning Tian and Justin Romberg},
  title   = {Fast and guaranteed blind multichannel deconvolution under a bilinear system model},
  journal = {arxiv:1610.06469},
  year    = {2016},
  url     = {http://arxiv.org/abs/1610.06469},
}

@Article{LiEtAl2016Rapid,
  author  = {Xiaodong Li and Shuyang Ling and Thomas Strohmer and Ke Wei},
  title   = {Rapid, Robust, and Reliable Blind Deconvolution via Nonconvex Optimization},
  journal = {arxiv:1606.04933},
  year    = {2016},
  url     = {http://arxiv.org/abs/1606.04933},
}

@InProceedings{CambareriJacques2016non,
  author    = {Valerio Cambareri and Laurent Jacques},
  title     = {A non-convex blind calibration method for randomised sensing strategies},
  booktitle = {2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing ({CoSeRa})},
  year      = {2016},
  month     = {sep},
  publisher = {{IEEE}},
  doi       = {10.1109/cosera.2016.7745690},
  url       = {https://doi.org/10.1109%2Fcosera.2016.7745690},
}

@Article{LeeJunge2015RIP,
  author  = {Kiryung Lee and Marius Junge},
  title   = {RIP-like Properties in Subsampled Blind Deconvolution},
  journal = {arxiv:1511.06146},
  year    = {2015},
  url     = {http://arxiv.org/abs/1511.06146},
}

@Article{LeeEtAl2015Blind,
  author  = {Kiryung Lee and Yanjun Li and Marius Junge and Yoram Bresler},
  title   = {Blind Recovery of Sparse Signals from Subsampled Convolution},
  journal = {arxiv:1511.06149},
  year    = {2015},
  url     = {http://arxiv.org/abs/1511.06149},
}

@Article{LeeEtAl2013Optimal,
  author  = {Kiryung Lee and Yihong Wu and Yoram Bresler},
  title   = {Near Optimal Compressed Sensing of a Class of Sparse Low-Rank Matrices via Sparse Power Factorization},
  journal = {arxiv:1312.0525},
  year    = {2013},
  url     = {http://arxiv.org/abs/1312.0525},
}

@Article{EftekhariWakin2015Greed,
  author  = {Armin Eftekhari and Michael B. Wakin},
  title   = {Greed is Super: A Fast Algorithm for Super-Resolution},
  journal = {arxiv:1511.03385},
  year    = {2015},
  url     = {http://arxiv.org/abs/1511.03385},
}

@Article{ZhongBoumal2017optimal,
  author  = {Zhong, Yiqiao and Boumal, Nicolas},
  title   = {Near-optimal bounds for phase synchronization},
  journal = {arXiv:1703.06605},
  year    = {2017},
}

@Article{PerryEtAl2016Message,
  author  = {Amelia Perry and Alexander S. Wein and Afonso S. Bandeira and Ankur Moitra},
  title   = {Message-passing algorithms for synchronization problems over compact groups},
  journal = {arxiv:1610.04583},
  year    = {2016},
  url     = {http://arxiv.org/abs/1610.04583},
}

@Article{BandeiraEtAl2016low,
  author  = {Afonso S. Bandeira and Nicolas Boumal and Vladislav Voroninski},
  title   = {On the low-rank approach for semidefinite programs arising in synchronization and community detection},
  journal = {arxiv:1602.04426},
  year    = {2016},
  url     = {http://arxiv.org/abs/1602.04426},
}

@Article{Boumal2016Nonconvex,
  author  = {Nicolas Boumal},
  title   = {Nonconvex phase synchronization},
  journal = {arxiv:1601.06114},
  year    = {2016},
  url     = {http://arxiv.org/abs/1601.06114},
}

@Article{ChenCandes2016Projected,
  author  = {Yuxin Chen and Emmanuel Candes},
  title   = {The Projected Power Method: An Efficient Algorithm for Joint Alignment from Pairwise Differences},
  journal = {arxiv:1609.05820},
  year    = {2016},
  url     = {http://arxiv.org/abs/1609.05820},
}

@Article{HauserEtAl2018PCA,
  author  = {Raphael A. Hauser and Armin Eftekhari and Heinrich F. Matzinger},
  title   = {PCA by Determinant Optimization has no Spurious Local Optima},
  journal = {arxiv:1803.04049},
  year    = {2018},
  url     = {http://arxiv.org/abs/1803.04049},
}

@Article{LuThicke2017Orbital,
  author    = {Jianfeng Lu and Kyle Thicke},
  title     = {Orbital minimization method with $\ell$ 1 regularization},
  journal   = {Journal of Computational Physics},
  year      = {2017},
  volume    = {336},
  pages     = {87--103},
  month     = {may},
  doi       = {10.1016/j.jcp.2017.02.005},
  publisher = {Elsevier {BV}},
  url       = {https://doi.org/10.1016%2Fj.jcp.2017.02.005},
}

@Article{ZhuEtAl2017Globala,
  author  = {Zhihui Zhu and Qiuwei Li and Gongguo Tang and Michael B. Wakin},
  title   = {The Global Optimization Geometry of Low-Rank Matrix Optimization},
  journal = {arxiv:1703.01256},
  year    = {2017},
  url     = {http://arxiv.org/abs/1703.01256},
}

@Article{Sra2015matrix,
  author  = {Suvrit Sra},
  title   = {On the matrix square root via geometric optimization},
  journal = {arxiv:1507.08366},
  year    = {2015},
  url     = {http://arxiv.org/abs/1507.08366},
}

@Article{JainEtAl2015Computing,
  author  = {Jain, Prateek and Jin, Chi and Kakade, Sham M and Netrapalli, Praneeth},
  title   = {Computing matrix squareroot via non convex local search},
  journal = {arXiv:1507.05854},
  year    = {2015},
}

@Article{AwasthiRisteski2015some,
  author  = {Pranjal Awasthi and Andrej Risteski},
  title   = {On some provably correct cases of variational inference for topic models},
  journal = {arxiv:1503.06567},
  year    = {2015},
  url     = {http://arxiv.org/abs/1503.06567},
}

@Article{MazumdarRawat2018Representation,
  author  = {Arya Mazumdar and Ankit Singh Rawat},
  title   = {Representation Learning and Recovery in the ReLU Model},
  journal = {arxiv:1803.04304},
  year    = {2018},
  url     = {http://arxiv.org/abs/1803.04304},
}

@Article{NouiehedRazaviyayn2018Learning,
  author  = {Maher Nouiehed and Meisam Razaviyayn},
  title   = {Learning Deep Models: Critical Points and Local Openness},
  journal = {arxiv:1803.02968},
  year    = {2018},
  url     = {http://arxiv.org/abs/1803.02968},
}

@Article{DuLee2018Power,
  author  = {Simon S. Du and Jason D. Lee},
  title   = {On the Power of Over-parametrization in Neural Networks with Quadratic Activation},
  journal = {arxiv:1803.01206},
  year    = {2018},
  url     = {http://arxiv.org/abs/1803.01206},
}

@Article{MondelliMontanari2018Connection,
  author  = {Marco Mondelli and Andrea Montanari},
  title   = {On the Connection Between Learning Two-Layers Neural Networks and Tensor Decomposition},
  journal = {arxiv:1802.07301},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.07301},
}

@Article{FuEtAl2018Local,
  author  = {Haoyu Fu and Yuejie Chi and Yingbin Liang},
  title   = {Local Geometry of One-Hidden-Layer Neural Networks for Logistic Regression},
  journal = {arxiv:1802.06463},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.06463},
}

@Article{YunEtAl2018Critical,
  author  = {Chulhee Yun and Suvrit Sra and Ali Jadbabaie},
  title   = {A Critical View of Global Optimality in Deep Learning},
  journal = {arxiv:1802.03487},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.03487},
}

@Article{LaurentBrecht2017Multilinear,
  author  = {Thomas Laurent and James von Brecht},
  title   = {The Multilinear Structure of ReLU Networks},
  journal = {arxiv:1712.10132},
  year    = {2017},
  url     = {http://arxiv.org/abs/1712.10132},
}

@Article{SafranShamir2017Spurious,
  author  = {Itay Safran and Ohad Shamir},
  title   = {Spurious Local Minima are Common in Two-Layer ReLU Neural Networks},
  journal = {arxiv:1712.08968},
  year    = {2017},
  url     = {http://arxiv.org/abs/1712.08968},
}

@Article{DuEtAl2017Gradient,
  author  = {Simon S. Du and Jason D. Lee and Yuandong Tian and Barnabas Poczos and Aarti Singh},
  title   = {Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of Spurious Local Minima},
  journal = {arxiv:1712.00779},
  year    = {2017},
  url     = {http://arxiv.org/abs/1712.00779},
}

@Article{ZhongEtAl2017Learning,
  author  = {Kai Zhong and Zhao Song and Inderjit S. Dhillon},
  title   = {Learning Non-overlapping Convolutional Neural Networks with Multiple Kernels},
  journal = {arxiv:1711.03440},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.03440},
}

@Article{GeEtAl2017Learning,
  author  = {Rong Ge and Jason D. Lee and Tengyu Ma},
  title   = {Learning One-hidden-layer Neural Networks with Landscape Design},
  journal = {arxiv:1711.00501},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.00501},
}

@Article{BoobLan2017Theoretical,
  author  = {Digvijay Boob and Guanghui Lan},
  title   = {Theoretical properties of the global optimizer of two layer neural network},
  journal = {arxiv:1710.11241},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.11241},
}

@Article{ZhouLiang2017Critical,
  author  = {Yi Zhou and Yingbin Liang},
  title   = {Critical Points of Neural Networks: Analytical Forms and Landscape Properties},
  journal = {arxiv:1710.11205},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.11205},
}

@Article{BrutzkusEtAl2017SGD,
  author  = {Alon Brutzkus and Amir Globerson and Eran Malach and Shai Shalev-Shwartz},
  title   = {SGD Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data},
  journal = {arxiv:1710.10174},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.10174},
}

@Article{FeiziEtAl2017Porcupine,
  author  = {Soheil Feizi and Hamid Javadi and Jesse Zhang and David Tse},
  title   = {Porcupine Neural Networks: (Almost) All Local Optima are Global},
  journal = {arxiv:1710.02196},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.02196},
}

@Article{DuEtAl2017When,
  author  = {Simon S. Du and Jason D. Lee and Yuandong Tian},
  title   = {When is a Convolutional Filter Easy To Learn?},
  journal = {arxiv:1709.06129},
  year    = {2017},
  url     = {http://arxiv.org/abs/1709.06129},
}

@Article{SoltanolkotabiEtAl2017Theoretical,
  author  = {Mahdi Soltanolkotabi and Adel Javanmard and Jason D. Lee},
  title   = {Theoretical insights into the optimization landscape of over-parameterized shallow neural networks},
  journal = {arxiv:1707.04926},
  year    = {2017},
  url     = {http://arxiv.org/abs/1707.04926},
}

@Article{ZhongEtAl2017Recovery,
  author  = {Kai Zhong and Zhao Song and Prateek Jain and Peter L. Bartlett and Inderjit S. Dhillon},
  title   = {Recovery Guarantees for One-hidden-layer Neural Networks},
  journal = {arxiv:1706.03175},
  year    = {2017},
  url     = {http://arxiv.org/abs/1706.03175},
}

@Article{LiYuan2017Convergence,
  author  = {Yuanzhi Li and Yang Yuan},
  title   = {Convergence Analysis of Two-layer Neural Networks with ReLU Activation},
  journal = {arxiv:1705.09886},
  year    = {2017},
  url     = {http://arxiv.org/abs/1705.09886},
}

@Article{HandVoroninski2017Global,
  author  = {Paul Hand and Vladislav Voroninski},
  title   = {Global Guarantees for Enforcing Deep Generative Priors by Empirical Risk},
  journal = {arxiv:1705.07576},
  year    = {2017},
  url     = {http://arxiv.org/abs/1705.07576},
}

@Article{Soltanolkotabi2017Learning,
  author  = {Mahdi Soltanolkotabi},
  title   = {Learning ReLUs via Gradient Descent},
  journal = {arxiv:1705.04591},
  year    = {2017},
  url     = {http://arxiv.org/abs/1705.04591},
}

@Article{BrutzkusGloberson2017Globally,
  author  = {Alon Brutzkus and Amir Globerson},
  title   = {Globally Optimal Gradient Descent for a ConvNet with Gaussian Inputs},
  journal = {arxiv:1702.07966},
  year    = {2017},
  url     = {http://arxiv.org/abs/1702.07966},
}

@Article{HardtEtAl2016Gradient,
  author  = {Moritz Hardt and Tengyu Ma and Benjamin Recht},
  title   = {Gradient Descent Learns Linear Dynamical Systems},
  journal = {arxiv:1609.05191},
  year    = {2016},
  url     = {http://arxiv.org/abs/1609.05191},
}

@Article{MeiEtAl2016Landscape,
  author  = {Song Mei and Yu Bai and Andrea Montanari},
  title   = {The Landscape of Empirical Risk for Non-convex Losses},
  journal = {arxiv:1607.06534},
  year    = {2016},
  url     = {http://arxiv.org/abs/1607.06534},
}

@Article{HardtEtAl2016Gradienta,
  author  = {Moritz Hardt and Tengyu Ma and Benjamin Recht},
  title   = {Gradient Descent Learns Linear Dynamical Systems},
  journal = {arxiv:1609.05191},
  year    = {2016},
  url     = {http://arxiv.org/abs/1609.05191},
}

@Article{BhojanapalliEtAl2018Smoothed,
  author  = {Srinadh Bhojanapalli and Nicolas Boumal and Prateek Jain and Praneeth Netrapalli},
  title   = {Smoothed analysis for low-rank solutions to semidefinite programs in quadratic penalty form},
  journal = {arxiv:1803.00186},
  year    = {2018},
  url     = {http://arxiv.org/abs/1803.00186},
}

@Article{MeiEtAl2017Solving,
  author  = {Song Mei and Theodor Misiakiewicz and Andrea Montanari and Roberto I. Oliveira},
  title   = {Solving SDPs for synchronization and MaxCut problems via the Grothendieck inequality},
  journal = {arxiv:1703.08729},
  year    = {2017},
  url     = {http://arxiv.org/abs/1703.08729},
}

@Article{LiTang2016Nonconvex,
  author  = {Qiuwei Li and Gongguo Tang},
  title   = {The Nonconvex Geometry of Low-Rank Matrix Optimizations with General Objective Functions},
  journal = {arxiv:1611.03060},
  year    = {2016},
  url     = {http://arxiv.org/abs/1611.03060},
}

@Article{BoumalEtAl2016non,
  author  = {Nicolas Boumal and Vladislav Voroninski and Afonso S. Bandeira},
  title   = {The non-convex Burer-Monteiro approach works on smooth semidefinite programs},
  journal = {arxiv:1606.04970},
  year    = {2016},
  url     = {http://arxiv.org/abs/1606.04970},
}

@Article{BandeiraEtAl2016lowa,
  author  = {Afonso S. Bandeira and Nicolas Boumal and Vladislav Voroninski},
  title   = {On the low-rank approach for semidefinite programs arising in synchronization and community detection},
  journal = {arxiv:1602.04426},
  year    = {2016},
  url     = {http://arxiv.org/abs/1602.04426},
}

@Article{SaEtAl2014Global,
  author  = {Christopher De Sa and Kunle Olukotun and Christopher Ré},
  title   = {Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems},
  journal = {arxiv:1411.1134},
  year    = {2014},
  url     = {http://arxiv.org/abs/1411.1134},
}

@Article{ChenEtAl2017Run,
  author  = {Yifan Chen and Yuejiao Sun and Wotao Yin},
  title   = {Run-and-Inspect Method for Nonconvex Optimization and Global Optimality Bounds for R-Local Minimizers},
  journal = {arxiv:1711.08172},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.08172},
}

@Article{MangoubiVishnoi2017Convex,
  author  = {Oren Mangoubi and Nisheeth K. Vishnoi},
  title   = {Convex Optimization with Nonconvex Oracles},
  journal = {arxiv:1711.02621},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.02621},
}

@Article{Thao2017convergent,
  author  = {Nguyen Hieu Thao},
  title   = {A convergent relaxation of the Douglas-Rachford algorithm},
  journal = {arxiv:1709.05984},
  year    = {2017},
  url     = {http://arxiv.org/abs/1709.05984},
}

@Article{DaoTam2017Lyapunov,
  author  = {Minh N. Dao and Matthew K. Tam},
  title   = {A Lyapunov-type approach to convergence of the Douglas-Rachford algorithm},
  journal = {arxiv:1706.04846},
  year    = {2017},
  url     = {http://arxiv.org/abs/1706.04846},
}

@Article{BorweinEtAl2016Dynamics,
  author  = {Jonathan M. Borwein and Scott B. Lindstrom and Brailey Sims and Anna Schneider and Matthew P. Skerritt},
  title   = {Dynamics of the Douglas-Rachford Method for Ellipses and p-Spheres},
  journal = {arxiv:1610.03975},
  year    = {2016},
  url     = {http://arxiv.org/abs/1610.03975},
}

@Article{Giladi2016remark,
  author  = {Ohad Giladi},
  title   = {A remark on the convergence of the Douglas-Rachford iteration in a non-convex setting},
  journal = {arxiv:1609.08751},
  year    = {2016},
  url     = {http://arxiv.org/abs/1609.08751},
}

@Article{BauschkeDao2016finite,
  author  = {Heinz H. Bauschke and Minh N. Dao},
  title   = {On the finite convergence of the Douglas-Rachford algorithm for solving (not necessarily convex) feasibility problems in Euclidean spaces},
  journal = {arxiv:1604.04657},
  year    = {2016},
  url     = {http://arxiv.org/abs/1604.04657},
}

@Article{ArtachoEtAl2015Global,
  author    = {Francisco J. Arag{\'{o}}n Artacho and Jonathan M. Borwein and Matthew K. Tam},
  title     = {Global behavior of the Douglas-Rachford method for a nonconvex feasibility problem},
  journal   = {Journal of Global Optimization},
  year      = {2015},
  volume    = {65},
  number    = {2},
  pages     = {309--327},
  month     = {nov},
  doi       = {10.1007/s10898-015-0380-6},
  publisher = {Springer Nature},
  url       = {https://doi.org/10.1007%2Fs10898-015-0380-6},
}

@InCollection{BorweinSims2011Douglas,
  author    = {Borwein, Jonathan M and Sims, Brailey},
  title     = {The Douglas--Rachford algorithm in the absence of convexity},
  booktitle = {Fixed-Point Algorithms for Inverse Problems in Science and Engineering},
  publisher = {Springer},
  year      = {2011},
  pages     = {93--109},
}

@Article{SunEtAl2016Sparse,
  author  = {Will Wei Sun and Zhaoran Wang and Xiang Lyu and Han Liu and Guang Cheng},
  title   = {Sparse Tensor Graphical Model: Non-convex Optimization and Statistical Inference},
  journal = {arxiv:1609.04522},
  year    = {2016},
  url     = {http://arxiv.org/abs/1609.04522},
}

@Article{SunEtAl2015Provable,
  author  = {Will Wei Sun and Junwei Lu and Han Liu and Guang Cheng},
  title   = {Provable Sparse Tensor Decomposition},
  journal = {arxiv:1502.01425},
  year    = {2015},
  url     = {http://arxiv.org/abs/1502.01425},
}

@InProceedings{YangEtAl2015Statistical,
  author       = {Yang, Fanny and Balakrishnan, Sivaraman and Wainwright, Martin J},
  title        = {Statistical and computational guarantees for the Baum-Welch algorithm},
  booktitle    = {Communication, Control, and Computing (Allerton), 2015 53rd Annual Allerton Conference on},
  year         = {2015},
  pages        = {658--665},
  organization = {IEEE},
}

@Article{Loh2015Statistical,
  author  = {Po-Ling Loh},
  title   = {Statistical consistency and asymptotic normality for high-dimensional robust M-estimators},
  journal = {arxiv:1501.00312},
  year    = {2015},
  url     = {http://arxiv.org/abs/1501.00312},
}

@Article{LohWainwright2014Support,
  author  = {Po-Ling Loh and Martin J. Wainwright},
  title   = {Support recovery without incoherence: A case for nonconvex regularization},
  journal = {arxiv:1412.5632},
  year    = {2014},
  url     = {http://arxiv.org/abs/1412.5632},
}

@Article{WangEtAl2014High,
  author  = {Zhaoran Wang and Quanquan Gu and Yang Ning and Han Liu},
  title   = {High Dimensional Expectation-Maximization Algorithm: Statistical Optimization and Asymptotic Normality},
  journal = {arxiv:1412.8729},
  year    = {2014},
  url     = {http://arxiv.org/abs/1412.8729},
}

@Article{BalakrishnanEtAl2014Statistical,
  author  = {Sivaraman Balakrishnan and Martin J. Wainwright and Bin Yu},
  title   = {Statistical guarantees for the EM algorithm: From population to sample-based analysis},
  journal = {arxiv:1408.2156},
  year    = {2014},
  url     = {http://arxiv.org/abs/1408.2156},
}

@Article{WangEtAl2014Nonconvex,
  author  = {Zhaoran Wang and Huanran Lu and Han Liu},
  title   = {Nonconvex Statistical Optimization: Minimax-Optimal Sparse PCA in Polynomial Time},
  journal = {arxiv:1408.5352},
  year    = {2014},
  url     = {http://arxiv.org/abs/1408.5352},
}

@Article{LohWainwright2013Regularized,
  author  = {Po-Ling Loh and Martin J. Wainwright},
  title   = {Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima},
  journal = {arxiv:1305.2436},
  year    = {2013},
  url     = {http://arxiv.org/abs/1305.2436},
}

@Article{LohWainwright2012High,
  author    = {Po-Ling Loh and Martin J. Wainwright},
  title     = {High-dimensional regression with noisy and missing data: Provable guarantees with nonconvexity},
  journal   = {The Annals of Statistics},
  year      = {2012},
  volume    = {40},
  number    = {3},
  pages     = {1637--1664},
  month     = {jun},
  doi       = {10.1214/12-aos1018},
  publisher = {Institute of Mathematical Statistics},
  url       = {https://doi.org/10.1214%2F12-aos1018},
}

@Article{KarkhaneeiMahdavi-Amiri2018Nonconvex,
  author  = {M. Mahdi Karkhaneei and Nezam Mahdavi-Amiri},
  title   = {Nonconvex weak sharp minima on Riemannian manifolds},
  journal = {arxiv:1803.03943},
  year    = {2018},
  url     = {http://arxiv.org/abs/1803.03943},
}

@Article{RoyerEtAl2018Newton,
  author  = {Clément W. Royer and Michael O'Neill and Stephen J. Wright},
  title   = {A Newton-CG Algorithm with Complexity Guarantees for Smooth Unconstrained Optimization},
  journal = {arxiv:1803.02924},
  year    = {2018},
  url     = {http://arxiv.org/abs/1803.02924},
}

@Article{Le-HuuParagios2018Continuous,
  author  = {D. Khuê Lê-Huu and Nikos Paragios},
  title   = {Continuous Relaxation of MAP Inference: A Nonconvex Perspective},
  journal = {arxiv:1802.07796},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.07796},
}

@Article{LuEtAl2018Sublinear,
  author  = {Songtao Lu and Mingyi Hong and Zhengdao Wang},
  title   = {On the Sublinear Convergence of Randomly Perturbed Alternating Gradient Descent to Second Order Stationary Solutions},
  journal = {arxiv:1802.10418},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.10418},
}

@Article{GaoEtAl2018ADMM,
  author  = {Wenbo Gao and Donald Goldfarb and Frank E. Curtis},
  title   = {ADMM for Multiaffine Constrained Optimization},
  journal = {arxiv:1802.09592},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.09592},
}

@Article{TripuraneniEtAl2018Averaging,
  author  = {Nilesh Tripuraneni and Nicolas Flammarion and Francis Bach and Michael I. Jordan},
  title   = {Averaging Stochastic Gradient Descent on Riemannian Manifolds},
  journal = {arxiv:1802.09128},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.09128},
}

@Article{HongEtAl2018Gradient,
  author  = {Mingyi Hong and Jason D. Lee and Meisam Razaviyayn},
  title   = {Gradient Primal-Dual Algorithm Converges to Second-Order Stationary Solutions for Nonconvex Distributed Optimization},
  journal = {arxiv:1802.08941},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.08941},
}

@Article{CurtisEtAl2018Concise,
  author  = {Frank E. Curtis and Zachary Lubberts and Daniel P. Robinson},
  title   = {Concise Complexity Analyses for Trust-Region Methods},
  journal = {arxiv:1802.07843},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.07843},
}

@Article{DavisDrusvyatskiy2018Stochastic,
  author  = {Davis, Damek and Drusvyatskiy, Dmitriy},
  title   = {Stochastic subgradient method converges at the rate $O(k^{-1/4})$ on weakly convex functions},
  journal = {arXiv:1802.02988},
  year    = {2018},
}

@Article{AroraEtAl2018Optimization,
  author  = {Sanjeev Arora and Nadav Cohen and Elad Hazan},
  title   = {On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization},
  journal = {arxiv:1802.06509},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.06509},
}

@Article{GunasekarEtAl2018Characterizing,
  author  = {Suriya Gunasekar and Jason Lee and Daniel Soudry and Nathan Srebro},
  title   = {Characterizing Implicit Bias in Terms of Optimization Geometry},
  journal = {arxiv:1802.08246},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.08246},
}

@Article{TzenEtAl2018Local,
  author  = {Belinda Tzen and Tengyuan Liang and Maxim Raginsky},
  title   = {Local Optimality and Generalization Guarantees for the Langevin Algorithm via Empirical Metastability},
  journal = {arxiv:1802.06439},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.06439},
}

@Article{VenturiEtAl2018Neural,
  author  = {Luca Venturi and Afonso S. Bandeira and Joan Bruna},
  title   = {Neural Networks with Finite Intrinsic Dimension have no Spurious Valleys},
  journal = {arxiv:1802.06384},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.06384},
}

@Article{WangEtAl2018Sample,
  author  = {Zhe Wang and Yi Zhou and Yingbin Liang and Guanghui Lan},
  title   = {Sample Complexity of Stochastic Variance-Reduced Cubic Regularization for Nonconvex Optimization},
  journal = {arxiv:1802.07372},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.07372},
}

@Article{KleinbergEtAl2018Alternative,
  author  = {Robert Kleinberg and Yuanzhi Li and Yang Yuan},
  title   = {An Alternative View: When Does SGD Escape Local Minima?},
  journal = {arxiv:1802.06175},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.06175},
}

@Article{LiuEtAl2018Deeper,
  author  = {Tianyi Liu and Zhehui Chen and Enlu Zhou and Tuo Zhao},
  title   = {Toward Deeper Understanding of Nonconvex Stochastic Optimization with Momentum using Diffusion Approximations},
  journal = {arxiv:1802.05155},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.05155},
}

@Article{ZhuLi2018Convergence,
  author  = {Zhihui Zhu and Xiao Li},
  title   = {Convergence Analysis of Alternating Nonconvex Projections},
  journal = {arxiv:1802.03889},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.03889},
}

@Article{DouikHassibi2018Manifold,
  author  = {Ahmed Douik and Babak Hassibi},
  title   = {Manifold Optimization Over the Set of Doubly Stochastic Matrices: A Second-Order Geometry},
  journal = {arxiv:1802.02628},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.02628},
}

@Article{BurerYe2018Exact,
  author  = {Samuel Burer and Yinyu Ye},
  title   = {Exact Semidefinite Formulations for a Class of (Random and Non-Random) Nonconvex Quadratic Programs},
  journal = {arxiv:1802.02688},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.02688},
}

@Article{CurtisRobinson2018How,
  author  = {Frank E. Curtis and Daniel P. Robinson},
  title   = {How to Characterize the Worst-Case Performance of Algorithms for Nonconvex Optimization},
  journal = {arxiv:1802.01062},
  year    = {2018},
  url     = {http://arxiv.org/abs/1802.01062},
}

@Article{YueEtAl2018Quadratic,
  author  = {Man-Chung Yue and Zirui Zhou and Anthony Man-Cho So},
  title   = {On the Quadratic Convergence of the Cubic Regularization Method under a Local Error Bound Condition},
  journal = {arxiv:1801.09387},
  year    = {2018},
  url     = {http://arxiv.org/abs/1801.09387},
}

@Article{BotNguyen2018proximal,
  author  = {Radu Ioan Bot and Dang-Khoa Nguyen},
  title   = {The proximal alternating direction method of multipliers in the nonconvex setting: convergence analysis and rates},
  journal = {arxiv:1801.01994},
  year    = {2018},
  url     = {http://arxiv.org/abs/1801.01994},
}

@Article{BolteEtAl2018Nonconvex,
  author  = {Jérôme Bolte and Shoham Sabach and Marc Teboulle},
  title   = {Nonconvex Lagrangian-Based Optimization: Monitoring Schemes and Global Convergence},
  journal = {arxiv:1801.03013},
  year    = {2018},
  url     = {http://arxiv.org/abs/1801.03013},
}

@Article{YuEtAl2017Third,
  author  = {Yaodong Yu and Pan Xu and Quanquan Gu},
  title   = {Third-order Smoothness Helps: Even Faster Stochastic Optimization Algorithms for Finding Local Minima},
  journal = {arxiv:1712.06585},
  year    = {2017},
  url     = {http://arxiv.org/abs/1712.06585},
}

@Article{YuEtAl2017Saving,
  author  = {Yaodong Yu and Difan Zou and Quanquan Gu},
  title   = {Saving Gradient and Negative Curvature Computations: Finding Local Minima More Efficiently},
  journal = {arxiv:1712.03950},
  year    = {2017},
  url     = {http://arxiv.org/abs/1712.03950},
}

@Article{XuEtAl2017NEON+:,
  author  = {Xu, Yi and Jin, Rong and Yang, Tianbao},
  title   = {NEON+: Accelerated Gradient Methods for Extracting Negative Curvature for Non-Convex Optimization},
  journal = {arXiv:1712.01033},
  year    = {2017},
}

@Article{JinEtAl2017Accelerated,
  author  = {Chi Jin and Praneeth Netrapalli and Michael I. Jordan},
  title   = {Accelerated Gradient Descent Escapes Saddle Points Faster than Gradient Descent},
  journal = {arxiv:1711.10456},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.10456},
}

@Article{MaEtAl2017Implicit,
  author  = {Cong Ma and Kaizheng Wang and Yuejie Chi and Yuxin Chen},
  title   = {Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent Converges Linearly for Phase Retrieval, Matrix Completion and Blind Deconvolution},
  journal = {arxiv:1711.10467},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.10467},
}

@Article{Allen-ZhuLi2017Neon2:,
  author  = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
  title   = {Neon2: Finding Local Minima via First-Order Oracles},
  journal = {arXiv:1711.06673},
  year    = {2017},
}

@Article{ChenEtAl2017Runa,
  author  = {Yifan Chen and Yuejiao Sun and Wotao Yin},
  title   = {Run-and-Inspect Method for Nonconvex Optimization and Global Optimality Bounds for R-Local Minimizers},
  journal = {arxiv:1711.08172},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.08172},
}

@Article{MurrayEtAl2017Revisiting,
  author  = {Ryan Murray and Brian Swenson and Soummya Kar},
  title   = {Revisiting Normalized Gradient Descent: Evasion of Saddle Points},
  journal = {arxiv:1711.05224},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.05224},
}

@Article{TripuraneniEtAl2017Stochastic,
  author  = {Nilesh Tripuraneni and Mitchell Stern and Chi Jin and Jeffrey Regier and Michael I. Jordan},
  title   = {Stochastic Cubic Regularization for Fast Nonconvex Optimization},
  journal = {arxiv:1711.02838},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.02838},
}

@Article{MangoubiVishnoi2017Convexa,
  author  = {Oren Mangoubi and Nisheeth K. Vishnoi},
  title   = {Convex Optimization with Nonconvex Oracles},
  journal = {arxiv:1711.02621},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.02621},
}

@Article{XuEtAl2017First,
  author  = {Yi Xu and Rong Jin and Tianbao Yang},
  title   = {First-order Stochastic Algorithms for Escaping From Saddle Points in Almost Linear Time},
  journal = {arxiv:1711.01944},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.01944},
}

@Article{CristofariEtAl2017local,
  author  = {A. Cristofari and T. Dehghan Niri and S. Lucidi},
  title   = {On local non-global minimizers of quadratic functions with cubic regularization},
  journal = {arxiv:1711.01303},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.01303},
}

@Article{WeberSra2017Frank,
  author  = {Melanie Weber and Suvrit Sra},
  title   = {Frank-Wolfe methods for geodesically convex optimization with application to the matrix geometric mean},
  journal = {arxiv:1710.10770},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.10770},
}

@Article{AgarwalHazan2017Lower,
  author  = {Naman Agarwal and Elad Hazan},
  title   = {Lower Bounds for Higher-Order Convex Optimization},
  journal = {arxiv:1710.10329},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.10329},
}

@Article{CarmonEtAl2017Lower,
  author  = {Yair Carmon and John C. Duchi and Oliver Hinder and Aaron Sidford},
  title   = {Lower Bounds for Finding Stationary Points II: First-Order Methods},
  journal = {arxiv:1711.00841},
  year    = {2017},
  url     = {http://arxiv.org/abs/1711.00841},
}

@Article{CarmonEtAl2017Lowera,
  author  = {Yair Carmon and John C. Duchi and Oliver Hinder and Aaron Sidford},
  title   = {Lower Bounds for Finding Stationary Points I},
  journal = {arxiv:1710.11606},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.11606},
}

@Article{LiuYang2017Stochastic,
  author  = {Mingrui Liu and Tianbao Yang},
  title   = {Stochastic Non-convex Optimization with Strong High Probability Second-order Convergence},
  journal = {arxiv:1710.09447},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.09447},
}

@Article{SongEtAl2017Block,
  author  = {Enbin Song and Zhubin Shen and Qingjiang Shi},
  title   = {Block Coordinate Descent Only Converge to Minimizers},
  journal = {arxiv:1710.09047},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.09047},
}

@Article{LeeEtAl2017First,
  author  = {Jason D. Lee and Ioannis Panageas and Georgios Piliouras and Max Simchowitz and Michael I. Jordan and Benjamin Recht},
  title   = {First-order Methods Almost Always Avoid Saddle Points},
  journal = {arxiv:1710.07406},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.07406},
}

@Article{LauYao2017Accelerated,
  author  = {Tsz Kit Lau and Yuan Yao},
  title   = {Accelerated Block Coordinate Proximal Gradients with Applications in High Dimensional Statistics},
  journal = {arxiv:1710.05338},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.05338},
}

@Article{HopkinsEtAl2017power,
  author  = {Samuel B. Hopkins and Pravesh K. Kothari and Aaron Potechin and Prasad Raghavendra and Tselil Schramm and David Steurer},
  title   = {The power of sum-of-squares for detecting hidden structures},
  journal = {arxiv:1710.05017},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.05017},
}

@Article{ZhangEtAl2017Primal,
  author  = {Junyu Zhang and Shiqian Ma and Shuzhong Zhang},
  title   = {Primal-Dual Optimization Algorithms over Riemannian Manifolds: an Iteration Complexity Analysis},
  journal = {arxiv:1710.02236},
  year    = {2017},
  url     = {http://arxiv.org/abs/1710.02236},
}

@Article{LiuYang2017Noisy,
  author  = {Mingrui Liu and Tianbao Yang},
  title   = {On Noisy Negative Curvature Descent: Competing with Gradient Descent for Faster Non-convex Optimization},
  journal = {arxiv:1709.08571},
  year    = {2017},
  url     = {http://arxiv.org/abs/1709.08571},
}

@Article{CartisEtAl2017Worst,
  author  = {Coralia Cartis and Nick I. M. Gould and Philippe L. Toint},
  title   = {Worst-case evaluation complexity and optimality of second-order methods for nonconvex smooth optimization},
  journal = {arxiv:1709.07180},
  year    = {2017},
  url     = {http://arxiv.org/abs/1709.07180},
}

@Article{ThemelisPatrinos2017Douglas,
  author  = {Andreas Themelis and Panagiotis Patrinos},
  title   = {Douglas-Rachford splitting and ADMM for nonconvex optimization: tight convergence results},
  journal = {arxiv:1709.05747},
  year    = {2017},
  url     = {http://arxiv.org/abs/1709.05747},
}

@Article{ChangEtAl2017Local,
  author  = {Tsung-Hui Chang and Mingyi Hong and Jong-Shi Pang},
  title   = {Local Minimizers and Second-Order Conditions in Composite Piecewise Programming via Directional Derivatives},
  journal = {arxiv:1709.05758},
  year    = {2017},
  url     = {http://arxiv.org/abs/1709.05758},
}

@Article{HaBarber2017Alternating,
  author  = {Wooseok Ha and Rina Foygel Barber},
  title   = {Alternating minimization and alternating descent over nonconvex sets},
  journal = {arxiv:1709.04451},
  year    = {2017},
  url     = {http://arxiv.org/abs/1709.04451},
}

@Article{XuEtAl2017Second,
  author  = {Xu, Peng and Roosta-Khorasan, Farbod and Mahoney, Michael W},
  title   = {Second-order optimization for non-convex machine learning: An empirical study},
  journal = {arXiv:1708.07827},
  year    = {2017},
}

@Article{XuEtAl2017Newton,
  author  = {Peng Xu and Farbod Roosta-Khorasani and Michael W. Mahoney},
  title   = {Newton-Type Methods for Non-Convex Optimization Under Inexact Hessian Information},
  journal = {arxiv:1708.07164},
  year    = {2017},
  url     = {http://arxiv.org/abs/1708.07164},
}

@Article{QuEtAl2017Non,
  author  = {Chao Qu and Yan Li and Huan Xu},
  title   = {Non-convex Conditional Gradient Sliding},
  journal = {arxiv:1708.04783},
  year    = {2017},
  url     = {http://arxiv.org/abs/1708.04783},
}

@Article{CartisEtAl2017Improved,
  author  = {Coralia Cartis and Nicholas I. M. Gould and Philippe L. Toint},
  title   = {Improved second-order evaluation complexity for unconstrained nonlinear optimization using high-order regularized models},
  journal = {arxiv:1708.04044},
  year    = {2017},
  url     = {http://arxiv.org/abs/1708.04044},
}

@Article{CurtisEtAl2017Inexact,
  author  = {Curtis, Frank E and Robinson, Daniel P and Samadi, Mohammadreza},
  title   = {An Inexact Regularized Newton Framework with a Worst-Case Iteration Complexity of $O(\varepsilon^{-3/2})$ for Nonconvex Optimization},
  journal = {arXiv:1708.00475},
  year    = {2017},
}

@Article{PaternainEtAl2017Second,
  author  = {Santiago Paternain and Aryan Mokhtari and Alejandro Ribeiro},
  title   = {A Second Order Method for Nonconvex Optimization},
  journal = {arxiv:1707.08028},
  year    = {2017},
  url     = {http://arxiv.org/abs/1707.08028},
}

@Article{ONeillWright2017Behavior,
  author  = {Michael O'Neill and Stephen J. Wright},
  title   = {Behavior of Accelerated Gradient Methods Near Critical Points of Nonconvex Functions},
  journal = {arxiv:1706.07993},
  year    = {2017},
  url     = {http://arxiv.org/abs/1706.07993},
}

@Article{ZhouEtAl2017Mirror,
  author  = {Zhengyuan Zhou and Panayotis Mertikopoulos and Nicholas Bambos and Stephen Boyd and Peter Glynn},
  title   = {Mirror descent in non-convex stochastic programming},
  journal = {arxiv:1706.05681},
  year    = {2017},
  url     = {http://arxiv.org/abs/1706.05681},
}

@Article{RoyerWright2017Complexity,
  author  = {Clément W. Royer and Stephen J. Wright},
  title   = {Complexity analysis of second-order line-search algorithms for smooth nonconvex optimization},
  journal = {arxiv:1706.03131},
  year    = {2017},
  url     = {http://arxiv.org/abs/1706.03131},
}

@Article{LiLiang2017Provable,
  author  = {Yuanzhi Li and Yingyu Liang},
  title   = {Provable Alternating Gradient Descent for Non-negative Matrix Factorization with Strong Correlations},
  journal = {arxiv:1706.04097},
  year    = {2017},
  url     = {http://arxiv.org/abs/1706.04097},
}

@Article{HosseiniSra2017Alternative,
  author  = {Reshad Hosseini and Suvrit Sra},
  title   = {An Alternative to EM for Gaussian Mixture Models: Batch and Stochastic Riemannian Optimization},
  journal = {arxiv:1706.03267},
  year    = {2017},
  url     = {http://arxiv.org/abs/1706.03267},
}

@Article{GoldfarbEtAl2017Using,
  author  = {Donald Goldfarb and Cun Mu and John Wright and Chaoxu Zhou},
  title   = {Using Negative Curvature in Solving Nonlinear Programs},
  journal = {arxiv:1706.00896},
  year    = {2017},
  url     = {http://arxiv.org/abs/1706.00896},
}

@Article{DuEtAl2017Gradienta,
  author  = {Simon S. Du and Chi Jin and Jason D. Lee and Michael I. Jordan and Barnabas Poczos and Aarti Singh},
  title   = {Gradient Descent Can Take Exponential Time to Escape Saddle Points},
  journal = {arxiv:1705.10412},
  year    = {2017},
  url     = {http://arxiv.org/abs/1705.10412},
}

@Article{CartisEtAl2017Optimality,
  author  = {C. Cartis and N. I. M. Gould and Ph. L. Toint},
  title   = {Optimality of orders one to three and beyond: characterization and evaluation complexity in constrained nonconvex optimization},
  journal = {arxiv:1705.07285},
  year    = {2017},
  url     = {http://arxiv.org/abs/1705.07285},
}

@Article{KohlerLucchi2017Sub,
  author  = {Jonas Moritz Kohler and Aurelien Lucchi},
  title   = {Sub-sampled Cubic Regularization for Non-convex Optimization},
  journal = {arxiv:1705.05933},
  year    = {2017},
  url     = {http://arxiv.org/abs/1705.05933},
}

@Article{LiuEtAl2017Linearized,
  author  = {Qinghua Liu and Xinyue Shen and Yuantao Gu},
  title   = {Linearized ADMM for Non-convex Non-smooth Optimization with Convergence Analysis},
  journal = {arxiv:1705.02502},
  year    = {2017},
  url     = {http://arxiv.org/abs/1705.02502},
}

@Article{CarmonEtAl2017``Convex,
  author  = {Carmon, Yair and Hinder, Oliver and Duchi, John C and Sidford, Aaron},
  title   = {``Convex Until Proven Guilty": Dimension-Free Acceleration of Gradient Descent on Non-Convex Functions},
  journal = {arXiv:1705.02766},
  year    = {2017},
}

@Article{JainEtAl2017Accelerating,
  author  = {Prateek Jain and Sham M. Kakade and Rahul Kidambi and Praneeth Netrapalli and Aaron Sidford},
  title   = {Accelerating Stochastic Gradient Descent},
  journal = {arxiv:1704.08227},
  year    = {2017},
  url     = {http://arxiv.org/abs/1704.08227},
}

@Article{SimchowitzEtAl2017Gap,
  author  = {Max Simchowitz and Ahmed El Alaoui and Benjamin Recht},
  title   = {On the Gap Between Strict-Saddles and True Convexity: An $\Omega(\log d)$ Lower Bound for Eigenvector Approximation},
  journal = {arxiv:1704.04548},
  year    = {2017},
  url     = {http://arxiv.org/abs/1704.04548},
}

@Article{PaquetteEtAl2017Catalyst,
  author  = {Paquette, Courtney and Lin, Hongzhou and Drusvyatskiy, Dmitriy and Mairal, Julien and Harchaoui, Zaid},
  title   = {Catalyst acceleration for gradient-based non-convex optimization},
  journal = {arXiv:1703.10993},
  year    = {2017},
}

@Article{BallardEtAl2017Energy,
  author    = {Ballard, Andrew J and Das, Ritankar and Martiniani, Stefano and Mehta, Dhagash and Sagun, Levent and Stevenson, Jacob D and Wales, David J},
  title     = {Energy landscapes for machine learning},
  journal   = {Physical Chemistry Chemical Physics},
  year      = {2017},
  volume    = {19},
  number    = {20},
  pages     = {12585--12603},
  publisher = {Royal Society of Chemistry},
}

@Article{BarberHa2017Gradient,
  author  = {Rina Foygel Barber and Wooseok Ha},
  title   = {Gradient descent with nonconvex constraints: local concavity determines convergence},
  journal = {arxiv:1703.07755},
  year    = {2017},
  url     = {http://arxiv.org/abs/1703.07755},
}

@Article{KasaiEtAl2017Riemannian,
  author  = {Hiroyuki Kasai and Hiroyuki Sato and Bamdev Mishra},
  title   = {Riemannian stochastic quasi-Newton algorithm with variance reduction and its convergence analysis},
  journal = {arxiv:1703.04890},
  year    = {2017},
  url     = {http://arxiv.org/abs/1703.04890},
}

@Article{JinEtAl2017How,
  author  = {Chi Jin and Rong Ge and Praneeth Netrapalli and Sham M. Kakade and Michael I. Jordan},
  title   = {How to Escape Saddle Points Efficiently},
  journal = {arxiv:1703.00887},
  year    = {2017},
  url     = {http://arxiv.org/abs/1703.00887},
}

@Article{BouttierGavra2017Convergence,
  author  = {Clément Bouttier and Ioana Gavra},
  title   = {Convergence rate of a simulated annealing algorithm with noisy observations},
  journal = {arxiv:1703.00329},
  year    = {2017},
  url     = {http://arxiv.org/abs/1703.00329},
}

@Article{CurtisRobinson2017Exploiting,
  author  = {Frank E. Curtis and Daniel P. Robinson},
  title   = {Exploiting Negative Curvature in Deterministic and Stochastic Optimization},
  journal = {arxiv:1703.00412},
  year    = {2017},
  url     = {http://arxiv.org/abs/1703.00412},
}

@Article{ChenEtAl2017Online,
  author  = {Chen, Zhehui and Yang, Forest L and Li, Chris J and Zhao, Tuo},
  title   = {Online multiview representation learning: Dropping convexity for better efficiency},
  journal = {arXiv:1702.08134},
  year    = {2017},
}

@Article{Allen-Zhu2017Natasha:,
  author  = {Allen-Zhu, Zeyuan},
  title   = {Natasha: Faster stochastic non-convex optimization via strongly non-convex parameter},
  journal = {arXiv:1702.00763},
  year    = {2017},
}

@Article{LuLi2017Phase,
  author  = {Yue M. Lu and Gen Li},
  title   = {Phase Transitions of Spectral Initialization for High-Dimensional Nonconvex Estimation},
  journal = {arxiv:1702.06435},
  year    = {2017},
  url     = {http://arxiv.org/abs/1702.06435},
}

@Article{BrunelEtAl2017Maximum,
  author  = {Victor-Emmanuel Brunel and Ankur Moitra and Philippe Rigollet and John Urschel},
  title   = {Maximum likelihood estimation of determinantal point processes},
  journal = {arxiv:1701.06501},
  year    = {2017},
  url     = {http://arxiv.org/abs/1701.06501},
}

@Article{GonenShalev-Shwartz2017Fast,
  author  = {Alon Gonen and Shai Shalev-Shwartz},
  title   = {Fast Rates for Empirical Risk Minimization of Strict Saddle Problems},
  journal = {arxiv:1701.04271},
  year    = {2017},
  url     = {http://arxiv.org/abs/1701.04271},
}

@Article{CarmonDuchi2016Gradient,
  author  = {Yair Carmon and John C. Duchi},
  title   = {Gradient Descent Efficiently Finds the Cubic-Regularized Non-Convex Newton Step},
  journal = {arxiv:1612.00547},
  year    = {2016},
  url     = {http://arxiv.org/abs/1612.00547},
}

@Article{Levy2016Power,
  author  = {Kfir Y. Levy},
  title   = {The Power of Normalization: Faster Evasion of Saddle Points},
  journal = {arxiv:1611.04831},
  year    = {2016},
  url     = {http://arxiv.org/abs/1611.04831},
}

@Article{CarmonEtAl2016Accelerated,
  author  = {Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, Aaron},
  title   = {Accelerated methods for non-convex optimization},
  journal = {arXiv:1611.00756},
  year    = {2016},
}

@Article{CartisEtAl2017Improveda,
  author  = {Coralia Cartis and Nicholas I. M. Gould and Philippe L. Toint},
  title   = {Improved second-order evaluation complexity for unconstrained nonlinear optimization using high-order regularized models},
  journal = {arxiv:1708.04044},
  year    = {2017},
  url     = {http://arxiv.org/abs/1708.04044},
}

@Article{BirginEtAl2017Worst,
  author    = {Birgin, Ernesto G and Gardenghi, JL and Mart{\'\i}nez, Jos{\'e} Mario and Santos, Sandra Augusta and Toint, Ph L},
  title     = {Worst-case evaluation complexity for unconstrained nonlinear optimization using high-order regularized models},
  journal   = {Mathematical Programming},
  year      = {2017},
  volume    = {163},
  number    = {1-2},
  pages     = {359--368},
  publisher = {Springer},
}

@Article{AgarwalEtAl2016Finding,
  author  = {Agarwal, Naman and Allen-Zhu, Zeyuan and Bullins, Brian and Hazan, Elad and Ma, Tengyu},
  title   = {Finding local minima for nonconvex optimization in linear time},
  journal = {arXiv:1611.01146},
  year    = {2016},
}

@Article{BlanchetEtAl2016Convergence,
  author  = {Jose Blanchet and Coralia Cartis and Matt Menickelly and Katya Scheinberg},
  title   = {Convergence Rate Analysis of a Stochastic Trust Region Method for Nonconvex Optimization},
  journal = {arxiv:1609.07428},
  year    = {2016},
  url     = {http://arxiv.org/abs/1609.07428},
}

@Article{XuEtAl2016Global,
  author  = {Ji Xu and Daniel Hsu and Arian Maleki},
  title   = {Global analysis of Expectation Maximization for mixtures of two Gaussians},
  journal = {arxiv:1608.07630},
  year    = {2016},
  url     = {http://arxiv.org/abs/1608.07630},
}

@Article{JinEtAl2016Local,
  author  = {Chi Jin and Yuchen Zhang and Sivaraman Balakrishnan and Martin J. Wainwright and Michael Jordan},
  title   = {Local Maxima in the Likelihood of Gaussian Mixture Models: Structural Results and Algorithmic Consequences},
  journal = {arxiv:1609.00978},
  year    = {2016},
  url     = {http://arxiv.org/abs/1609.00978},
}

@Article{Ochs2016Local,
  author  = {Peter Ochs},
  title   = {Local Convergence of the Heavy-ball Method and iPiano for Non-convex Optimization},
  journal = {arxiv:1606.09070},
  year    = {2016},
  url     = {http://arxiv.org/abs/1606.09070},
}

@Article{BoumalEtAl2016Global,
  author  = {Nicolas Boumal and P. -A. Absil and Coralia Cartis},
  title   = {Global rates of convergence for nonconvex optimization on manifolds},
  journal = {arxiv:1605.08101},
  year    = {2016},
  url     = {http://arxiv.org/abs/1605.08101},
}

@Article{PanageasPiliouras2016Gradient,
  author  = {Ioannis Panageas and Georgios Piliouras},
  title   = {Gradient Descent Only Converges to Minimizers: Non-Isolated Critical Points and Invariant Regions},
  journal = {arxiv:1605.00405},
  year    = {2016},
  url     = {http://arxiv.org/abs/1605.00405},
}

@Article{BauschkeMoursi2017Douglas,
  author    = {Bauschke, Heinz H and Moursi, Walaa M},
  title     = {On the Douglas--Rachford algorithm},
  journal   = {Mathematical Programming},
  year      = {2017},
  volume    = {164},
  number    = {1-2},
  pages     = {263--284},
  publisher = {Springer},
}

@Article{Montanari2016Grothendieck,
  author  = {Andrea Montanari},
  title   = {A Grothendieck-type inequality for local maxima},
  journal = {arxiv:1603.04064},
  year    = {2016},
  url     = {http://arxiv.org/abs/1603.04064},
}

@Article{ZhangSra2016First,
  author  = {Hongyi Zhang and Suvrit Sra},
  title   = {First-order Methods for Geodesically Convex Optimization},
  journal = {arxiv:1602.06053},
  year    = {2016},
  url     = {http://arxiv.org/abs/1602.06053},
}

@Article{AnandkumarGe2016Efficient,
  author  = {Anima Anandkumar and Rong Ge},
  title   = {Efficient approaches for escaping higher order saddle points in non-convex optimization},
  journal = {arxiv:1602.05908},
  year    = {2016},
  url     = {http://arxiv.org/abs/1602.05908},
}

@Article{LeeEtAl2016Gradient,
  author  = {Jason D. Lee and Max Simchowitz and Michael I. Jordan and Benjamin Recht},
  title   = {Gradient Descent Converges to Minimizers},
  journal = {arxiv:1602.04915},
  year    = {2016},
  url     = {http://arxiv.org/abs/1602.04915},
}

@Article{SunEtAl2015When,
  author  = {Ju Sun and Qing Qu and John Wright},
  title   = {When Are Nonconvex Problems Not Scary?},
  journal = {arxiv:1510.06096},
  year    = {2015},
  url     = {http://arxiv.org/abs/1510.06096},
}

@Article{ZhuEtAl2017Globalb,
  author  = {Zhihui Zhu and Qiuwei Li and Gongguo Tang and Michael B. Wakin},
  title   = {The Global Optimization Geometry of Low-Rank Matrix Optimization},
  journal = {arxiv:1703.01256},
  year    = {2017},
  url     = {http://arxiv.org/abs/1703.01256},
}

@Article{WangEtAl2015Global,
  author  = {Yu Wang and Wotao Yin and Jinshan Zeng},
  title   = {Global Convergence of ADMM in Nonconvex Nonsmooth Optimization},
  journal = {arxiv:1511.06324},
  year    = {2015},
  url     = {http://arxiv.org/abs/1511.06324},
}

@Article{BhojanapalliEtAl2015Dropping,
  author  = {Srinadh Bhojanapalli and Anastasios Kyrillidis and Sujay Sanghavi},
  title   = {Dropping Convexity for Faster Semi-definite Optimization},
  journal = {arxiv:1509.03917},
  year    = {2015},
  url     = {http://arxiv.org/abs/1509.03917},
}

@Article{AspelmeierEtAl2015Local,
  author  = {Timo Aspelmeier and C. Charitha and D. Russell Luke},
  title   = {Local Linear Convergence of the ADMM/Douglas--Rachford Algorithms without Strong Convexity and Application to Statistical Imaging},
  journal = {arxiv:1508.04468},
  year    = {2015},
  url     = {http://arxiv.org/abs/1508.04468},
}

@Article{BelloniEtAl2015Escaping,
  author  = {Alexandre Belloni and Tengyuan Liang and Hariharan Narayanan and Alexander Rakhlin},
  title   = {Escaping the Local Minima via Simulated Annealing: Optimization of Approximately Convex Functions},
  journal = {arxiv:1501.07242},
  year    = {2015},
  url     = {http://arxiv.org/abs/1501.07242},
}

@InProceedings{GeEtAl2015Escaping,
  author    = {Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
  title     = {Escaping from saddle points—online stochastic gradient for tensor decomposition},
  booktitle = {Conference on Learning Theory},
  year      = {2015},
  pages     = {797--842},
}

@Article{LiEtAl2015Peaceman,
  author  = {Guoyin Li and Tianxiang Liu and Ting Kei Pong},
  title   = {Peaceman-Rachford splitting for a class of nonconvex optimization problems},
  journal = {arxiv:1507.00887},
  year    = {2015},
  url     = {http://arxiv.org/abs/1507.00887},
}

@Article{LiPong2015Douglas,
  author    = {Guoyin Li and Ting Kei Pong},
  title     = {Douglas-Rachford splitting for nonconvex optimization with application to nonconvex feasibility problems},
  journal   = {Mathematical Programming},
  year      = {2015},
  volume    = {159},
  number    = {1-2},
  pages     = {371--401},
  month     = {nov},
  doi       = {10.1007/s10107-015-0963-5},
  publisher = {Springer Nature},
  url       = {https://doi.org/10.1007%2Fs10107-015-0963-5},
}

@Article{LiPong2015Global,
  author    = {Guoyin Li and Ting Kei Pong},
  title     = {Global Convergence of Splitting Methods for Nonconvex Composite Optimization},
  journal   = {{SIAM} Journal on Optimization},
  year      = {2015},
  volume    = {25},
  number    = {4},
  pages     = {2434--2460},
  month     = {jan},
  doi       = {10.1137/140998135},
  publisher = {Society for Industrial {\&} Applied Mathematics ({SIAM})},
  url       = {https://doi.org/10.1137%2F140998135},
}

@Article{GhadimiLan2013Accelerated,
  author  = {Saeed Ghadimi and Guanghui Lan},
  title   = {Accelerated Gradient Methods for Nonconvex Nonlinear and Stochastic Programming},
  journal = {arxiv:1310.3787},
  year    = {2013},
  url     = {http://arxiv.org/abs/1310.3787},
}

@Article{BolteEtAl2014Proximal,
  author    = {Bolte, J{\'e}r{\^o}me and Sabach, Shoham and Teboulle, Marc},
  title     = {Proximal alternating linearized minimization or nonconvex and nonsmooth problems},
  journal   = {Mathematical Programming},
  year      = {2014},
  volume    = {146},
  number    = {1-2},
  pages     = {459--494},
  publisher = {Springer},
}

@Article{AttouchEtAl2013Convergence,
  author    = {Attouch, Hedy and Bolte, J{\'e}r{\^o}me and Svaiter, Benar Fux},
  title     = {Convergence of descent methods for semi-algebraic and tame problems: proximal algorithms, forward--backward splitting, and regularized Gauss--Seidel methods},
  journal   = {Mathematical Programming},
  year      = {2013},
  volume    = {137},
  number    = {1-2},
  pages     = {91--129},
  publisher = {Springer},
}

@Article{AttouchEtAl2008Proximal,
  author  = {Hedy Attouch and Jerome Bolte and Patrick Redont and Antoine Soubeyran},
  title   = {Proximal alternating minimization and projection methods for nonconvex problems. An approach based on the Kurdyka-Lojasiewicz inequality},
  journal = {arxiv:0801.1780},
  year    = {2008},
  url     = {http://arxiv.org/abs/0801.1780},
}

@Article{AttouchEtAl2010Proximal,
  author    = {Attouch, H{\'e}dy and Bolte, J{\'e}r{\^o}me and Redont, Patrick and Soubeyran, Antoine},
  title     = {Proximal alternating minimization and projection methods for nonconvex problems: An approach based on the Kurdyka-{\L}ojasiewicz inequality},
  journal   = {Mathematics of Operations Research},
  year      = {2010},
  volume    = {35},
  number    = {2},
  pages     = {438--457},
  publisher = {INFORMS},
}

@Article{NesterovPolyak2006Cubic,
  author    = {Nesterov, Yurii and Polyak, Boris T},
  title     = {Cubic regularization of Newton method and its global performance},
  journal   = {Mathematical Programming},
  year      = {2006},
  volume    = {108},
  number    = {1},
  pages     = {177--205},
  publisher = {Springer},
}

@Article{Fortin2005Computing,
  author    = {Fortin, Charles},
  title     = {Computing the local-nonglobal minimizer of a large scale trust-region subproblem},
  journal   = {SIAM Journal on Optimization},
  year      = {2005},
  volume    = {16},
  number    = {1},
  pages     = {263--296},
  publisher = {SIAM},
}

@Article{LucidiEtAl1998some,
  author    = {Lucidi, Stefano and Palagi, Laura and Roma, Massimo},
  title     = {On some properties of quadratic programs with a convex quadratic constraint},
  journal   = {SIAM Journal on Optimization},
  year      = {1998},
  volume    = {8},
  number    = {1},
  pages     = {105--122},
  publisher = {SIAM},
}

@Article{Martinez1994Local,
  author    = {Mart{\'\i}nez, Jos{\'e} Mario},
  title     = {Local minimizers of quadratic functions on Euclidean balls and spheres},
  journal   = {SIAM Journal on Optimization},
  year      = {1994},
  volume    = {4},
  number    = {1},
  pages     = {159--176},
  publisher = {SIAM},
}

@Article{HuangEtAl2018Riemannian,
  author    = {Huang, Wen and Absil, P-A and Gallivan, KA},
  title     = {A Riemannian BFGS method without differentiated retraction for nonconvex optimization problems},
  journal   = {SIAM Journal on Optimization},
  year      = {2018},
  volume    = {28},
  number    = {1},
  pages     = {470--495},
  doi       = {10.1137/17M1127582},
  publisher = {SIAM},
}

@Article{BentoEtAl2017Iteration,
  author    = {Bento, Glaydston C and Ferreira, Orizon P and Melo, Jefferson G},
  title     = {Iteration-complexity of gradient, subgradient and proximal point methods on Riemannian manifolds},
  journal   = {Journal of Optimization Theory and Applications},
  year      = {2017},
  volume    = {173},
  number    = {2},
  pages     = {548--562},
  doi       = {10.1007/s10957-017-1093-4},
  publisher = {Springer},
}

@Article{DingChen2018Leave,
  author      = {Lijun Ding and Yudong Chen},
  title       = {The Leave-one-out Approach for Matrix Completion: Primal and Dual Analysis},
  year        = {2018},
  date        = {2018-03-20},
  eprint      = {1803.07554},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1803.07554v1:PDF},
  keywords    = {stat.ML, cs.IT, cs.LG, math.IT, math.OC, math.ST, stat.TH},
  url         = {https://arxiv.org/abs/1803.07554},
}

@Article{ChenEtAl2018Gradient,
  author      = {Yuxin Chen and Yuejie Chi and Jianqing Fan and Cong Ma},
  title       = {Gradient Descent with Random Initialization: Fast Global Convergence for Nonconvex Phase Retrieval},
  journal     = {arXiv:1803.07726},
  year        = {2018},
  date        = {2018-03-21},
  eprint      = {1803.07726},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1803.07726v1:PDF},
  keywords    = {stat.ML, cs.IT, cs.LG, cs.NA, math.IT, math.OC},
  url         = {https://arxiv.org/abs/1803.07726},
}

@Article{MixonVillar2018SUNLayer:,
  author      = {Dustin G. Mixon and Soledad Villar},
  title       = {SUNLayer: Stable denoising with generative networks},
  journal     = {arXiv:1803.09319},
  year        = {2018},
  date        = {2018-03-25},
  eprint      = {1803.09319},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1803.09319v1:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Article{JentzenWurstemberger2018Lower,
  author      = {Arnulf Jentzen and Philippe von Wurstemberger},
  title       = {Lower error bounds for the stochastic gradient descent optimization algorithm: Sharp convergence rates for slowly and fast decaying learning rates},
  journal     = {arXiv:1803.08600},
  year        = {2018},
  date        = {2018-03-22},
  eprint      = {1803.08600},
  eprintclass = {math.NA},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1803.08600v1:PDF},
  keywords    = {math.NA, math.PR, stat.ML},
  url         = {http://arxiv.org/pdf/1803.08600},
}

@Article{Allen-ZhuEtAl2018Operator,
  author      = {Zeyuan Allen-Zhu and Ankit Garg and Yuanzhi Li and Rafael Oliveira and Avi Wigderson},
  title       = {Operator Scaling via Geodesically Convex Optimization, Invariant Theory and Polynomial Identity Testing},
  journal     = {arXiv:1804.01076},
  year        = {2018},
  date        = {2018-04-03},
  eprint      = {1804.01076},
  eprintclass = {cs.DS},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1804.01076v1:PDF},
  keywords    = {cs.DS, cs.CC, math.AG, math.OC},
}

@Article{FerreiraEtAl2018spherical,
  author      = {O. P. Ferreira and S. Z. Németh and L. Xiao},
  title       = {On the spherical quasi-convexity of quadratic functions},
  journal     = {arXiv:1804.02907},
  year        = {2018},
  date        = {2018-04-09},
  eprint      = {1804.02907},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1804.02907v1:PDF},
  keywords    = {math.OC},
}

@Article{BoumalEtAl2018Deterministic,
  author      = {Nicolas Boumal and Vladislav Voroninski and Afonso S. Bandeira},
  title       = {Deterministic guarantees for Burer-Monteiro factorizations of smooth semidefinite programs},
  journal     = {arXiv:1804.02008},
  year        = {2018},
  date        = {2018-04-05},
  eprint      = {1804.02008},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1804.02008v1:PDF},
  keywords    = {math.OC, math.NA},
}

@Article{ZhangXia2017Tensor,
  author      = {Anru Zhang and Dong Xia},
  title       = {Tensor SVD: Statistical and Computational Limits},
  journal     = {arXiv:1703.02724},
  year        = {2018},
  date        = {2017-03-08},
  eprint      = {1703.02724},
  eprintclass = {math.ST},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1703.02724v2:PDF},
  keywords    = {math.ST, cs.LG, stat.ME, stat.ML, stat.TH},
}

@Article{HaoEtAl2018Sparse,
  author      = {Botao Hao and Anru Zhang and Guang Cheng},
  title       = {Sparse and Low-rank Tensor Estimation via Cubic Sketchings},
  journal     = {arXiv:1801.09326},
  year        = {2018},
  date        = {2018-01-29},
  eprint      = {1801.09326},
  eprintclass = {math.ST},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1801.09326v1:PDF},
  keywords    = {math.ST, stat.ML, stat.TH},
}

@Article{MeiEtAl2018Mean,
  author      = {Song Mei and Andrea Montanari and Phan-Minh Nguyen},
  title       = {A Mean Field View of the Landscape of Two-Layers Neural Networks},
  journal     = {arXiv:1804.06561},
  year        = {2018},
  date        = {2018-04-18},
  eprint      = {1804.06561},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1804.06561v1:PDF},
  keywords    = {stat.ML, cs.LG, math.ST, stat.TH},
}

@Article{BartlettEtAl2018Representing,
  author      = {Peter L. Bartlett and Steven N. Evans and Philip M. Long},
  title       = {Representing smooth functions as compositions of near-identity functions with implications for deep network optimization},
  journal     = {arXiv:1804.05012},
  year        = {2018},
  date        = {2018-04-13},
  eprint      = {1804.05012},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1804.05012v2:PDF},
  keywords    = {cs.LG, cs.AI, cs.NE, math.ST, stat.ML, stat.TH},
}

@Article{DavisEtAl2018Stochastic,
  author      = {Damek Davis and Dmitriy Drusvyatskiy and Sham Kakade and Jason D. Lee},
  title       = {Stochastic subgradient method converges on tame functions},
  journal     = {arXiv:1804.07795},
  year        = {2018},
  date        = {2018-04-20},
  eprint      = {1804.07795},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1804.07795v1:PDF},
  keywords    = {math.OC, cs.LG, 65K05, 65K10, 90C15, 90C30},
}

@Article{LiuYin2018Envelope,
  author      = {Yanli Liu and Wotao Yin},
  title       = {An Envelope for Davis-Yin Splitting and Strict Saddle Point Avoidance},
  journal     = {arXiv:1804.08739},
  year        = {2018},
  date        = {2018-04-23},
  eprint      = {1804.08739},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1804.08739v1:PDF},
  keywords    = {math.OC},
}

@Article{KhamaruWainwright2018Convergence,
  author      = {Koulik Khamaru and Martin J. Wainwright},
  title       = {Convergence guarantees for a class of non-convex and non-smooth optimization problems},
  journal     = {arXiv:1804.09629},
  year        = {2018},
  date        = {2018-04-25},
  eprint      = {1804.09629},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1804.09629v1:PDF},
  keywords    = {stat.ML, cs.LG, math.OC},
}

@Article{AwasthiVijayaraghavan2018Towards,
  author      = {Pranjal Awasthi and Aravindan Vijayaraghavan},
  title       = {Towards Learning Sparsely Used Dictionaries with Arbitrary Supports},
  journal     = {arXiv:1804.08603},
  year        = {2018},
  date        = {2018-04-23},
  eprint      = {1804.08603},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1804.08603v1:PDF},
  keywords    = {cs.LG, cs.DS, stat.ML},
}

@Article{BurkeEtAl2018Gradient,
  author      = {James V. Burke and Frank E. Curtis and Adrian S. Lewis and Michael L. Overton and Lucas E. A. Simões},
  title       = {Gradient Sampling Methods for Nonsmooth Optimization},
  journal     = {arXiv:1804.11003},
  year        = {2018},
  date        = {2018-04-29},
  eprint      = {1804.11003v1},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1804.11003v1:PDF},
  keywords    = {math.OC},
}

@Article{VempalaWilmes2018Polynomial,
  author      = {Santosh Vempala and John Wilmes},
  title       = {Polynomial Convergence of Gradient Descent for Training One-Hidden-Layer Neural Networks},
  journal     = {arXiv:1805.02677},
  year        = {2018},
  date        = {2018-05-07},
  eprint      = {1805.02677},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.02677v1:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Article{ZhuEtAl2018Global,
  author      = {Zhihui Zhu and Daniel Soudry and Yonina C. Eldar and Michael B. Wakin},
  title       = {The Global Optimization Geometry of Shallow Linear Neural Networks},
  journal     = {arXiv:1805.04938},
  year        = {2018},
  date        = {2018-05-13},
  eprint      = {1805.04938},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.04938v1:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Article{AdolphsEtAl2018Local,
  author      = {Leonard Adolphs and Hadi Daneshmand and Aurelien Lucchi and Thomas Hofmann},
  title       = {Local Saddle Point Optimization: A Curvature Exploitation Approach},
  journal     = {arXiv:1805.05751},
  year        = {2018},
  date        = {2018-05-15},
  eprint      = {1805.05751},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.05751v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{LanYang2018Accelerated,
  author      = {Guanghui Lan and Yu Yang},
  title       = {Accelerated Stochastic Algorithms for Nonconvex Finite-sum and Multi-block Optimization},
  journal     = {arXiv:1805.05411},
  year        = {2018},
  date        = {2018-05-14},
  eprint      = {1805.05411},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.05411v1:PDF},
  keywords    = {math.OC},
}

@Article{ZhangZhang2018Cubic,
  author      = {Junyu Zhang and Shuzhong Zhang},
  title       = {A Cubic Regularized Newton's Method over Riemannian Manifolds},
  journal     = {arXiv:1805.05565},
  year        = {2018},
  date        = {2018-05-15},
  eprint      = {1805.05565},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.05565v1:PDF},
  keywords    = {math.OC},
}

@Article{EhrhardtEtAl2018geometric,
  author      = {Matthias J. Ehrhardt and Erlend S. Riis and Torbjørn Ringholm and Carola-Bibiane Schönlieb},
  title       = {A geometric integration approach to smooth optimisation: Foundations of the discrete gradient method},
  journal     = {arXiv:1805.06444},
  year        = {2018},
  date        = {2018-05-16},
  eprint      = {1805.06444},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.06444v1:PDF},
  keywords    = {math.OC, 49M37, 49Q15, 65K05, 65K10, 74S60, 90C15, 90C26, 90C30},
}

@Article{OymakSoltanolkotabi2018End,
  author      = {Samet Oymak and Mahdi Soltanolkotabi},
  title       = {End-to-end Learning of a Convolutional Neural Network via Deep Tensor Decomposition},
  journal     = {arXiv:1805.06523},
  year        = {2018},
  date        = {2018-05-16},
  eprint      = {1805.06523},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.06523v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{LiangEtAl2018Adding,
  author      = {Shiyu Liang and Ruoyu Sun and Jason D. Lee and R. Srikant},
  title       = {Adding One Neuron Can Eliminate All Bad Local Minima},
  journal     = {arXiv:1805.08671},
  year        = {2018},
  date        = {2018-05-22},
  eprint      = {1805.08671},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.08671v1:PDF},
  keywords    = {stat.ML, cs.LG},
}

@Article{SangLiu2018Adaptive,
  author      = {Hejian Sang and Jia Liu},
  title       = {Adaptive Stochastic Gradient Langevin Dynamics: Taming Convergence and Saddle Point Escape Time},
  journal     = {arXiv:1805.09416},
  year        = {2018},
  date        = {2018-05-23},
  eprint      = {1805.09416},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.09416v1:PDF},
  keywords    = {cs.LG, cs.AI, stat.ML},
}

@Article{DuGoel2018Improved,
  author      = {Simon S. Du and Surbhi Goel},
  title       = {Improved Learning of One-hidden-layer Convolutional Neural Networks with Overlaps},
  journal     = {arXiv:1805.07798},
  year        = {2018},
  date        = {2018-05-20},
  eprint      = {1805.07798},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.07798v1:PDF},
  keywords    = {cs.LG, cs.AI, cs.CV, cs.DS, stat.ML},
}

@Article{KawashimaFujisawa2018Stochastic,
  author      = {Takayuki Kawashima and Hironori Fujisawa},
  title       = {Stochastic Gradient Descent for Stochastic Doubly-Nonconvex Composite Optimization},
  journal     = {arXiv:1805.07960},
  year        = {2018},
  abstract    = {The stochastic gradient descent has been widely used for solving composite optimization problems in big data analyses. Many algorithms and convergence properties have been developed. The composite functions were convex primarily and gradually nonconvex composite functions have been adopted to obtain more desirable properties. The convergence properties have been investigated, but only when either of composite functions is nonconvex. There is no convergence property when both composite functions are nonconvex, which is named the \textit{doubly-nonconvex} case.To overcome this difficulty, we assume a simple and weak condition that the penalty function is \textit{quasiconvex} and then we obtain convergence properties for the stochastic doubly-nonconvex composite optimization problem.The convergence rate obtained here is of the same order as the existing work.We deeply analyze the convergence rate with the constant step size and mini-batch size and give the optimal convergence rate with appropriate sizes, which is superior to the existing work. Experimental results illustrate that our method is superior to existing methods.},
  date        = {2018-05-21},
  eprint      = {1805.07960},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.07960v1:PDF},
  keywords    = {stat.ML, cs.LG, math.OC},
}

@Article{HauserEftekhari2018PCA,
  author      = {Raphael H. Hauser and Armin Eftekhari},
  title       = {PCA by Optimisation of Symmetric Functions has no Spurious Local Optima},
  journal     = {arXiv:1805.07459},
  year        = {2018},
  abstract    = {Principal Component Analysis (PCA) finds the best linear representation of data, and is an indispensable tool in many learning and inference tasks. Classically, principal components of a dataset are interpreted as the directions that preserve most of its "energy", an interpretation that is theoretically underpinned by the celebrated Eckart-Young-Mirsky Theorem. This paper introduces many other ways of performing PCA, with various geometric interpretations, and proves that the corresponding family of non-convex programs have no spurious local optima; these programs therefore behave like convex problems and are amenable to a variety of convex solvers. Beyond providing new geometric interpretations and enhancing our theoretical understanding of PCA, our findings might pave the way for entirely new approaches to structured dimensionality reduction, such as sparse PCA and nonnegative matrix factorisation. More specifically, we study an unconstrained formulation of PCA using determinant optimisation that might provide an elegant alternative to the deflating scheme, commonly used in sparse PCA.},
  date        = {2018-05-18},
  eprint      = {1805.07459},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.07459v1:PDF},
  keywords    = {math.OC},
}

@Article{Hinder2018Cutting,
  author      = {Oliver Hinder},
  title       = {Cutting plane methods can be extended into nonconvex optimization},
  journal     = {arXiv:1805.08370},
  year        = {2018},
  abstract    = {We show that it is possible to obtain an $O(\epsilon^{-4/3})$ runtime --- including computational cost --- for finding $\epsilon$-stationary points of nonconvex functions using cutting plane methods. This improves on the best known epsilon dependence achieved by cubic regularized Newton of $O(\epsilon^{-3/2})$ as proved by Nesterov and Polyak (2006)\nocite{nesterov2006cubic}. Our techniques utilize the convex until proven guilty principle proposed by Carmon, Duchi, Hinder, and Sidford (2017)\nocite{carmon2017convex}.},
  date        = {2018-05-22},
  eprint      = {1805.08370},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.08370v1:PDF},
  keywords    = {math.OC, cs.CC},
}

@Article{BaiMei2018Connection,
  author      = {Yu Bai and Song Mei},
  title       = {On the Connection Between Sequential Quadratic Programming and Riemannian Gradient Methods},
  journal     = {arXiv:1805.08756},
  year        = {2018},
  date        = {2018-05-22},
  eprint      = {1805.08756},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.08756v1:PDF},
  keywords    = {math.OC},
}

@Article{JoszEtAl2018theory,
  author      = {Cedric Josz and Yi Ouyang and Richard Zhang and Javad Lavaei and Somayeh Sojoudi},
  title       = {A theory on the absence of spurious optimality},
  journal     = {arXiv:1805.08204},
  year        = {2018},
  date        = {2018-05-21},
  eprint      = {1805.08204},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.08204v1:PDF},
  keywords    = {math.OC, 90C26},
}

@Article{JinEtAl2018Minimizing,
  author      = {Chi Jin and Lydia T. Liu and Rong Ge and Michael I. Jordan},
  title       = {Minimizing Nonconvex Population Risk from Rough Empirical Risk},
  journal     = {arXiv:1803.09357},
  year        = {2018},
  date        = {2018-03-25},
  eprint      = {1803.09357},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1803.09357v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{LiBresler2018Global,
  author      = {Yanjun Li and Yoram Bresler},
  title       = {Global Geometry of Multichannel Sparse Blind Deconvolution on the Sphere},
  journal     = {arXiv:1805.10437},
  year        = {2018},
  date        = {2018-05-26},
  eprint      = {1805.10437},
  eprintclass = {cs.IT},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.10437v1:PDF},
  keywords    = {cs.IT, cs.CV, cs.LG, math.IT, math.OC},
}

@Article{LiHuang2018Guaranteed,
  author      = {Jialin Li and Furong Huang},
  title       = {Guaranteed Simultaneous Asymmetric Tensor Decomposition via Orthogonalized Alternating Least Squares},
  journal     = {arXiv:1805.10348},
  year        = {2018},
  date        = {2018-05-25},
  eprint      = {1805.10348},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.10348v1:PDF},
  keywords    = {stat.ML, cs.LG},
}

@Article{ZhangEtAl2018How,
  author      = {Richard Y. Zhang and Cédric Josz and Somayeh Sojoudi and Javad Lavaei},
  title       = {How Much Restricted Isometry is Needed In Nonconvex Matrix Recovery?},
  journal     = {arXiv:1805.10251},
  year        = {2018},
  date        = {2018-05-25},
  eprint      = {1805.10251},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.10251v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{WardEtAl2018AdaGrad,
  author      = {Rachel Ward and Xiaoxia Wu and Leon Bottou},
  title       = {AdaGrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization},
  journal     = {arXiv:1806.01811},
  year        = {2018},
  date        = {2018-06-05},
  eprint      = {http://arxiv.org/abs/1806.01811},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.01811v2:PDF},
  keywords    = {stat.ML, cs.LG, 90C26},
}

@Article{AgarwalEtAl2018Adaptive,
  author      = {Naman Agarwal and Nicolas Boumal and Brian Bullins and Coralia Cartis},
  title       = {Adaptive regularization with cubics on manifolds with a first-order analysis},
  journal     = {arXiv:1806.00065},
  year        = {2018},
  date        = {2018-05-31},
  eprint      = {http://arxiv.org/abs/1806.00065},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.00065v1:PDF},
  keywords    = {math.OC},
}

@Article{ZhangEtAl2018Structured,
  author      = {Yuqian Zhang and Han-Wen Kuo and John Wright},
  title       = {Structured Local Optima in Sparse Blind Deconvolution},
  journal     = {arXiv:1806.00338},
  year        = {2018},
  date        = {2018-06-01},
  eprint      = {http://arxiv.org/abs/1806.00338},
  eprintclass = {eess.SP},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.00338v1:PDF},
  keywords    = {eess.SP, cs.IT, math.IT, math.OC, stat.ML},
}

@Article{KyrillidisEtAl2018Run,
  author      = {Anastasios Kyrillidis and Shashanka Ubaru and Georgios Kollias and Kristofer Bouchard},
  title       = {Run Procrustes, Run! On the convergence of accelerated Procrustes Flow},
  journal     = {arXiv:1806.00534},
  year        = {2018},
  date        = {2018-06-01},
  eprint      = {http://arxiv.org/abs/1806.00534},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.00534v1:PDF},
  keywords    = {cs.LG, cs.DS, cs.IT, math.IT, math.OC, stat.ML},
}

@Article{DuEtAl2018Algorithmic,
  author      = {Simon S. Du and Wei Hu and Jason D. Lee},
  title       = {Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced},
  journal     = {arXiv:1806.00900},
  year        = {2018},
  date        = {2018-06-04},
  eprint      = {http://arxiv.org/abs/1806.00900},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.00900v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{FerreiraEtAl2018Gradient,
  author      = {O. P. Ferreira and M. S. Louzeiro and L. F. Prudente},
  title       = {Gradient Method for Optimization on Riemannian Manifolds with Lower Bounded Curvature},
  journal     = {arXiv:1806.02694},
  year        = {2018},
  date        = {2018-06-07},
  eprint      = {http://arxiv.org/abs/1806.02694},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.02694v1:PDF},
  keywords    = {math.OC, 90C33, 49K05, 47J25},
}

@Article{ZhangSra2018Towards,
  author      = {Hongyi Zhang and Suvrit Sra},
  title       = {Towards Riemannian Accelerated Gradient Methods},
  journal     = {arXiv:1806.02812},
  year        = {2018},
  date        = {2018-06-07},
  eprint      = {http://arxiv.org/abs/1806.02812},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.02812v1:PDF},
  keywords    = {math.OC, cs.LG},
}

@Article{HuangXu2018Solving,
  author      = {Meng Huang and Zhiqiang Xu},
  title       = {Solving Systems of Quadratic Equations via Exponential-type Gradient Descent Algorithm},
  journal     = {arXiv:1806.00904},
  year        = {2018},
  date        = {2018-06-04},
  eprint      = {http://arxiv.org/abs/1806.00904},
  eprintclass = {math.NA},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.00904v1:PDF},
  keywords    = {math.NA, cs.IT, math.IT},
}

@Article{GhodsEtAl2018Linear,
  author      = {Ramina Ghods and Andrew S. Lan and Tom Goldstein and Christoph Studer},
  title       = {Linear Spectral Estimators and an Application to Phase Retrieval},
  journal     = {arXiv:1806.03547},
  year        = {2018},
  date        = {2018-06-09},
  eprint      = {http://arxiv.org/abs/1806.03547},
  eprintclass = {cs.IT},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.03547v1:PDF},
  keywords    = {cs.IT, eess.SP, math.IT, stat.ML},
}

@Article{MaEtAl2018Approximate,
  author      = {Junjie Ma and Ji Xu and Arian Maleki},
  title       = {Approximate Message Passing for Amplitude Based Optimization},
  journal     = {arXiv:1806.03276},
  year        = {2018},
  date        = {2018-06-08},
  eprint      = {http://arxiv.org/abs/1806.03276},
  eprintclass = {cs.IT},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.03276v1:PDF},
  keywords    = {cs.IT, math.IT},
}

@Article{ChenEtAl2018Landscape,
  author      = {Zhehui Chen and Xingguo Li and Lin F. Yang and Jarvis Haupt and Tuo Zhao},
  title       = {On Landscape of Lagrangian Functions and Stochastic Search for Constrained Nonconvex Optimization},
  journal     = {arXiv:1806.05151},
  year        = {2018},
  date        = {2018-06-13},
  eprint      = {http://arxiv.org/abs/1806.05151},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.05151v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{ZhangHe2018Convergence,
  author      = {Siqi Zhang and Niao He},
  title       = {On the Convergence Rate of Stochastic Mirror Descent for Nonsmooth Nonconvex Optimization},
  journal     = {arXiv:1806.04781},
  year        = {2018},
  date        = {2018-06-12},
  eprint      = {http://arxiv.org/abs/1806.04781},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.04781v1:PDF},
  keywords    = {math.OC},
}

@Article{PumirEtAl2018Smoothed,
  author      = {Thomas Pumir and Samy Jelassi and Nicolas Boumal},
  title       = {Smoothed analysis of the low-rank approach for smooth semidefinite programs},
  journal     = {arXiv:1806.03763},
  year        = {2018},
  date        = {2018-06-11},
  eprint      = {http://arxiv.org/abs/1806.03763},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.03763v1:PDF},
  keywords    = {stat.ML, cs.LG, math.OC},
}

@Article{Vishnoi2018Geodesic,
  author      = {Nisheeth K. Vishnoi},
  title       = {Geodesic Convex Optimization: Differentiation on Manifolds, Geodesics, and Convexity},
  journal     = {arXiv:1806.06373},
  year        = {2018},
  date        = {2018-06-17},
  eprint      = {http://arxiv.org/abs/1806.06373},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.06373v1:PDF},
  keywords    = {math.OC, cs.DS, cs.LG, math.DG},
}

@Article{JagatapHegde2018Learning,
  author      = {Gauri Jagatap and Chinmay Hegde},
  title       = {Learning ReLU Networks via Alternating Minimization},
  journal     = {arXiv:1806.07863},
  year        = {2018},
  date        = {2018-06-20},
  eprint      = {http://arxiv.org/abs/1806.07863},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.07863v1:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Article{ZhangEtAl2018Learning,
  author      = {Xiao Zhang and Yaodong Yu and Lingxiao Wang and Quanquan Gu},
  title       = {Learning One-hidden-layer ReLU Networks via Gradient Descent},
  journal     = {arXiv:1806.07808},
  year        = {2018},
  date        = {2018-06-20},
  eprint      = {http://arxiv.org/abs/1806.07808},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1806.07808v1:PDF},
  keywords    = {stat.ML, cs.LG},
}

@Article{ErdogduEtAl2018Convergence,
  author      = {Murat A. Erdogdu and Asuman Ozdaglar and Pablo A. Parrilo and Nuri Denizcan Vanli},
  title       = {Convergence Rate of Block-Coordinate Maximization Burer-Monteiro Method for Solving Large SDPs},
  journal     = {arXiv:1807.04428},
  year        = {2018},
  date        = {2018-07-12},
  eprint      = {http://arxiv.org/abs/1807.04428},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1807.04428v1:PDF},
  keywords    = {math.OC, cs.LG, stat.ML},
}

@Article{RiisEtAl2018geometric,
  author      = {Erlend S. Riis and Matthias J. Ehrhardt and G. R. W. Quispel and Carola-Bibiane Schönlieb},
  title       = {A geometric integration approach to nonsmooth, nonconvex optimisation},
  journal     = {arXiv:1807.07554},
  year        = {2018},
  date        = {2018-07-19},
  eprint      = {http://arxiv.org/abs/1807.07554},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1807.07554v1:PDF},
  keywords    = {math.OC, 49M25, 49Q15, 65K10, 90C15, 90C26, 90C56, 94A08},
}

@Article{EhrhardtEtAl2018geometrica,
  author      = {Matthias J. Ehrhardt and Erlend S. Riis and Torbjørn Ringholm and Carola-Bibiane Schönlieb},
  title       = {A geometric integration approach to smooth optimisation: Foundations of the discrete gradient method},
  journal     = {arXiv:1805.06444},
  year        = {2018},
  date        = {2018-05-16},
  eprint      = {http://arxiv.org/abs/1805.06444},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.06444v1:PDF},
  keywords    = {math.OC, 49M37, 49Q15, 65K05, 65K10, 74S60, 90C15, 90C26, 90C30},
}

@Article{JiangLi2018linear,
  author      = {Rujun Jiang and Duan Li},
  title       = {A linear-time algorithm for generalized trust region problems},
  journal     = {arXiv:1807.07563},
  year        = {2018},
  date        = {2018-07-19},
  eprint      = {http://arxiv.org/abs/1807.07563},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1807.07563v1:PDF},
  keywords    = {math.OC},
}

@Article{AndreaniEtAl2010Second,
  author    = {Andreani, R. and Birgin, E. G. and Martínez, J. M. and Schuverdt, M. L.},
  title     = {Second-order negative-curvature methods for box-constrained and general constrained optimization},
  journal   = {Computational Optimization and Applications},
  year      = {2010},
  volume    = {45},
  number    = {2},
  pages     = {209},
  month     = mar,
  issn      = {1573-2894},
  abstract  = {A Nonlinear Programming algorithm that converges to second-order stationary points is introduced in this paper. The main tool is a second-order negative-curvature method for box-constrained minimization of a certain class of functions that do not possess continuous second derivatives. This method is used to define an Augmented Lagrangian algorithm of PHR (Powell-Hestenes-Rockafellar) type. Convergence proofs under weak constraint qualifications are given. Numerical examples showing that the new method converges to second-order stationary points in situations in which first-order methods fail are exhibited.},
  date      = {2010-03-01},
  doi       = {10.1007/s10589-009-9240-y},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/s10589-009-9240-y},
}

@Article{ArousEtAl2018Algorithmic,
  author      = {Gerard Ben Arous and Reza Gheissari and Aukosh Jagannath},
  title       = {Algorithmic thresholds for tensor PCA},
  journal     = {arXiv:1808.00921},
  year        = {2018},
  abstract    = {We study the algorithmic thresholds for principal component analysis of Gaussian $k$-tensors with a planted rank-one spike, via Langevin dynamics and gradient descent. In order to efficiently recover the spike from natural initializations, the signal to noise ratio must diverge in the dimension. Our proof shows that the mechanism for the success/failure of recovery is the strength of the "curvature" of the spike on the maximum entropy region of the initial data. To demonstrate this, we study the dynamics on a generalized family of high-dimensional landscapes with planted signals, containing the spiked tensor models as specific instances. We identify thresholds of signal-to-noise ratios above which order 1 time recovery succeeds; in the case of the spiked tensor model these match the thresholds conjectured for algorithms such as Approximate Message Passing. Below these thresholds, where the curvature of the signal on the maximal entropy region is weak, we show that recovery from certain natural initializations takes at least stretched exponential time. Our approach combines global regularity estimates for spin glasses with point-wise estimates, to study the recovery problem by a perturbative approach.},
  date        = {2018-08-02},
  eprint      = {http://arxiv.org/abs/1808.00921},
  eprintclass = {math.PR},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1808.00921v1:PDF},
  keywords    = {math.PR, math.ST, stat.TH},
}

@Article{LiLiang2018Learning,
  author      = {Yuanzhi Li and Yingyu Liang},
  title       = {Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data},
  journal     = {arXiv:1808.01204},
  year        = {2018},
  date        = {2018-08-03},
  eprint      = {http://arxiv.org/abs/1808.01204},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1808.01204v1:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Article{ChenEtAl2018Convergence,
  author      = {Xiangyi Chen and Sijia Liu and Ruoyu Sun and Mingyi Hong},
  title       = {On the Convergence of A Class of Adam-Type Algorithms for Non-Convex Optimization},
  journal     = {arXiv:1808.02941},
  year        = {2018},
  abstract    = {This paper studies a class of adaptive gradient based momentum algorithms that update the search directions and learning rates simultaneously using past gradients. This class, which we refer to as the "Adam-type", includes the popular algorithms such as the Adam, AMSGrad and AdaGrad. Despite their popularity in training deep neural networks, the convergence of these algorithms for solving nonconvex problems remains an open question. This paper provides a set of mild sufficient conditions that guarantee the convergence for the Adam-type methods. We prove that under our derived conditions, these methods can achieve the convergence rate of order $O(\log{T}/\sqrt{T})$ for nonconvex stochastic optimization. We show the conditions are essential in the sense that violating them may make the algorithm diverge. Moreover, we propose and analyze a class of (deterministic) incremental adaptive gradient algorithms, which has the same $O(\log{T}/\sqrt{T})$ convergence rate. Our study could also be extended to a broader class of adaptive gradient methods in machine learning and optimization.},
  date        = {2018-08-08},
  eprint      = {http://arxiv.org/abs/1808.02941},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1808.02941v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{OuyangXu2018Lower,
  author      = {Yuyuan Ouyang and Yangyang Xu},
  title       = {Lower complexity bounds of first-order methods for convex-concave bilinear saddle-point problems},
  journal     = {arXiv:1808.02901},
  year        = {2018},
  abstract    = {On solving a convex-concave bilinear saddle-point problem (SPP), there have been many works studying the complexity results of first-order methods. These results are all about upper complexity bounds, which can determine at most how many efforts would guarantee a solution of desired accuracy. In this paper, we pursue the opposite direction by deriving lower complexity bounds of first-order methods on large-scale SPPs. Our results apply to the methods whose iterates are in the linear span of past first-order information, as well as more general methods that produce their iterates in an arbitrary manner based on first-order information. We first work on the affinely constrained smooth convex optimization that is a special case of SPP. Different from gradient method on unconstrained problems, we show that first-order methods on affinely constrained problems generally cannot be accelerated from the known convergence rate $O(1/t)$ to $O(1/t^2)$, and in addition, $O(1/t)$ is optimal for convex problems. Moreover, we prove that for strongly convex problems, $O(1/t^2)$ is the best possible convergence rate, while it is known that gradient methods can have linear convergence on unconstrained problems. Then we extend these results to general SPPs. It turns out that our lower complexity bounds match with several established upper complexity bounds in the literature, and thus they are tight and indicate the optimality of several existing first-order methods.},
  date        = {2018-08-08},
  eprint      = {http://arxiv.org/abs/1808.02901},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1808.02901v1:PDF},
  keywords    = {math.OC, 90C25, 90C06, 90C60, 49M37, 68Q25},
}

@Article{Cooper2018Discrete,
  author      = {Y. Cooper},
  title       = {Discrete gradient descent differs qualitatively from gradient flow},
  journal     = {arXiv:1808.04839},
  year        = {2018},
  abstract    = {We consider gradient descent on functions of the form $L_1 = |f|$ and $L_2 = f^2$, where $f: \mathbb{R}^n \rightarrow \mathbb{R}$ is any smooth function with 0 as a regular value. We show that gradient descent implemented with a discrete step size $\tau$ behaves qualitatively differently from continuous gradient descent. We show that over long time scales, continuous and discrete gradient descent on $L_1$ find different minima of $L_1$, and we can characterize the difference - the minima that tend to be found by discrete gradient descent lie in a secondary critical submanifold $M' \subset M$, the locus within $M$ where the function $K=|\nabla f|^2 \big|_M$ is minimized. In this paper, we explain this behavior. We also study the more subtle behavior of discrete gradient descent on $L_2$.},
  date        = {2018-08-14},
  eprint      = {http://arxiv.org/abs/1808.04839},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1808.04839v1:PDF},
  keywords    = {math.OC, cs.LG, math.DS, stat.ML},
}

@Article{WangEtAl2018Learning,
  author      = {Gang Wang and Georgios B. Giannakis and Jie Chen},
  title       = {Learning ReLU Networks on Linearly Separable Data: Algorithm, Optimality, and Generalization},
  journal     = {arXiv:1808.04685},
  year        = {2018},
  abstract    = {Neural networks with ReLU activations have achieved great empirical success in various domains. However, existing results for learning ReLU networks either pose assumptions on the underlying data distribution being e.g. Gaussian, or require the network size and/or training size to be sufficiently large. In this context, the problem of learning a two-layer ReLU network is approached in a binary classification setting, where the data are linearly separable and a hinge loss criterion is adopted. Leveraging the power of random noise, this contribution presents a novel stochastic gradient descent (SGD) algorithm, which can provably train any single-hidden-layer ReLU network to attain global optimality, despite the presence of infinitely many bad local minima and saddle points in general. This result is the first of its kind, requiring no assumptions on the data distribution, training/network size, or initialization. Convergence of the resultant iterative algorithm to a global minimum is analyzed by establishing both an upper bound and a lower bound on the number of effective (non-zero) updates to be performed. Furthermore, generalization guarantees are developed for ReLU networks trained with the novel SGD. These guarantees highlight a fundamental difference (at least in the worst case) between learning a ReLU network as well as a leaky ReLU network in terms of sample complexity. Numerical tests using synthetic data and real images validate the effectiveness of the algorithm and the practical merits of the theory.},
  date        = {2018-08-14},
  eprint      = {http://arxiv.org/abs/1808.04685},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1808.04685v1:PDF},
  keywords    = {stat.ML, cs.IT, cs.LG, math.IT, math.OC},
}

@Article{ZhouEtAl2018Convergence,
  author      = {Dongruo Zhou and Yiqi Tang and Ziyan Yang and Yuan Cao and Quanquan Gu},
  title       = {On the Convergence of Adaptive Gradient Methods for Nonconvex Optimization},
  journal     = {arXiv:1808.05671},
  year        = {2018},
  abstract    = {Adaptive gradient methods are workhorses in deep learning. However, the convergence guarantees of adaptive gradient methods for nonconvex optimization have not been sufficiently studied. In this paper, we provide a sharp analysis of a recently proposed adaptive gradient method namely partially adaptive momentum estimation method (Padam) (Chen and Gu, 2018), which admits many existing adaptive gradient methods such as AdaGrad, RMSProp and AMSGrad as special cases. Our analysis shows that, for smooth nonconvex functions, Padam converges to a first-order stationary point at the rate of $O\big((\sum_{i=1}^d\|\mathbf{g}_{1:T,i}\|_2)^{1/2}/T^{3/4} + d/T\big)$, where $T$ is the number of iterations, $d$ is the dimension, $\mathbf{g}_1,\ldots,\mathbf{g}_T$ are the stochastic gradients, and $\mathbf{g}_{1:T,i} = [g_{1,i},g_{2,i},\ldots,g_{T,i}]^\top$. Our theoretical result also suggests that in order to achieve faster convergence rate, it is necessary to use Padam instead of AMSGrad. This is well-aligned with the empirical results of deep learning reported in Chen and Gu (2018).},
  date        = {2018-08-16},
  eprint      = {http://arxiv.org/abs/1808.05671},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1808.05671v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{BellaviaEtAl2018Theoretical,
  author      = {Stefania Bellavia and Gianmarco Gurioli and Benedetta Morini},
  title       = {Theoretical study of an adaptive cubic regularization method with dynamic inexact Hessian information},
  journal     = {arXiv:1808.06239},
  year        = {2018},
  abstract    = {We consider the Adaptive Regularization with Cubics approach for solving nonconvex optimization problems and propose a new variant based on inexact Hessian information chosen dynamically. The theoretical analysis of the proposed procedure is given. The key property of ARC framework, constituted by optimal worst-case function/derivative evaluation bounds for first- and second-order critical point, is guaranteed. Application to large-scale finite-sum minimization based on sub-sampled Hessian is discussed and analyzed in both a deterministic and probabilistic manner.},
  date        = {2018-08-19},
  eprint      = {http://arxiv.org/abs/1808.06239},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1808.06239v1:PDF},
  keywords    = {math.OC, math.NA},
}

@Article{FerreiraEtAl2018Iteration,
  author      = {O. P. Ferreira and M. S. Louzeiro and L. F. Prudente},
  title       = {Iteration-Complexity of the Subgradient Method on Riemannian Manifolds with Lower Bounded Curvature},
  journal     = {arXiv:1808.06274},
  year        = {2018},
  abstract    = {The subgradient method for convex optimization problems on complete Riemannian manifolds with lower bounded sectional curvature is analyzed in this paper. Iteration-complexity bounds of the subgradient method with exogenous step-size and Polyak's step-size are stablished, completing and improving recent results on the subject.},
  date        = {2018-08-20},
  eprint      = {http://arxiv.org/abs/1808.06274},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1808.06274v1:PDF},
  keywords    = {math.OC, 90c},
}

@Article{ZhouEtAl2018Convergencea,
  author      = {Yi Zhou and Zhe Wang and Yingbin Liang},
  title       = {Convergence of Cubic Regularization for Nonconvex Optimization under KL Property},
  journal     = {arXiv:1808.07382},
  year        = {2018},
  abstract    = {Cubic-regularized Newton's method (CR) is a popular algorithm that guarantees to produce a second-order stationary solution for solving nonconvex optimization problems. However, existing understandings of the convergence rate of CR are conditioned on special types of geometrical properties of the objective function. In this paper, we explore the asymptotic convergence rate of CR by exploiting the ubiquitous Kurdyka-Lojasiewicz (KL) property of nonconvex objective functions. In specific, we characterize the asymptotic convergence rate of various types of optimality measures for CR including function value gap, variable distance gap, gradient norm and least eigenvalue of the Hessian matrix. Our results fully characterize the diverse convergence behaviors of these optimality measures in the full parameter regime of the KL property. Moreover, we show that the obtained asymptotic convergence rates of CR are order-wise faster than those of first-order gradient descent algorithms under the KL property.},
  date        = {2018-08-22},
  eprint      = {http://arxiv.org/abs/1808.07382},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1808.07382v1:PDF},
  keywords    = {math.OC, cs.LG, stat.ML},
}

@Article{WangEtAl2018Note,
  author      = {Zhe Wang and Yi Zhou and Yingbin Liang and Guanghui Lan},
  title       = {A Note on Inexact Condition for Cubic Regularized Newton's Method},
  journal     = {arXiv:1808.07384},
  year        = {2018},
  abstract    = {This note considers the inexact cubic-regularized Newton's method (CR), which has been shown in \cite{Cartis2011a} to achieve the same order-level convergence rate to a secondary stationary point as the exact CR \citep{Nesterov2006}. However, the inexactness condition in \cite{Cartis2011a} is not implementable due to its dependence on future iterates variable. This note fixes such an issue by proving the same convergence rate for nonconvex optimization under an inexact adaptive condition that depends on only the current iterate. Our proof controls the sufficient decrease of the function value over the total iterations rather than each iteration as used in the previous studies, which can be of independent interest in other contexts.},
  date        = {2018-08-22},
  eprint      = {http://arxiv.org/abs/1808.07384},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1808.07384v1:PDF},
  keywords    = {math.OC, cs.LG},
}

@Article{Hu2018,
  author      = {Jiang Hu and Bo Jiang and Lin Lin and Zaiwen Wen and Yaxiang Yuan},
  title       = {Structured Quasi-Newton Methods for Optimization with Orthogonality Constraints},
  journal     = {arXiv:1809.00452},
  year        = {2018},
  date        = {2018-09-03},
  eprint      = {http://arxiv.org/abs/1809.00452},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.00452v1:PDF},
  keywords    = {math.OC},
}

@Article{Cotter2018,
  author      = {Andrew Cotter and Heinrich Jiang and Serena Wang and Taman Narayan and Maya Gupta and Seungil You and Karthik Sridharan},
  title       = {Optimization with Non-Differentiable Constraints with Applications to Fairness, Recall, Churn, and Other Goals},
  journal     = {arXiv:1809.04198},
  year        = {2018},
  date        = {2018-09-11},
  eprint      = {http://arxiv.org/abs/1809.04198},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.04198v1:PDF},
  keywords    = {cs.LG, cs.AI, cs.GT, math.OC, stat.ML},
}

@Article{Mokhtari2018,
  author      = {Aryan Mokhtari and Asuman Ozdaglar and Ali Jadbabaie},
  title       = {Escaping Saddle Points in Constrained Optimization},
  journal     = {arXiv:1809.02162},
  year        = {2018},
  date        = {2018-09-06},
  eprint      = {http://arxiv.org/abs/1809.02162},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.02162v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{Nesterov2018,
  author      = {Yurii Nesterov and Alexander Gasnikov and Sergey Guminov and Pavel Dvurechensky},
  title       = {Primal-dual accelerated gradient descent with line search for convex and nonconvex optimization problems},
  journal     = {arXiv:1809.05895},
  year        = {2018},
  date        = {2018-09-16},
  eprint      = {http://arxiv.org/abs/1809.05895},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.05895v1:PDF},
  keywords    = {math.OC},
}

@Article{Gao2018,
  author      = {Xuefeng Gao and Mert Gürbüzbalaban and Lingjiong Zhu},
  title       = {Global Convergence of Stochastic Gradient Hamiltonian Monte Carlo for Non-Convex Stochastic Optimization: Non-Asymptotic Performance Bounds and Momentum-Based Acceleration},
  journal     = {arXiv:1809.04618},
  year        = {2018},
  date        = {2018-09-12},
  eprint      = {http://arxiv.org/abs/1809.04618},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.04618v1:PDF},
  keywords    = {math.OC, cs.LG},
}

@Article{Sun2018,
  author      = {Tao Sun and Yuejiao Sun and Wotao Yin},
  title       = {On Markov Chain Gradient Descent},
  journal     = {arXiv:1809.04216},
  year        = {2018},
  date        = {2018-09-12},
  eprint      = {http://arxiv.org/abs/1809.04216},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.04216v1:PDF},
  keywords    = {math.OC, stat.ML},
}

@Article{Cai2018,
  author      = {Jian-Feng Cai and Ke Wei},
  title       = {Solving systems of phaseless equations via Riemannian optimization with optimal sampling complexity},
  journal     = {arXiv:1809.02773},
  year        = {2018},
  date        = {2018-09-08},
  eprint      = {http://arxiv.org/abs/1809.02773},
  eprintclass = {math.NA},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.02773v1:PDF},
  keywords    = {math.NA},
}

@Article{Cooper2018,
  author      = {Y. Cooper},
  title       = {Secondary gradient descent in higher codimension},
  journal     = {arXiv:1809.05527},
  year        = {2018},
  date        = {2018-09-14},
  eprint      = {http://arxiv.org/abs/1809.05527},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.05527v1:PDF},
  keywords    = {math.OC, cs.LG, math.DS, stat.ML},
}

@Article{Oymak2018,
  author      = {Samet Oymak},
  title       = {Stochastic Gradient Descent Learns State Equations with Nonlinear Activations},
  journal     = {arXiv:1809.03019},
  year        = {2018},
  date        = {2018-09-09},
  eprint      = {http://arxiv.org/abs/1809.03019},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.03019v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{Ramezani-Kebrya2018,
  author      = {Ali Ramezani-Kebrya and Ashish Khisti and Ben Liang},
  title       = {On the Stability and Convergence of Stochastic Gradient Descent with Momentum},
  journal     = {arXiv:1809.04564},
  year        = {2018},
  date        = {2018-09-12},
  eprint      = {http://arxiv.org/abs/1809.04564},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.04564v1:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Article{Dong2018,
  author      = {Jialin Dong and Yuanming Shi},
  title       = {Nonconvex Demixing From Bilinear Measurements},
  journal     = {arXiv:1809.06796},
  year        = {2018},
  date        = {2018-09-18},
  eprint      = {http://arxiv.org/abs/1809.06796},
  eprintclass = {cs.IT},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.06796v1:PDF},
  keywords    = {cs.IT, cs.LG, math.IT, stat.ML},
}

@Article{Balasubramanian2018,
  author      = {Krishnakumar Balasubramanian and Saeed Ghadimi},
  title       = {Zeroth-order (Non)-Convex Stochastic Optimization via Conditional Gradient and Gradient Updates},
  journal     = {arXiv:1809.06474},
  year        = {2018},
  date        = {2018-09-17},
  eprint      = {http://arxiv.org/abs/1809.06474},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.06474v1:PDF},
  keywords    = {math.OC, cs.LG, stat.ML},
}

@Article{Lindstrom2018,
  author      = {Scott B. Lindstrom and Brailey Sims},
  title       = {Survey: Sixty Years of Douglas--Rachford},
  journal     = {arXiv:1809.07181},
  year        = {2018},
  date        = {2018-09-19},
  eprint      = {http://arxiv.org/abs/1809.07181},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.07181v1:PDF},
  keywords    = {math.OC, 49J53, 46N10, 49-02, 49-03, 49Mxx},
}

@Article{Wang2018,
  author      = {Hao Wang and Jiashan Wang and Yuyang Rong and Hudie Zhou},
  title       = {An Inexact First-order Method for Constrained Nonlinear Optimization},
  journal     = {arXiv:1809.06704},
  year        = {2018},
  date        = {2018-09-15},
  eprint      = {http://arxiv.org/abs/1809.06704},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.06704v1:PDF},
  keywords    = {math.OC},
}

@Article{LiEtAl2018Towards,
  author      = {Zhenzhen Li and Jian-Feng Cai and Ke Wei},
  title       = {Towards the optimal construction of a loss function without spurious local minima for solving quadratic equations},
  journal     = {arXiv:1809.10520},
  year        = {2018},
  date        = {2018-09-27},
  eprint      = {http://arxiv.org/abs/1809.10520},
  eprintclass = {cs.IT},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.10520v1:PDF},
  keywords    = {cs.IT, math.IT},
}

@Article{LiEtAl2018Nonconvexa,
  author      = {Xiao Li and Zhihui Zhu and Anthony Man-Cho So and Rene Vidal},
  title       = {Nonconvex Robust Low-rank Matrix Recovery},
  journal     = {arXiv:1809.09237},
  year        = {2018},
  date        = {2018-09-24},
  eprint      = {http://arxiv.org/abs/1809.09237},
  eprintclass = {cs.IT},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.09237v1:PDF},
  keywords    = {cs.IT, math.IT},
}

@Article{GilboaEtAl2018Efficient,
  author      = {Dar Gilboa and Sam Buchanan and John Wright},
  title       = {Efficient Dictionary Learning with Gradient Descent},
  journal     = {arXiv:1809.10313},
  year        = {2018},
  date        = {2018-09-27},
  eprint      = {http://arxiv.org/abs/1809.10313},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.10313v1:PDF},
  keywords    = {math.OC},
}

@Article{LiuEtAl2018Stochastic,
  author      = {Liu Liu and Xuanqing Liu and Cho-Jui Hsieh and Dacheng Tao},
  title       = {Stochastic Second-order Methods for Non-convex Optimization with Inexact Hessian and Gradient},
  journal     = {arXiv:1809.09853},
  year        = {2018},
  date        = {2018-09-26},
  eprint      = {http://arxiv.org/abs/1809.09853},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.09853v1:PDF},
  keywords    = {math.OC, cs.LG, stat.ML},
}

@Article{BomzeEtAl2018Hessian,
  author      = {Immanuel M. Bomze and Panayotis Mertikopoulos and Werner Schachinger and Mathias Staudigl},
  title       = {Hessian barrier algorithms for linearly constrained optimization problems},
  journal     = {arXiv:1809.09449},
  year        = {2018},
  date        = {2018-09-25},
  eprint      = {http://arxiv.org/abs/1809.09449},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.09449v1:PDF},
  keywords    = {math.OC, cs.LG, Primary: 90C51, 90C30, secondary: 90C25, 90C26},
}

@Article{ChiEtAl2018Nonconvex,
  author      = {Yuejie Chi and Yue M. Lu and Yuxin Chen},
  title       = {Nonconvex Optimization Meets Low-Rank Matrix Factorization: An Overview},
  journal     = {arXiv:1809.09573},
  year        = {2018},
  date        = {2018-09-25},
  eprint      = {http://arxiv.org/abs/1809.09573},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.09573v1:PDF},
  keywords    = {cs.LG, cs.IT, eess.SP, math.IT, math.OC, math.ST, stat.ML, stat.TH},
}

@Article{RafiqueEtAl2018Non,
  author      = {Hassan Rafique and Mingrui Liu and Qihang Lin and Tianbao Yang},
  title       = {Non-Convex Min-Max Optimization: Provable Algorithms and Applications in Machine Learning},
  journal     = {arXiv:1810.02060},
  year        = {2018},
  date        = {2018-10-04},
  eprint      = {http://arxiv.org/abs/1810.02060},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.02060v1:PDF},
  keywords    = {math.OC, cs.LG},
}

@Article{NouiehedEtAl2018Convergence,
  author      = {Maher Nouiehed and Jason D. Lee and Meisam Razaviyayn},
  title       = {Convergence to Second-Order Stationarity for Constrained Non-Convex Optimization},
  journal     = {arXiv:1810.02024},
  year        = {2018},
  date        = {2018-10-04},
  eprint      = {http://arxiv.org/abs/1810.02024},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.02024v1:PDF},
  keywords    = {math.OC},
}

@Article{DuEtAl2018Gradient,
  author      = {Simon S. Du and Xiyu Zhai and Barnabas Poczos and Aarti Singh},
  title       = {Gradient Descent Provably Optimizes Over-parameterized Neural Networks},
  journal     = {arXiv:1810.02054},
  year        = {2018},
  date        = {2018-10-04},
  eprint      = {http://arxiv.org/abs/1810.02054},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.02054v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{JiTelgarsky2018Gradient,
  author      = {Ziwei Ji and Matus Telgarsky},
  title       = {Gradient descent aligns the layers of deep linear networks},
  journal     = {arXiv:1810.02032},
  year        = {2018},
  date        = {2018-10-04},
  eprint      = {http://arxiv.org/abs/1810.02032},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.02032v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{RoostaEtAl2018Newton,
  author      = {Fred Roosta and Yang Liu and Peng Xu and Michael W. Mahoney},
  title       = {Newton-MR: Newton's Method Without Smoothness or Convexity},
  journal     = {arXiv:1810.00303},
  year        = {2018},
  date        = {2018-09-30},
  eprint      = {http://arxiv.org/abs/1810.00303},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.00303v1:PDF},
  keywords    = {math.OC, cs.LG},
}

@Article{LingEtAl2018Landscape,
  author      = {Shuyang Ling and Ruitu Xu and Afonso S. Bandeira},
  title       = {On the Landscape of Synchronization Networks: A Perspective from Nonconvex Optimization},
  journal     = {arXiv:1809.11083},
  year        = {2018},
  date        = {2018-09-28},
  eprint      = {http://arxiv.org/abs/1809.11083},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.11083v1:PDF},
  keywords    = {math.OC},
}

@Article{BecigneulGanea2018Riemannian,
  author      = {Gary Bécigneul and Octavian-Eugen Ganea},
  title       = {Riemannian Adaptive Optimization Methods},
  journal     = {arXiv:1810.00760},
  year        = {2018},
  date        = {2018-10-01},
  eprint      = {http://arxiv.org/abs/1810.00760},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.00760v1:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Article{DengEtAl2018Optimal,
  author      = {Qi Deng and Yi Cheng and Guanghui Lan},
  title       = {Optimal Adaptive and Accelerated Stochastic Gradient Descent},
  journal     = {arXiv:1810.00553},
  year        = {2018},
  date        = {2018-10-01},
  eprint      = {http://arxiv.org/abs/1810.00553},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.00553v1:PDF},
  keywords    = {stat.ML, cs.LG},
}

@Article{AroraEtAl2018Convergence,
  author      = {Sanjeev Arora and Nadav Cohen and Noah Golowich and Wei Hu},
  title       = {A Convergence Analysis of Gradient Descent for Deep Linear Neural Networks},
  journal     = {arXiv:1810.02281},
  year        = {2018},
  date        = {2018-10-04},
  eprint      = {http://arxiv.org/abs/1810.02281},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.02281v1:PDF},
  keywords    = {cs.LG, cs.NE, stat.ML},
}

@Article{LukeEtAl2018Optimization,
  author      = {D. Russell Luke and Shoham Sabach and Marc Teboulle},
  title       = {Optimization on Spheres: Models and Proximal Algorithms with Computational Performance Comparisons},
  journal     = {arXiv:1810.02893},
  year        = {2018},
  date        = {2018-10-05},
  eprint      = {http://arxiv.org/abs/1810.02893},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.02893v1:PDF},
  keywords    = {math.OC},
}

@Article{XiongEtAl2018Analytical,
  author      = {Huaqing Xiong and Yuejie Chi and Bin Hu and Wei Zhang},
  title       = {Analytical Convergence Regions of Accelerated First-Order Methods in Nonconvex Optimization under Regularity Condition},
  journal     = {arXiv:1810.03229},
  year        = {2018},
  date        = {2018-10-07},
  eprint      = {http://arxiv.org/abs/1810.03229},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.03229v1:PDF},
  keywords    = {math.OC},
}

@Article{DeyEtAl2018ReLU,
  author      = {Santanu S. Dey and Guanyi Wang and Yao Xie},
  title       = {ReLU Regression: Complexity, Exact and Approximation Algorithms},
  journal     = {arXiv:1810.03592},
  year        = {2018},
  date        = {2018-10-08},
  eprint      = {http://arxiv.org/abs/1810.03592},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.03592v1:PDF},
  keywords    = {math.OC},
}

@Article{WangEtAl2018Cubic,
  author      = {Zhe Wang and Yi Zhou and Yingbin Liang and Guanghui Lan},
  title       = {Cubic Regularization with Momentum for Nonconvex Optimization},
  journal     = {arXiv:1810.03763},
  year        = {2018},
  date        = {2018-10-09},
  eprint      = {http://arxiv.org/abs/1810.03763},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.03763v1:PDF},
  keywords    = {math.OC, cs.LG, stat.ML},
}

@Article{GaoEtAl2018Parallelizable,
  author      = {Bin Gao and Xin Liu and Ya-xiang Yuan},
  title       = {Parallelizable Algorithms for Optimization Problems with Orthogonality Constraints},
  journal     = {arXiv:1810.03930},
  year        = {2018},
  date        = {2018-10-09},
  eprint      = {http://arxiv.org/abs/1810.03930},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.03930v1:PDF},
  keywords    = {math.OC, 15A18, 65F15, 65K05, 90C06},
}

@Article{Hegde2018Algorithmic,
  author      = {Chinmay Hegde},
  title       = {Algorithmic Aspects of Inverse Problems Using Generative Models},
  journal     = {arXiv:1810.03587},
  year        = {2018},
  date        = {2018-10-08},
  eprint      = {http://arxiv.org/abs/1810.03587},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.03587v1:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Article{KwonCaramanis2018Global,
  author      = {Jeongyeol Kwon and Constantine Caramanis},
  title       = {Global Convergence of EM Algorithm for Mixtures of Two Component Linear Regression},
  journal     = {arXiv:1810.05752},
  year        = {2018},
  date        = {2018-10-12},
  eprint      = {http://arxiv.org/abs/1810.05752},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.05752v1:PDF},
  keywords    = {stat.ML, cs.LG, math.ST, stat.TH},
}

@Article{DavisDrusvyatskiy2018Uniform,
  author      = {Damek Davis and Dmitriy Drusvyatskiy},
  title       = {Uniform Graphical Convergence of Subgradients in Nonconvex Optimization and Learning},
  journal     = {arXiv:1810.07590},
  year        = {2018},
  date        = {2018-10-17},
  eprint      = {http://arxiv.org/abs/1810.07590},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.07590v1:PDF},
  keywords    = {math.OC, cs.LG, 65K10, 90C15, 68Q32},
}

@Article{BergouEtAl2018Subsampling,
  author      = {El-houcine Bergou and Youssef Diouane and Vyacheslav Kungurtsev and Clément W. Royer},
  title       = {A Subsampling Line-Search Method with Second-Order Results},
  journal     = {arXiv:1810.07211},
  year        = {2018},
  date        = {2018-10-16},
  eprint      = {http://arxiv.org/abs/1810.07211},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.07211v1:PDF},
  keywords    = {math.OC},
}

@Article{GeEtAl2018Learning,
  author      = {Rong Ge and Rohith Kuditipudi and Zhize Li and Xiang Wang},
  title       = {Learning Two-layer Neural Networks with Symmetric Inputs},
  journal     = {arXiv:1810.06793},
  year        = {2018},
  date        = {2018-10-16},
  eprint      = {http://arxiv.org/abs/1810.06793},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.06793v1:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Article{HeckelEtAl2018Deep,
  author      = {Reinhard Heckel and Wen Huang and Paul Hand and Vladislav Voroninski},
  title       = {Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior},
  journal     = {arXiv:1805.08855},
  year        = {2018},
  abstract    = {Deep neural networks provide state-of-the-art performance for image denoising, where the goal is to map a noisy image to a near noise-free image. The underlying principle is simple: images are well described by priors that map a low-dimensional latent representations to image. Based on a prior, a noisy image can be denoised by finding a close image in the range of the prior. Since deep networks trained on large set of images have empirically been shown to be good priors, they enable effective denoisers. However, there is little theory to justify this success, let alone to predict the denoising performance. In this paper we consider the problem of denoising an image from additive Gaussian noise with variance $\sigma^2$, assuming the image is well described by a deep neural network with ReLu activations functions, mapping a $k$-dimensional latent space to an $n$-dimensional image. We provide an iterative algorithm minimizing a non-convex loss that provably removes noise energy by a fraction $\sigma^2 k/n$. We also demonstrate in numerical experiments that this denoising performance is, indeed, achieved by generative priors learned from data.},
  date        = {2018-05-22},
  eprint      = {http://arxiv.org/abs/1805.08855},
  eprintclass = {cs.IT},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1805.08855v1:PDF},
  keywords    = {cs.IT, cs.LG, eess.SP, math.IT, math.OC},
}

@Article{QuEtAl2014Finding,
  author       = {Qing Qu and Ju Sun and John Wright},
  title        = {Finding a sparse vector in a subspace: Linear sparsity using alternating directions},
  journal      = {IEEE Transaction on Information Theory},
  year         = {2016},
  volume       = {62},
  number       = {10},
  pages        = {5855--5880},
  date         = {2014-12-15},
  doi          = {10.1109/TIT.2016.2601599},
  eprint       = {http://arxiv.org/abs/1412.4659},
  eprintclass  = {cs.IT},
  eprinttype   = {arXiv},
  file         = {:http\://arxiv.org/pdf/1412.4659v3:PDF},
  journaltitle = {IEEE Transaction on Information Theory, 62(10):5855 - 5880, 2016},
  keywords     = {cs.IT, cs.CV, cs.LG, math.IT, math.OC, stat.ML},
}

@Article{DavisEtAl2018Subgradient,
  author      = {Damek Davis and Dmitriy Drusvyatskiy and Kellie J. MacPhee and Courtney Paquette},
  title       = {Subgradient methods for sharp weakly convex functions},
  journal     = {arXiv:1803.02461},
  year        = {2018},
  abstract    = {Subgradient methods converge linearly on a convex function that grows sharply away from its solution set. In this work, we show that the same is true for sharp functions that are only weakly convex, provided that the subgradient methods are initialized within a fixed tube around the solution set. A variety of statistical and signal processing tasks come equipped with good initialization, and provably lead to formulations that are both weakly convex and sharp. Therefore, in such settings, subgradient methods can serve as inexpensive local search procedures. We illustrate the proposed techniques on phase retrieval and covariance estimation problems.},
  date        = {2018-03-06},
  eprint      = {http://arxiv.org/abs/1803.02461},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1803.02461v1:PDF},
  keywords    = {math.OC, 65K05, 65K10, 90C15, 90C30},
}

@Article{KawaguchiBengio2018Depth,
  author      = {Kenji Kawaguchi and Yoshua Bengio},
  title       = {Depth with Nonlinearity Creates No Bad Local Minima in ResNets},
  journal     = {arXiv:1810.09038},
  year        = {2018},
  date        = {2018-10-21},
  eprint      = {http://arxiv.org/abs/1810.09038},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.09038v1:PDF},
  keywords    = {stat.ML, cs.AI, cs.LG, math.OC},
}

@Article{LinEtAl2018Solving,
  author      = {Qihang Lin and Mingrui Liu and Hassan Rafique and Tianbao Yang},
  title       = {Solving Weakly-Convex-Weakly-Concave Saddle-Point Problems as Weakly-Monotone Variational Inequality},
  journal     = {arXiv:1810.10207},
  year        = {2018},
  date        = {2018-10-24},
  eprint      = {http://arxiv.org/abs/1810.10207},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.10207v1:PDF},
  keywords    = {math.OC, stat.ML},
}

@Article{WangEtAl2018SpiderBoost,
  author      = {Zhe Wang and Kaiyi Ji and Yi Zhou and Yingbin Liang and Vahid Tarokh},
  title       = {SpiderBoost: A Class of Faster Variance-reduced Algorithms for Nonconvex Optimization},
  journal     = {arXiv:1810.10690},
  year        = {2018},
  date        = {2018-10-25},
  eprint      = {http://arxiv.org/abs/1810.10690},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.10690v1:PDF},
  keywords    = {math.OC, cs.LG, stat.ML},
}

@Article{BaiEtAl2018Subgradient,
  author      = {Yu Bai and Qijia Jiang and Ju Sun},
  title       = {Subgradient Descent Learns Orthogonal Dictionaries},
  journal     = {arXiv:1810.10702},
  year        = {2018},
  date        = {2018-10-25},
  eprint      = {http://arxiv.org/abs/1810.10702},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.10702v1:PDF},
  keywords    = {cs.LG, cs.IT, math.IT, math.OC, stat.ML},
}

@Article{FoucartSubramanian2018Iterative,
  author      = {Simon Foucart and Srinivas Subramanian},
  title       = {Iterative Hard Thresholding for Low-Rank Recovery from Rank-One Projections},
  journal     = {arXiv:1810.11749},
  year        = {2018},
  date        = {2018-10-28},
  eprint      = {http://arxiv.org/abs/1810.11749},
  eprintclass = {math.NA},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.11749v1:PDF},
  keywords    = {math.NA, 15A18, 15A29, 65F10, 94A12},
}

@Article{FosterEtAl2018Uniform,
  author      = {Dylan J. Foster and Ayush Sekhari and Karthik Sridharan},
  title       = {Uniform Convergence of Gradients for Non-Convex Learning and Optimization},
  journal     = {arXiv:1810.11059},
  year        = {2018},
  date        = {2018-10-25},
  eprint      = {http://arxiv.org/abs/1810.11059},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.11059v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{OliveiraFerreira2018Newton,
  author      = {Fabiana R. de Oliveira and Orizon P. Ferreira},
  title       = {Newton method for finding a singularity of a special class of locally Lipschitz continuous vector fields on Riemannian manifolds},
  journal     = {arXiv:1810.11636},
  year        = {2018},
  date        = {2018-10-27},
  eprint      = {http://arxiv.org/abs/1810.11636},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.11636v1:PDF},
  keywords    = {math.OC},
}

@Article{OliveiraFerreira2018Inexact,
  author      = {Fabiana R. de Oliveira and Orizon P. Ferreira},
  title       = {Inexact Newton method with feasible inexact projections for solving constrained smooth and nonsmooth equations},
  journal     = {arXiv:1810.11640},
  year        = {2018},
  date        = {2018-10-27},
  eprint      = {http://arxiv.org/abs/1810.11640},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.11640v1:PDF},
  keywords    = {math.OC},
}

@Article{Allen-ZhuEtAl2018Convergence,
  author      = {Zeyuan Allen-Zhu and Yuanzhi Li and Zhao Song},
  title       = {On the Convergence Rate of Training Recurrent Neural Networks},
  journal     = {arXiv:1810.12065},
  year        = {2018},
  date        = {2018-10-29},
  eprint      = {http://arxiv.org/abs/1810.12065},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.12065v1:PDF},
  keywords    = {cs.LG, cs.DS, cs.NE, math.OC, stat.ML},
}

@Article{ZhangEtAl2018Recovery,
  author      = {Hongyang Zhang and Vatsal Sharan and Moses Charikar and Yingyu Liang},
  title       = {Recovery Guarantees for Quadratic Tensors with Limited Observations},
  journal     = {arXiv:1811.00148},
  year        = {2018},
  date        = {2018-10-31},
  eprint      = {http://arxiv.org/abs/1811.00148},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.00148v1:PDF},
  keywords    = {cs.LG, cs.DS, stat.ML},
}

@Article{KakadeLee2018Provably,
  author      = {Sham Kakade and Jason D. Lee},
  title       = {Provably Correct Automatic Subdifferentiation for Qualified Programs},
  journal     = {arXiv:1809.08530},
  year        = {2018},
  date        = {2018-09-23},
  eprint      = {http://arxiv.org/abs/1809.08530},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1809.08530v1:PDF},
  keywords    = {math.OC, cs.LG, stat.ML},
}

@Article{XuEtAl2018Benefits,
  author      = {Ji Xu and Daniel Hsu and Arian Maleki},
  title       = {Benefits of over-parameterization with EM},
  journal     = {arXiv:1810.11344},
  year        = {2018},
  date        = {2018-10-26},
  eprint      = {http://arxiv.org/abs/1810.11344},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.11344v1:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Article{ShenSanghavi2018Iteratively,
  author      = {Yanyao Shen and Sujay Sanghavi},
  title       = {Iteratively Learning from the Best},
  journal     = {arXiv:1810.11874},
  year        = {2018},
  date        = {2018-10-28},
  eprint      = {http://arxiv.org/abs/1810.11874},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.11874v1:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Article{ErdogduEtAl2018Global,
  author      = {Murat A. Erdogdu and Lester Mackey and Ohad Shamir},
  title       = {Global Non-convex Optimization with Discretized Diffusions},
  journal     = {arXiv:1810.12361},
  year        = {2018},
  date        = {2018-10-29},
  eprint      = {http://arxiv.org/abs/1810.12361},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.12361v1:PDF},
  keywords    = {stat.ML, cs.LG, stat.CO},
}

@Article{BassilyEtAl2018exponential,
  author      = {Raef Bassily and Mikhail Belkin and Siyuan Ma},
  title       = {On exponential convergence of SGD in non-convex over-parametrized learning},
  journal     = {arXiv:1811.02564},
  year        = {2018},
  date        = {2018-11-06},
  eprint      = {http://arxiv.org/abs/1811.02564},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.02564v1:PDF},
  keywords    = {math.OC, cs.LG, stat.ML},
}

@Article{DrusvyatskiyLewis2018Inexact,
  author      = {Dmitriy Drusvyatskiy and Adrian S. Lewis},
  title       = {Inexact alternating projections on nonconvex sets},
  journal     = {arXiv:1811.01298},
  year        = {2018},
  date        = {2018-11-03},
  eprint      = {http://arxiv.org/abs/1811.01298},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.01298v1:PDF},
  keywords    = {math.OC, 49M20, 65K10, 90C30},
}

@Article{CartisEtAl2018Sharp,
  author      = {Coralia Cartis and Nick I. M. Gould and Philippe L. Toint},
  title       = {Sharp worst-case evaluation complexity bounds for arbitrary-order nonconvex optimization with inexpensive constraints},
  journal     = {arXiv:1811.01220},
  year        = {2018},
  date        = {2018-11-03},
  eprint      = {http://arxiv.org/abs/1811.01220},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.01220v1:PDF},
  keywords    = {math.OC, cs.AI, cs.CC, math.NA, 49K10, 49M37, 65K05, 65Y20, 68T05, 68W40, F.1.3, F.2.1, G.1.6, I.2.6},
}

@Article{ChenEtAl2018Proximal,
  author      = {Shixiang Chen and Shiqian Ma and Anthony Man-Cho So and Tong Zhang},
  title       = {Proximal Gradient Method for Manifold Optimization},
  journal     = {arXiv:1811.00980},
  year        = {2018},
  date        = {2018-11-02},
  eprint      = {http://arxiv.org/abs/1811.00980},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.00980v1:PDF},
  keywords    = {math.OC, stat.ML},
}

@Article{YangEtAl2014Optimality,
  author  = {Yang, Wei Hong and Zhang, Lei-Hong and Song, Ruyi},
  title   = {Optimality conditions for the nonlinear programming problems on Riemannian manifolds},
  journal = {Pacific Journal of Optimization},
  year    = {2014},
  volume  = {10},
  number  = {2},
  pages   = {415--434},
}

@Article{BakshiEtAl2018Learning,
  author      = {Ainesh Bakshi and Rajesh Jayaram and David P. Woodruff},
  title       = {Learning Two Layer Rectified Neural Networks in Polynomial Time},
  journal     = {arXiv:1811.01885},
  year        = {2018},
  date        = {2018-11-05},
  eprint      = {http://arxiv.org/abs/1811.01885},
  eprintclass = {cs.DS},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.01885v1:PDF},
  keywords    = {cs.DS, cs.LG},
}

@Article{DuEtAl2018Gradienta,
  author      = {Simon S. Du and Jason D. Lee and Haochuan Li and Liwei Wang and Xiyu Zhai},
  title       = {Gradient Descent Finds Global Minima of Deep Neural Networks},
  journal     = {arXiv:1811.03804},
  year        = {2018},
  date        = {2018-11-09},
  eprint      = {http://arxiv.org/abs/1811.03804},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.03804v1:PDF},
  keywords    = {cs.LG, cs.AI, cs.CV, math.OC, stat.ML},
}

@Article{Allen-ZhuEtAl2018Convergencea,
  author      = {Zeyuan Allen-Zhu and Yuanzhi Li and Zhao Song},
  title       = {A Convergence Theory for Deep Learning via Over-Parameterization},
  journal     = {arXiv:1811.03962},
  year        = {2018},
  date        = {2018-11-09},
  eprint      = {http://arxiv.org/abs/1811.03962},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.03962v2:PDF},
  keywords    = {cs.LG, cs.DS, cs.NE, math.OC, stat.ML},
}

@Article{Allen-ZhuEtAl2018Learning,
  author      = {Zeyuan Allen-Zhu and Yuanzhi Li and Yingyu Liang},
  title       = {Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers},
  journal     = {arXiv:1811.04918},
  year        = {2018},
  date        = {2018-11-12},
  eprint      = {http://arxiv.org/abs/1811.04918},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.04918v1:PDF},
  keywords    = {cs.LG, cs.DS, cs.NE, math.OC, stat.ML},
}

@Article{ZhangEtAl2018R,
  author      = {Jingzhao Zhang and Hongyi Zhang and Suvrit Sra},
  title       = {R-SPIDER: A Fast Riemannian Stochastic Optimization Algorithm with Curvature Independent Rate},
  journal     = {arXiv:1811.04194},
  year        = {2018},
  date        = {2018-11-10},
  eprint      = {http://arxiv.org/abs/1811.04194},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.04194v1:PDF},
  keywords    = {math.OC, cs.LG},
}

@Article{BellaviaEtAl2018Deterministic,
  author      = {S. Bellavia and G. Gurioli and B. Morini and Ph. L. Toint},
  title       = {Deterministic and stochastic inexact regularization algorithms for nonconvex optimization with optimal complexity},
  journal     = {arXiv:1811.03831},
  year        = {2018},
  date        = {2018-11-09},
  eprint      = {http://arxiv.org/abs/1811.03831},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.03831v2:PDF},
  keywords    = {math.OC, cs.AI, cs.CC, 49K10, 49M37, 65K05, 68T05, 68W40, F.1.3; F.2.1; G.1.6; I.2.6},
}

@Article{DongEtAl2018Blind,
  author      = {Jialin Dong and Yuanming Shi and Zhi Ding},
  title       = {Blind Over-the-Air Computation and Data Fusion via Provable Wirtinger Flow},
  journal     = {arXiv:1811.04644},
  year        = {2018},
  date        = {2018-11-12},
  eprint      = {http://arxiv.org/abs/1811.04644},
  eprintclass = {cs.IT},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.04644v1:PDF},
  keywords    = {cs.IT, math.IT, stat.ML},
}

@Article{LuoEtAl2018Optimal,
  author      = {Wangyu Luo and Wael Alghamdi and Yue M. Lu},
  title       = {Optimal Spectral Initialization for Signal Recovery with Applications to Phase Retrieval},
  journal     = {arXiv:1811.04420},
  year        = {2018},
  date        = {2018-11-11},
  eprint      = {http://arxiv.org/abs/1811.04420},
  eprintclass = {cs.IT},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.04420v1:PDF},
  keywords    = {cs.IT, math.IT},
}

@Article{FangEtAl2018SPIDER,
  author      = {Cong Fang and Chris Junchi Li and Zhouchen Lin and Tong Zhang},
  title       = {SPIDER: Near-Optimal Non-Convex Optimization via Stochastic Path Integrated Differential Estimator},
  journal     = {arXiv:1807.01695},
  year        = {2018},
  date        = {2018-07-04},
  eprint      = {http://arxiv.org/abs/1807.01695},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1807.01695v2:PDF},
  keywords    = {math.OC, cs.LG, stat.ML},
}

@Article{ZouEtAl2018Stochastic,
  author      = {Difan Zou and Yuan Cao and Dongruo Zhou and Quanquan Gu},
  title       = {Stochastic Gradient Descent Optimizes Over-parameterized Deep ReLU Networks},
  journal     = {arXiv:1811.08888},
  year        = {2018},
  date        = {2018-11-21},
  eprint      = {http://arxiv.org/abs/1811.08888},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.08888v1:PDF},
  keywords    = {cs.LG, cs.AI, math.OC, stat.ML},
}

@Article{ZhouEtAl2018Faster,
  author      = {Pan Zhou and Xiao-Tong Yuan and Jiashi Feng},
  title       = {Faster First-Order Methods for Stochastic Non-Convex Optimization on Riemannian Manifolds},
  journal     = {arXiv:1811.08109},
  year        = {2018},
  date        = {2018-11-20},
  eprint      = {http://arxiv.org/abs/1811.08109},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.08109v1:PDF},
  keywords    = {math.OC},
}

@Article{KawaguchiEtAl2018Effect,
  author      = {Kenji Kawaguchi and Jiaoyang Huang and Leslie Pack Kaelbling},
  title       = {Effect of Depth and Width on Local Minima in Deep Learning},
  journal     = {arXiv:1811.08150},
  year        = {2018},
  date        = {2018-11-20},
  eprint      = {http://arxiv.org/abs/1811.08150},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.08150v1:PDF},
  keywords    = {cs.LG, cs.NE, math.OC, stat.ML},
}

@Article{CartisEtAl2018Universal,
  author      = {Coralia Cartis and Nicholas I. M. Gould and Philippe L. Toint},
  title       = {Universal regularization methods - varying the power, the smoothness and the accuracy},
  journal     = {arXiv:1811.07057},
  year        = {2018},
  date        = {2018-11-16},
  eprint      = {http://arxiv.org/abs/1811.07057},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.07057v1:PDF},
  keywords    = {math.OC},
}

@Article{MaEtAl2018Sampling,
  author      = {Yi-An Ma and Yuansi Chen and Chi Jin and Nicolas Flammarion and Michael I. Jordan},
  title       = {Sampling Can Be Faster Than Optimization},
  journal     = {arXiv:1811.08413},
  year        = {2018},
  date        = {2018-11-20},
  eprint      = {http://arxiv.org/abs/1811.08413},
  eprintclass = {stat.ML},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.08413v1:PDF},
  keywords    = {stat.ML, cs.LG},
}

@Article{TraonmilinAujol2018basins,
  author      = {Yann Traonmilin and Jean-François Aujol},
  title       = {The basins of attraction of the global minimizers of the non-convex sparse spikes estimation problem},
  journal     = {arXiv:1811.12000},
  year        = {2018},
  date        = {2018-11-29},
  eprint      = {http://arxiv.org/abs/1811.12000},
  eprintclass = {cs.IT},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.12000v1:PDF},
  keywords    = {cs.IT, math.IT},
}

@Article{SunEtAl2018Markov,
  author      = {Tao Sun and Yuejiao Sun and Yangyang Xu and Wotao Yin},
  title       = {Markov Chain Block Coordinate Descent},
  journal     = {arXiv:1811.08990},
  year        = {2018},
  date        = {2018-11-22},
  eprint      = {http://arxiv.org/abs/1811.08990},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.08990v1:PDF},
  keywords    = {math.OC, cs.LG, stat.ML},
}

@Article{XuEtAl2018Stochastic,
  author      = {Yi Xu and Qi Qi and Qihang Lin and Rong Jin and Tianbao Yang},
  title       = {Stochastic Optimization for DC Functions and Non-smooth Non-convex Regularizers with Non-asymptotic Convergence},
  journal     = {arXiv:1811.11829},
  year        = {2018},
  date        = {2018-11-28},
  eprint      = {http://arxiv.org/abs/1811.11829},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.11829v1:PDF},
  keywords    = {math.OC, stat.ML},
}

@Article{ZhangEtAl2018Adaptive,
  author      = {Junyu Zhang and Lin Xiao and Shuzhong Zhang},
  title       = {Adaptive Stochastic Variance Reduction for Subsampled Newton Method with Cubic Regularization},
  journal     = {arXiv:1811.11637},
  year        = {2018},
  date        = {2018-11-28},
  eprint      = {http://arxiv.org/abs/1811.11637},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.11637v1:PDF},
  keywords    = {math.OC},
}

@Article{LukeMartins2018Convergence,
  author      = {D. Russell Luke and Anna-Lena Martins},
  title       = {Convergence Analysis of the Relaxed Douglas-Rachford Algorithm},
  journal     = {arXiv:1811.11590},
  year        = {2018},
  date        = {2018-11-28},
  eprint      = {http://arxiv.org/abs/1811.11590},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.11590v1:PDF},
  keywords    = {math.OC, 65K10, 49K40, 49M05, 65K05, 90C26, 49M20, 49J53},
}

@Article{LiangMonteiro2018Doubly,
  author      = {Jiaming Liang and Renato D. C. Monteiro},
  title       = {A Doubly Accelerated Inexact Proximal Point Method for Nonconvex Composite Optimization Problems},
  journal     = {arXiv:1811.11378},
  year        = {2018},
  date        = {2018-11-28},
  eprint      = {http://arxiv.org/abs/1811.11378},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.11378v1:PDF},
  keywords    = {math.OC},
}

@Article{BhaskaraEtAl2018Smoothed,
  author      = {Aditya Bhaskara and Aidao Chen and Aidan Perreault and Aravindan Vijayaraghavan},
  title       = {Smoothed Analysis in Unsupervised Learning via Decoupling},
  journal     = {arXiv:1811.12361},
  year        = {2018},
  date        = {2018-11-29},
  eprint      = {http://arxiv.org/abs/1811.12361},
  eprintclass = {cs.DS},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.12361v1:PDF},
  keywords    = {cs.DS, cs.LG, stat.ML},
}

@Article{HaEtAl2018equivalence,
  author      = {Wooseok Ha and Haoyang Liu and Rina Foygel Barber},
  title       = {An equivalence between stationary points for rank constraints versus low-rank factorizations},
  journal     = {arXiv:1812.00404},
  year        = {2018},
  date        = {2018-12-02},
  eprint      = {http://arxiv.org/abs/1812.00404},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1812.00404v1:PDF},
  keywords    = {math.OC},
}

@Article{Zhang2018Phase,
  author      = {Teng Zhang},
  title       = {Phase Retrieval by Alternating Minimization with Random Initialization},
  journal     = {arXiv:1812.01255},
  year        = {2018},
  date        = {2018-12-04},
  eprint      = {http://arxiv.org/abs/1812.01255v},
  eprintclass = {math.ST},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1812.01255v1:PDF},
  keywords    = {math.ST, stat.TH},
}

@Article{SanjabiEtAl2018Solving,
  author      = {Maziar Sanjabi and Meisam Razaviyayn and Jason D. Lee},
  title       = {Solving Non-Convex Non-Concave Min-Max Games Under Polyak-Łojasiewicz Condition},
  journal     = {arXiv:1812.02878},
  year        = {2018},
  date        = {2018-12-07},
  eprint      = {http://arxiv.org/abs/1812.02878},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1812.02878v1:PDF},
  keywords    = {math.OC, cs.GT, cs.LG},
}

@Article{WaldspurgerWaters2018Rank,
  author      = {Irène Waldspurger and Alden Waters},
  title       = {Rank optimality for the Burer-Monteiro factorization},
  journal     = {arXiv:1812.03046},
  year        = {2018},
  date        = {2018-12-07},
  eprint      = {http://arxiv.org/abs/1812.03046},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1812.03046v1:PDF},
  keywords    = {math.OC},
}

@Article{HuangEtAl2018Provably,
  author      = {Wen Huang and Paul Hand and Reinhard Heckel and Vladislav Voroninski},
  title       = {A Provably Convergent Scheme for Compressive Sensing under Random Generative Priors},
  journal     = {arXiv:1812.04176},
  year        = {2018},
  date        = {2018-12-11},
  eprint      = {http://arxiv.org/abs/1812.04176},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1812.04176v1:PDF},
  keywords    = {math.OC},
}

@Article{GaoEtAl2018Semi,
  author      = {Tingran Gao and Lek-Heng Lim and Ke Ye},
  title       = {Semi-Riemannian Manifold Optimization},
  journal     = {arXiv:1812.07643},
  year        = {2018},
  date        = {2018-12-18},
  eprint      = {http://arxiv.org/abs/1812.07643},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1812.07643v1:PDF},
  keywords    = {math.OC, cs.NA, 90C30, 53C50, 53B30, 49M05, 49M15, F.2.1; G.1.6},
}

@Article{GaoEtAl2018Breaking,
  author      = {Xuefeng Gao and Mert Gurbuzbalaban and Lingjiong Zhu},
  title       = {Breaking Reversibility Accelerates Langevin Dynamics for Global Non-Convex Optimization},
  journal     = {arXiv:1812.07725},
  year        = {2018},
  date        = {2018-12-19},
  eprint      = {http://arxiv.org/abs/1812.07725},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1812.07725v1:PDF},
  keywords    = {math.OC, cs.LG, cs.NA, math.PR, stat.ML, 65K05, 90C26, 90C30, 82C31, 65C30},
}

@Article{ZhangLuo2018Proximal,
  author      = {Jiawei Zhang and Zhi-Quan Luo},
  title       = {A Proximal Alternating Direction Method of Multiplier for Linearly Constrained Nonconvex Minimization},
  journal     = {arXiv:1812.10229},
  year        = {2018},
  date        = {2018-12-26},
  eprint      = {http://arxiv.org/abs/1812.10229},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1812.10229v1:PDF},
  keywords    = {math.OC},
}

@Article{OymakSoltanolkotabi2018Overparameterized,
  author      = {Samet Oymak and Mahdi Soltanolkotabi},
  title       = {Overparameterized Nonlinear Learning: Gradient Descent Takes the Shortest Path?},
  journal     = {arXiv:1812.10004},
  year        = {2018},
  date        = {2018-12-25},
  eprint      = {http://arxiv.org/abs/1812.10004},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1812.10004v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{ZhuEtAl2018Dual,
  author      = {Zhihui Zhu and Yifan Wang and Daniel P. Robinson and Daniel Q. Naiman and Rene Vidal and Manolis C. Tsakiris},
  title       = {Dual Principal Component Pursuit: Probability Analysis and Efficient Algorithms},
  journal     = {arXiv:1812.09924},
  year        = {2018},
  date        = {2018-12-24},
  eprint      = {http://arxiv.org/abs/1812.09924},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1812.09924v1:PDF},
  keywords    = {cs.LG, cs.CV, math.OC},
}

@Article{KuoEtAl2019Geometry,
  author      = {Han-Wen Kuo and Yenson Lau and Yuqian Zhang and John Wright},
  title       = {Geometry and Symmetry in Short-and-Sparse Deconvolution},
  journal     = {arXiv:1901.00256},
  year        = {2019},
  date        = {2019-01-02},
  eprint      = {http://arxiv.org/abs/1901.00256},
  eprintclass = {eess.SP},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.00256v1:PDF},
  keywords    = {eess.SP, cs.LG, eess.IV, math.OC},
}

@Article{FattahiSojoudi2018Exact,
  author      = {Salar Fattahi and Somayeh Sojoudi},
  title       = {Exact Guarantees on the Absence of Spurious Local Minima for Non-negative Robust Principal Component Analysis},
  journal     = {arXiv:1812.11466},
  year        = {2018},
  date        = {2018-12-30},
  eprint      = {http://arxiv.org/abs/1812.11466},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1812.11466v1:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Article{LiEtAl2018Over,
  author      = {Dawei Li and Tian Ding and Ruoyu Sun},
  title       = {Over-Parameterized Deep Neural Networks Have No Strict Local Minima For Any Continuous Activations},
  journal     = {arXiv:1812.11039},
  year        = {2018},
  date        = {2018-12-28},
  eprint      = {http://arxiv.org/abs/1812.11039},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1812.11039v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{KawaguchiKaelbling2019Elimination,
  author      = {Kenji Kawaguchi and Leslie Pack Kaelbling},
  title       = {Elimination of All Bad Local Minima in Deep Learning},
  journal     = {arXiv:1901.00279},
  year        = {2019},
  date        = {2019-01-02},
  eprint      = {http://arxiv.org/abs/1901.00279},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.00279v1:PDF},
  keywords    = {cs.LG, cs.NE, math.OC, stat.ML},
}

@Article{MishchenkoRichtarik2018Stochastic,
  author      = {Konstantin Mishchenko and Peter Richtárik},
  title       = {A Stochastic Penalty Model for Convex and Nonconvex Optimization with Big Constraints},
  journal     = {arXiv:1810.13387},
  year        = {2018},
  date        = {2018-10-31},
  eprint      = {http://arxiv.org/abs/1810.13387},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1810.13387v1:PDF},
  keywords    = {math.OC},
}

@Article{ClasonEtAl2019Primal,
  author      = {Christian Clason and Stanislav Mazurenko and Tuomo Valkonen},
  title       = {Primal-dual proximal splitting and generalized conjugation in non-smooth non-convex optimization},
  journal     = {arXiv:1901.02746},
  year        = {2019},
  date        = {2019-01-09},
  eprint      = {http://arxiv.org/abs/1901.02746},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.02746v1:PDF},
  keywords    = {math.OC},
}

@Article{JavanmardEtAl2019Analysis,
  author      = {Adel Javanmard and Marco Mondelli and Andrea Montanari},
  title       = {Analysis of a Two-Layer Neural Network via Displacement Convexity},
  journal     = {arXiv:1901.01375},
  year        = {2019},
  date        = {2019-01-05},
  eprint      = {http://arxiv.org/abs/1901.01375},
  eprintclass = {math.ST},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.01375v1:PDF},
  keywords    = {math.ST, cs.LG, stat.TH},
}

@Article{ZhangEtAl2019Sharp,
  author      = {Richard Y. Zhang and Somayeh Sojoudi and Javad Lavaei},
  title       = {Sharp Restricted Isometry Bounds for the Inexistence of Spurious Local Minima in Nonconvex Matrix Recovery},
  journal     = {arXiv:1901.01631},
  year        = {2019},
  date        = {2019-01-07},
  eprint      = {http://arxiv.org/abs/1901.01631},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.01631v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{CharisopoulosEtAl2019Composite,
  author      = {Vasileios Charisopoulos and Damek Davis and Mateo Díaz and Dmitriy Drusvyatskiy},
  title       = {Composite optimization for robust blind deconvolution},
  journal     = {arXiv:1901.01624},
  year        = {2019},
  date        = {2019-01-06},
  eprint      = {http://arxiv.org/abs/1901.01624},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.01624v1:PDF},
  keywords    = {math.OC, cs.LG, math.ST, stat.TH, 65K10, 90C06},
}

@Article{ZhangEtAl2019Global,
  author      = {Yuqian Zhang and Yenson Lau and Han-Wen Kuo and Sky Cheung and Abhay Pasupathy and John Wright},
  title       = {On the Global Geometry of Sphere-Constrained Sparse Blind Deconvolution},
  journal     = {arXiv:1901.01913},
  year        = {2019},
  date        = {2019-01-07},
  eprint      = {http://arxiv.org/abs/1901.01913},
  eprintclass = {cs.CV},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.01913v1:PDF},
  keywords    = {cs.CV, cs.LG},
}

@Article{YonelYazici2019Generalization,
  author      = {Bariscan Yonel and Birsen Yazici},
  title       = {A Generalization of Wirtinger Flow for Exact Interferometric Inversion},
  journal     = {arXiv:1901.03940},
  year        = {2019},
  date        = {2019-01-13},
  eprint      = {http://arxiv.org/abs/1901.03940},
  eprintclass = {eess.SP},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.03940v1:PDF},
  keywords    = {eess.SP, cs.IT, math.IT},
}

@Article{GaoZhao2019Multi,
  author      = {Tingran Gao and Zhizhen Zhao},
  title       = {Multi-Frequency Phase Synchronization},
  journal     = {arXiv:1901.08235},
  year        = {2019},
  date        = {2019-01-24},
  eprint      = {http://arxiv.org/abs/1901.08235},
  eprintclass = {cs.IT},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.08235v1:PDF},
  keywords    = {cs.IT, cs.DS, math.IT, math.OC, math.ST, stat.TH, 94A12, 20C40, 22E70, 68P20, G.1.6},
}

@Article{NguyenEtAl2019Non,
  author      = {Thanh Huy Nguyen and Umut Şimşekli and Gaël Richard},
  title       = {Non-Asymptotic Analysis of Fractional Langevin Monte Carlo for Non-Convex Optimization},
  journal     = {arXiv:1901.07487},
  year        = {2019},
  date        = {2019-01-22},
  eprint      = {http://arxiv.org/abs/1901.07487},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.07487v1:PDF},
  keywords    = {math.OC, cs.LG, stat.ML},
}

@Article{NguyenEtAl2019DTN,
  author      = {Lam M. Nguyen and Phuong Ha Nguyen and Dzung T. Phan and Jayant R. Kalagnanam and Marten van Dijk},
  title       = {DTN: A Learning Rate Scheme with Convergence Rate of $\mathcal{O}(1/t)$ for SGD},
  journal     = {arXiv:1901.07634},
  year        = {2019},
  date        = {2019-01-22},
  eprint      = {http://arxiv.org/abs/1901.07634},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.07634v1:PDF},
  keywords    = {cs.LG, math.OC, stat.ML},
}

@Article{MetelTakeda2019Stochastic,
  author      = {Michael R. Metel and Akiko Takeda},
  title       = {Stochastic Gradient Methods for Non-Smooth Non-Convex Regularized Optimization},
  journal     = {arXiv:1901.08369},
  year        = {2019},
  date        = {2019-01-24},
  eprint      = {http://arxiv.org/abs/1901.08369},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.08369v1:PDF},
  keywords    = {math.OC},
}

@Article{MokhtariEtAl2019Unified,
  author      = {Aryan Mokhtari and Asuman Ozdaglar and Sarath Pattathil},
  title       = {A Unified Analysis of Extra-gradient and Optimistic Gradient Methods for Saddle Point Problems: Proximal Point Approach},
  journal     = {arXiv:1901.08511},
  year        = {2019},
  date        = {2019-01-24},
  eprint      = {http://arxiv.org/abs/1901.08511},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.08511v1:PDF},
  keywords    = {math.OC, cs.LG, stat.ML},
}

@Article{KalanEtAl2019Fitting,
  author      = {Seyed Mohammadreza Mousavi Kalan and Mahdi Soltanolkotabi and A. Salman Avestimehr},
  title       = {Fitting ReLUs via SGD and Quantized SGD},
  journal     = {arXiv:1901.06587},
  year        = {2019},
  date        = {2019-01-19},
  eprint      = {http://arxiv.org/abs/1901.06587},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.06587v1:PDF},
  keywords    = {cs.LG, cs.DC, cs.IT, math.IT, stat.ML},
}

@Article{KreusserEtAl2019Deterministic,
  author      = {Lisa Maria Kreusser and Stanley J. Osher and Bao Wang},
  title       = {A Deterministic Approach to Avoid Saddle Points},
  journal     = {arXiv:1901.06827},
  year        = {2019},
  date        = {2019-01-21},
  eprint      = {http://arxiv.org/abs/1901.06827},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.06827v1:PDF},
  keywords    = {cs.LG, math.DS, math.NA, stat.ML},
}

@Article{AroraEtAl2019Fine,
  author      = {Sanjeev Arora and Simon S. Du and Wei Hu and Zhiyuan Li and Ruosong Wang},
  title       = {Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks},
  journal     = {arXiv:1901.08584},
  year        = {2019},
  date        = {2019-01-24},
  eprint      = {http://arxiv.org/abs/1901.08584},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.08584v1:PDF},
  keywords    = {cs.LG, cs.NE, stat.ML},
}

@Article{DuHu2019Width,
  author      = {Simon S. Du and Wei Hu},
  title       = {Width Provably Matters in Optimization for Deep Linear Neural Networks},
  journal     = {arXiv:1901.08572},
  year        = {2019},
  date        = {2019-01-24},
  eprint      = {http://arxiv.org/abs/1901.08572},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1901.08572v1:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Article{Lezcano-CasadoMartinez-Rubio2019Cheap,
  author        = {Mario Lezcano-Casado and David Martínez-Rubio},
  title         = {Cheap Orthogonal Constraints in Neural Networks: A Simple Parametrization of the Orthogonal and Unitary Group},
  journal       = {arXiv:1901.08428},
  year          = {2019},
  __markedentry = {[sun:]},
  date          = {2019-01-24},
  eprint        = {http://arxiv.org/abs/1901.08428},
  eprintclass   = {cs.LG},
  eprinttype    = {arXiv},
  file          = {:http\://arxiv.org/pdf/1901.08428v1:PDF},
  keywords      = {cs.LG, stat.ML},
}

@Article{ChenEtAl2019Nonconvex,
  author        = {Ji Chen and Dekai Liu and Xiaodong Li},
  title         = {Nonconvex Rectangular Matrix Completion via Gradient Descent without $\ell_{2,\infty}$ Regularization},
  journal       = {arXiv:1901.06116},
  year          = {2019},
  __markedentry = {[sun:6]},
  date          = {2019-01-18},
  eprint        = {http://arxiv.org/abs/1901.06116},
  eprintclass   = {stat.ML},
  eprinttype    = {arXiv},
  file          = {:http\://arxiv.org/pdf/1901.06116v1:PDF},
  keywords      = {stat.ML, cs.LG},
}

@Comment{jabref-meta: databaseType:bibtex;}
