---
layout: page
title: "Provable Nonconvex Methods/Algorithms"
date: 2014-06-18 16:26
comments: true
sharing: true
footer: true
---
General nonconvex optimization is undoubtedly hard -- in sharp contrast to convex optimization, of which there is good separation of problem structure, input data, and optimization algorithms. But many nonconvex problems of interest become amenable to simple and practical algorithms and rigorous analyses once the artificial separation is removed. This page collects recent research effort in this line. (**Update: Feb 22 2016**)

\[<span style="color:red">**S**</span>\] indicates my contribution. 

## Problems with Hidden Convexity or Analytic Solutions
 #. [These slides](http://www.stat.cmu.edu/~ryantibs/convexopt/lectures/25-ncnp.pdf) summarize lots of them.  
 
### Blind Deconvolution
 #. [Blind Deconvolution using Convex Programming](http://arxiv.org/abs/1211.5608) (2012)

### Separable Nonnegative Matrix Factorization (NMF)
 #. [Intersecting Faces: Non-negative Matrix Factorization With New Guarantees](http://arxiv.org/abs/1507.02189) (2015)
 #. [The why and how of nonnegative matrix factorization](http://arxiv.org/abs/1401.5226) (2014)
 #. [Computing a Nonnegative Matrix Factorization -- Provably](http://arxiv.org/abs/1111.0952) (2011)

## Problems with Provable Global Results

### Matrix Completion/Sensing 
(See also [low-rank matrix/tensor recovery](/research/low-rank/) )   
 
 #. [A Note on Alternating Minimization Algorithm for the Matrix Completion Problem](http://arxiv.org/abs/1602.02164) (2016)
 #. [Recovery guarantee of weighted low-rank approximation via alternating minimization](http://arxiv.org/abs/1602.02262) (2016)
 #. [Guarantees of Riemannian Optimization for Low Rank Matrix Recovery](http://arxiv.org/abs/1511.01562) (2015)
 #. [Fast low-rank estimation by projected gradient descent: General statistical and algorithmic guarantees](http://arxiv.org/abs/1509.03025) (2015)
 #. [Low-rank Solutions of Linear Matrix Equations via Procrustes Flow](http://arxiv.org/abs/1507.03566) (2015)  
 #. [A Convergent Gradient Descent Algorithm for Rank Minimization and Semidefinite Programming from Random Linear Measurements](http://arxiv.org/abs/1506.06081) (2015) 
 #. [Guaranteed Matrix Completion via Non-convex Factorization](http://arxiv.org/abs/1411.8003) (2014)
 #. [Fast Exact Matrix Completion with Finite Samples](http://arxiv.org/abs/1411.1087) (2014)  
 #. [Non-convex Robust PCA](http://arxiv.org/abs/1410.7660) (2014)  
 #. [Fast Matrix Completion without the Condition Number](http://jmlr.org/proceedings/papers/v35/hardt14a.pdf) (2014)  
 #. [Understanding Alternating Minimization for Matrix Completion](http://arxiv.org/abs/1312.0925) (2013)  
 #. [Low-rank Matrix Completion using Alternating Minimization](http://arxiv.org/abs/1212.0467) (2012)  
 #. [Matrix Completion from a Few Entries](http://arxiv.org/abs/0901.3150) (2009)  
 #. [Guaranteed Rank Minimization via Singular Value Projection](http://arxiv.org/abs/0909.5457) (2009)

### Tensor Recovery & Hidden Variable Models
 #. [Speeding up sum-of-squares for tensor decomposition and planted sparse vectors](http://arxiv.org/abs/1512.02337) (2015)
 #. [Tensor vs Matrix Methods: Robust Tensor Decomposition under Block Sparse Perturbations](http://arxiv.org/abs/1510.04747) (2015)
 #. [Analyzing Tensor Power Method Dynamics: Applications to Learning Overcomplete Latent Variable Models](http://arxiv.org/abs/1411.1488) (2014)
 #. [Tensor decompositions for learning latent variable models](http://arxiv.org/abs/1210.7559) (2014)
 #. [Provable Learning of Overcomplete Latent Variable Models: Semi-supervised and Unsupervised Settings](http://arxiv.org/abs/1408.0553) (2014)
 #. [Provable Tensor Factorization with Missing Data](http://arxiv.org/abs/1406.2784) (2014)
 #. [Guaranteed Non-Orthogonal Tensor Decomposition via Alternating Rank-1 Updates](http://arxiv.org/abs/1402.5180) (2014)

### Phase Retrieval
 #. [A Geometric Analysis of Phase Retrieval](http://arxiv.org/abs/1602.06664) (\[<span style="color:red">**S**</span>\], 2016)
 #. [The Local Convexity of Solving Quadratic Equations](http://arxiv.org/abs/1506.07868) (2015)
 #. [Solving Random Quadratic Systems of Equations Is Nearly as Easy as Solving Linear Systems](http://arxiv.org/abs/1505.05114) (2015)  
 #. [Phase Retrieval via Wirtinger Flow: Theory and Algorithms](http://arxiv.org/abs/1407.1065) (2014)
 #. [Phase Retrieval using Alternating Minimization](http://arxiv.org/abs/1306.0160) (2013)

### Dictionary Learning
(See also **Theory** part in [Dictionary/Deep Learning](/research/dict-learn/)) 

 #. [Complete Dictionary Recovery over the Sphere](http://arxiv.org/abs/1504.06785) (\[<span style="color:red">**S**</span>\], 2015)  
 #. [Simple, Efficient, and Neural Algorithms for Sparse Coding](http://arxiv.org/abs/1503.00778) (2015)
 #. [More Algorithms for Provable Dictionary Learning](http://arxiv.org/abs/1401.0579) (2014)
 #. [Exact Recovery of Sparsely Used Overcomplete Dictionaries](http://arxiv.org/abs/1309.1952) (2013)
 #. [New Algorithms for Learning Incoherent and Overcomplete Dictionaries](http://arxiv.org/abs/1308.6273) (2013)
 #. [Learning Sparsely Used Overcomplete Dictionaries via Alternating Minimization](http://arxiv.org/abs/1310.7991) (2013)

### Sparse Vectors in Linear Subspaces
(See [Structured Element Pursuit](/research/struct-elem/) )

### Nonnegative/Sparse Principal Component Analysis
 #. [Non-negative Principal Component Analysis: Message Passing Algorithms and Sharp Asymptotics](http://arxiv.org/abs/1406.4775) (2014)
 
### Mixed Linear Regression 
 #. [Provable Tensor Methods for Learning Mixtures of Classifiers](http://arxiv.org/abs/1412.3046) (2014)
 #. [Alternating Minimization for Mixed Linear Regression](http://arxiv.org/abs/1310.3745) (2013)
 
### Blind Deconvolution
 #. [ RIP-like Properties in Subsampled Blind Deconvolution](http://arxiv.org/abs/1511.06146) (2015)
 #. [Blind Recovery of Sparse Signals from Subsampled Convolution](http://arxiv.org/abs/1511.06149) (2015)
 #. [Near Optimal Compressed Sensing of Sparse Rank-One Matrices via Sparse Power Factorization](http://arxiv.org/abs/1312.0525) (2013)
 
### Super Resolution
 #. [Greed is Super: A Fast Algorithm for Super-Resolution](http://arxiv.org/abs/1511.03385) (2015)
 
### Phase Synchronization 
 #. [On the low-rank approach for semidefinite programs arising in synchronization and community detection](http://arxiv.org/abs/1602.04426) (2016)
 #. [Nonconvex phase synchronization](http://arxiv.org/abs/1601.06114) (2016)
 
### Numerical Linear Algebra
 #. [On the matrix square root via geometric optimization](http://arxiv.org/abs/1507.08366) (2015)
 #. [Computing Matrix Squareroot via Non Convex Local Search](http://arxiv.org/abs/1507.05854) (2015)
 
### Bayesian Inference
 #. [On some provably correct cases of variational inference for topic models](http://arxiv.org/abs/1503.06567) (2015)
 
### Burer-Monteiro Style Decomposition Algorithms
 #. [Global Convergence of Stochastic Gradient Descent for Some Nonconvex Matrix Problems](http://arxiv.org/abs/1411.1134) (2014)

## Of Statistical Nature ... 
 #. [Statistical and Computational Guarantees for the Baum-Welch Algorithm](http://arxiv.org/abs/1512.08269) (2015)
 #. [Provable Sparse Tensor Decomposition](http://arxiv.org/abs/1502.01425) (2015)
 #. [Statistical consistency and asymptotic normality for high-dimensional robust M-estimators](http://arxiv.org/abs/1501.00312) (2015)
 #. [Support recovery without incoherence: A case for nonconvex regularizations](http://arxiv.org/abs/1412.5632) (2014)
 #. [High Dimensional Expectation-Maximization Algorithm: Statistical Optimization and Asymptotic Normality](http://arxiv.org/abs/1412.8729) (2014)
 #. [Statistical guarantees for the EM algorithm: From population to sample-based analysis](http://arxiv.org/abs/1408.2156) (2014)
 #. [Nonconvex Statistical Optimization: Minimax-Optimal Sparse PCA in Polynomial Time](http://arxiv.org/abs/1408.5352) (2014)
 #. [Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima](http://arxiv.org/abs/1305.2436) (2013)
 #. [High-dimensional regression with noisy and missing data: Provable guarantees with nonconvexity](http://arxiv.org/abs/1109.3714) (2011)
 
## Relevant Tools/Local Results
 #. [First-order Methods for Geodesically Convex Optimization](http://arxiv.org/abs/1602.06053) (2016)
 #. [Efficient approaches for escaping higher order saddle points in non-convex optimization](http://arxiv.org/abs/1602.05908) (2016)
 #. [Gradient Descent Converges to Minimizers](http://arxiv.org/abs/1602.04915) (2016)
 #. [When Are Nonconvex Problems Not Scary?](http://arxiv.org/abs/1510.06096) (2015)
 #. [Dropping Convexity for Faster Semi-definite Optimization](http://arxiv.org/abs/1509.03917) (2015)
 #. [Escaping the Local Minima via Simulated Annealing: Optimization of Approximately Convex Functions](http://arxiv.org/abs/1501.07242) (2015)
 #. [Escaping From Saddle Points --- Online Stochastic Gradient for Tensor Decomposition](http://arxiv.org/abs/1503.02101) (2015)
 #. [Proximal alternating linearized minimization for nonconvex and nonsmooth problems](http://dx.doi.org/10.1007/s10107-013-0701-9) (2013)
 #. [Convergence of descent methods for semi-algebraic and tame problems: proximal algorithms, forward–backward splitting, and regularized Gauss–Seidel methods](http://dx.doi.org/10.1007/s10107-011-0484-9) (2013)
 #. [Proximal alternating minimization and projection methods for nonconvex problems: An approach based on the Kurdyka-Łojasiewicz inequality](http://arxiv.org/abs/0801.1780) (2008)


> **Disclaimer** - This page is meant to serve a hub for references on this problem, and does not represent in any way personal endorsement of papers listed here. So I do not hold any responsibility for quality and technical correctness of each paper listed here. The reader is advised to use this resource with discretion.

> **If you'd like your paper to be listed here**  - Just drop me a few lines via email (which can be found on "Welcome" page). If you don't bother to spend a word, just deposit your paper on arXiv. I get email alert about new animals there every morning,  and will be happy to hunt one for this zoo if it seems **fit**. 

